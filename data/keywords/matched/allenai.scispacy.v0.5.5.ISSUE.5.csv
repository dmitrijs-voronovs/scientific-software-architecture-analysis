id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/allenai/scispacy/issues/388:2392,modifiability,compon,components,2392,"und by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionalit",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2445,modifiability,Paramet,Parameters,2445,"plete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from s",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2770,modifiability,configur,configurations,2770,"apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entities_tuple(text: str, long_form_abbrev_ents: bool, model_list: list, scispacy_linker_config: dict):. # place code for function here, likely to utilize the imported modules above. return (nlp, doc). text = ""Spinal ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:3728,modifiability,modul,modules,3728,"d""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entities_tuple(text: str, long_form_abbrev_ents: bool, model_list: list, scispacy_linker_config: dict):. # place code for function here, likely to utilize the imported modules above. return (nlp, doc). text = ""Spinal and bulbar muscular atrophy (SBMA) is an \. inherited motor neuron disease caused by the expansion \. of a polyglutamine tract within the androgen receptor (AR). \. SBMA can be caused by this easily."". tup = consolidated_entities_tuple(text, True, [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""], . {""resolve_abbreviations"": True, ""filter_for_definitions"": False, . ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). nlp = tup[0]. doc = tup[1]. # Let's look at the first entity. entity = doc.ents[0]. print(""Name: "", entity). >>> Name: Spinal and bulbar muscular atrophy. # Each entity is linked to UMLS with a score. # (currently just char-3gram matching). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. 	print(linker.kb.cui_to_entity[umls_ent[0]]). >>> CUI: C1839259, Name: Bulbo-Spinal Atrophy, X-Linked. >>> Definition: An X-linked recessive form of spinal muscular atrophy. It is due to a mutation o",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:3821,modifiability,inherit,inherited,3821,"ker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entities_tuple(text: str, long_form_abbrev_ents: bool, model_list: list, scispacy_linker_config: dict):. # place code for function here, likely to utilize the imported modules above. return (nlp, doc). text = ""Spinal and bulbar muscular atrophy (SBMA) is an \. inherited motor neuron disease caused by the expansion \. of a polyglutamine tract within the androgen receptor (AR). \. SBMA can be caused by this easily."". tup = consolidated_entities_tuple(text, True, [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""], . {""resolve_abbreviations"": True, ""filter_for_definitions"": False, . ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). nlp = tup[0]. doc = tup[1]. # Let's look at the first entity. entity = doc.ents[0]. print(""Name: "", entity). >>> Name: Spinal and bulbar muscular atrophy. # Each entity is linked to UMLS with a score. # (currently just char-3gram matching). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. 	print(linker.kb.cui_to_entity[umls_ent[0]]). >>> CUI: C1839259, Name: Bulbo-Spinal Atrophy, X-Linked. >>> Definition: An X-linked recessive form of spinal muscular atrophy. It is due to a mutation of the. 				gene encoding the ANDROGEN RECEPTOR. >>> TUI(s): T047. >>> Aliases (abbreviated, to",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1551,performance,time,times,1551,"mings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:5474,performance,time,time,5474,"ar muscular atrophy (SBMA) is an \. inherited motor neuron disease caused by the expansion \. of a polyglutamine tract within the androgen receptor (AR). \. SBMA can be caused by this easily."". tup = consolidated_entities_tuple(text, True, [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""], . {""resolve_abbreviations"": True, ""filter_for_definitions"": False, . ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). nlp = tup[0]. doc = tup[1]. # Let's look at the first entity. entity = doc.ents[0]. print(""Name: "", entity). >>> Name: Spinal and bulbar muscular atrophy. # Each entity is linked to UMLS with a score. # (currently just char-3gram matching). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. 	print(linker.kb.cui_to_entity[umls_ent[0]]). >>> CUI: C1839259, Name: Bulbo-Spinal Atrophy, X-Linked. >>> Definition: An X-linked recessive form of spinal muscular atrophy. It is due to a mutation of the. 				gene encoding the ANDROGEN RECEPTOR. >>> TUI(s): T047. >>> Aliases (abbreviated, total: 50):. Bulbo-Spinal Atrophy, X-Linked, Bulbo-Spinal Atrophy, X-Linked, .... >>> CUI: C0752353, Name: Atrophy, Muscular, Spinobulbar. >>> Definition: ..... >>> TUI(s): T047. >>> Aliases: (total: ?):. ... , ... , ... , ... >>> ..... # Now let's look at the abbreviations in the text. print(""Abbreviation"", ""\t"", ""Definition""). for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). >>> Abbreviation	 Span	 Definition. >>> SBMA 		 (33, 34) Spinal and bulbar muscular atrophy. >>> SBMA 	 	 (6, 7) Spinal and bulbar muscular atrophy. >>> AR 		 (29, 30) androgen receptor. ```. Thank you for taking the time to read this. If this sort of function already exists in ScispaCy, please let me know. Otherwise, if this sort of function or some other code that accomplishes the same thing can be added to ScispaCy, that would be awesome. I believe it can be a powerful addition to the library. Let me know your thoughts.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:603,safety,detect,detected,603,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1324,safety,compl,completely,1324,"powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the des",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1447,safety,compl,complete,1447,"the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parame",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:3728,safety,modul,modules,3728,"d""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entities_tuple(text: str, long_form_abbrev_ents: bool, model_list: list, scispacy_linker_config: dict):. # place code for function here, likely to utilize the imported modules above. return (nlp, doc). text = ""Spinal and bulbar muscular atrophy (SBMA) is an \. inherited motor neuron disease caused by the expansion \. of a polyglutamine tract within the androgen receptor (AR). \. SBMA can be caused by this easily."". tup = consolidated_entities_tuple(text, True, [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""], . {""resolve_abbreviations"": True, ""filter_for_definitions"": False, . ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). nlp = tup[0]. doc = tup[1]. # Let's look at the first entity. entity = doc.ents[0]. print(""Name: "", entity). >>> Name: Spinal and bulbar muscular atrophy. # Each entity is linked to UMLS with a score. # (currently just char-3gram matching). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. 	print(linker.kb.cui_to_entity[umls_ent[0]]). >>> CUI: C1839259, Name: Bulbo-Spinal Atrophy, X-Linked. >>> Definition: An X-linked recessive form of spinal muscular atrophy. It is due to a mutation o",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:43,security,Model,Models,43,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:189,security,ident,identify,189,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:354,security,ident,identified,354,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:378,security,model,models,378,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:475,security,model,model,475,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:510,security,model,model,510,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:539,security,model,model,539,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:603,security,detect,detected,603,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:644,security,ident,identified,644,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:738,security,model,model,738,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1127,security,model,models,1127,"d so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1138,security,ident,identify,1138,"hink ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may g",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1204,security,model,model,1204,"biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, u",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1263,security,model,models,1263,"nd other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next lo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1313,security,model,models,1313,"be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1324,security,compl,completely,1324,"powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the des",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1414,security,model,models,1414,"can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be rough",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1447,security,compl,complete,1447,"the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parame",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1516,security,model,model,1516," would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be iden",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1818,security,model,model,1818," ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including th",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1824,security,ident,identifies,1824," However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1984,security,model,model,1984,"he entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple wi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:1990,security,ident,identifies,1990,"ies should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the f",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2240,security,model,model,2240,"ne entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the prop",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2515,security,ident,identified,2515,"l individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2561,security,ident,identify,2561,"onger phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entit",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2653,security,model,models,2653,"are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entities_tuple(text: str, long_form_abbrev_ents: bool, model_list: list, scispacy_linker_config:",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2770,security,configur,configurations,2770,"apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entities_tuple(text: str, long_form_abbrev_ents: bool, model_list: list, scispacy_linker_config: dict):. # place code for function here, likely to utilize the imported modules above. return (nlp, doc). text = ""Spinal ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:170,usability,tool,tool,170,"Combining Entities Recognized by Different Models & by the AbbreviationDetector; I recently encountered both spaCy and ScispaCy and so far I think ScispaCy is an awesome tool to be able to identify and link biomedical entities found in text with concepts from UMLS and other knowledge bases. I was thinking it would be even more powerful if the entities identified by different models and by the AbbreviationDetector can be combined. This would allow the shortcomings of one model to be compensated by another model. It would also allow a model's shortcomings to be compensated by the long forms of any detected abbreviations. For example, the identified entities in ""Spinal and bulbar muscular atrophy (SBMA)"" using the `en_core_sci_lg` model in the [ScispaCy Demo](url) are: . - ""Spinal"". - ""bulbar muscular atrophy"". - ""SBMA"". However, after adding the AbbreviationDetector as a pipe, we would recognize ""SBMA"" as an abbreviation for ""Spinal and bulbar muscular atrophy"", so really, the entities should be the following, but they are not corrected as such:. - ""Spinal and bulbar muscular atrophy"". - ""SBMA"". Similarly, some models may identify fragments of a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:2154,usability,help,helpful,2154,"f a phrase as separate entities while another model may recognize a whole phrase as one entity. Or, some models may recognize certain entities while other models may completely ignore them. If there is some way of consolidating entities found by different models, then a more accurate and complete list of entities will be obtained than just using any given model individually. There are also times when a longer phrased entity is not always better, because it may yield poor matching results that are below the desired mention threshold for a given knowledge base. For example, in the [ScispaCy Demo](https://scispacy.apps.allenai.org/), the `en_core_sci_md` model identifies ""inherited motor neuron disease"" as an entity but gives no results satisfying the mention threshold of 0.85. On the other hand, the `en_core_sci_sm` model identifies ""inherited"" and ""motor neuron disease"" as separate entities, each of which have matches above the 0.85 mention threshold. Therefore, it may generally be helpful to also keep track of any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/388:3182,usability,user,user,3182,"any related original, unconsolidated entities from each model and pick the next longest phrased entities that have matching results above the desired mention threshold. Overall, a function with the following components would be roughly what I'm looking for:. - Parameters to take in:. - The text string from which entities will be identified. - A boolean for whether or not to identify the long forms of abbreviations as entities. (e.g., True). - A list of the desired models to use (e.g., [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""]). - A dictionary with any desired configurations of the scispacy linker, including the linker name (e.g., {""resolve_abbreviations"": True, ""filter_for_definitions"": False, ""no_definition_threshold"": 0.85, ""linker_name"": ""umls""}). . - Output: A tuple with the following two items:. - The nlp object that can be used to make the linker to the utilized knowledge base. - A Doc object with the longest length entities that also have matches above the user's desired mention threshold. Here is how use of the proposed function, which I call `consolidated_entities_tuple` might look like (This is NOT functioning code, just an example of how I imagine the functionality to be):. ```. import spacy. import scispacy. from scispacy.linking import EntityLinker. from scispacy.abbreviation import AbbreviationDetector. def consolidated_entities_tuple(text: str, long_form_abbrev_ents: bool, model_list: list, scispacy_linker_config: dict):. # place code for function here, likely to utilize the imported modules above. return (nlp, doc). text = ""Spinal and bulbar muscular atrophy (SBMA) is an \. inherited motor neuron disease caused by the expansion \. of a polyglutamine tract within the androgen receptor (AR). \. SBMA can be caused by this easily."". tup = consolidated_entities_tuple(text, True, [""en_core_sci_sm"", ""en_core_sci_scibert"", ""en_ner_bc5cdr_md""], . {""resolve_abbreviations"": True, ""filter_for_definitions"": False, . ""no_definition_threshold"": ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/388
https://github.com/allenai/scispacy/issues/389:104,energy efficiency,model,models,104,"Train scispacy for languages other than English; The tool is the great work. Thanks. I realized all the models are currently for English language. I was wondering if you have any plans to support any other language, or is there any documentation on how to train my own for another language?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/389
https://github.com/allenai/scispacy/issues/389:115,energy efficiency,current,currently,115,"Train scispacy for languages other than English; The tool is the great work. Thanks. I realized all the models are currently for English language. I was wondering if you have any plans to support any other language, or is there any documentation on how to train my own for another language?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/389
https://github.com/allenai/scispacy/issues/389:104,security,model,models,104,"Train scispacy for languages other than English; The tool is the great work. Thanks. I realized all the models are currently for English language. I was wondering if you have any plans to support any other language, or is there any documentation on how to train my own for another language?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/389
https://github.com/allenai/scispacy/issues/389:179,testability,plan,plans,179,"Train scispacy for languages other than English; The tool is the great work. Thanks. I realized all the models are currently for English language. I was wondering if you have any plans to support any other language, or is there any documentation on how to train my own for another language?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/389
https://github.com/allenai/scispacy/issues/389:53,usability,tool,tool,53,"Train scispacy for languages other than English; The tool is the great work. Thanks. I realized all the models are currently for English language. I was wondering if you have any plans to support any other language, or is there any documentation on how to train my own for another language?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/389
https://github.com/allenai/scispacy/issues/389:188,usability,support,support,188,"Train scispacy for languages other than English; The tool is the great work. Thanks. I realized all the models are currently for English language. I was wondering if you have any plans to support any other language, or is there any documentation on how to train my own for another language?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/389
https://github.com/allenai/scispacy/issues/389:232,usability,document,documentation,232,"Train scispacy for languages other than English; The tool is the great work. Thanks. I realized all the models are currently for English language. I was wondering if you have any plans to support any other language, or is there any documentation on how to train my own for another language?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/389
https://github.com/allenai/scispacy/issues/390:120,energy efficiency,load,load,120,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:632,energy efficiency,CPU,CPU,632,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:120,performance,load,load,120,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:140,performance,time,time,140,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:171,performance,time,time,171,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:228,performance,cach,cached,228,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:268,performance,time,time,268,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:632,performance,CPU,CPU,632,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:636,performance,time,times,636,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:687,performance,time,time,687,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/390:643,usability,user,user,643,"Entity Linker takes a while to process; I tried using the entity linker with UMLS from scispacy and it takes a while to load (for the first time) ~ around 14s. The second time I run it is noticeably faster ~ 30 ms. I assume its cached? Here is the code I ran:. ```. %%time. doc = nlp(""arrhythmia""). spacy.displacy.render(doc, style = ""ent"", jupyter = True). entity = doc.ents[0]. print(""Name: "", entity). linker = nlp.get_pipe(""scispacy_linker""). for umls_ent in entity._.kb_ents:. print(umls_ent). print(linker.kb.cui_to_entity[umls_ent[0]]). print(""----------------------""). ```. and it outputted:. ```. ..(the printed values)... CPU times: user 0 ns, sys: 297 ms, total: 297 ms. Wall time: 13.8 s. ```. Is this normal? Is there a way to make the results appear faster as in the demo in Streamlit, when I type in words in the textbox, the results seem to come out instantaneously. How is it done there?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/390
https://github.com/allenai/scispacy/issues/391:86,deployability,releas,release,86,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:171,deployability,version,versions,171,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:306,deployability,version,version,306,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:348,deployability,updat,update,348,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:171,integrability,version,versions,171,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:306,integrability,version,version,306,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:135,interoperability,conflict,conflict,135,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:171,modifiability,version,versions,171,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:306,modifiability,version,version,306,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:348,safety,updat,update,348,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:348,security,updat,update,348,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/391:373,security,team,team,373,"scispacy with spacy 3.1.1 and prodigy 1.11; I'm trying to use scispacy with the newly release prodigy (1.11.2) but there seems to be a conflict between the required spacy versions. scispacy uses spacy 3.0.7, but prodigy requires spacy<3.2.0, >=3.1.1. Is there some way that I can use scispacy with a newer version or spacy, or should I wait for an update from the scispacy team?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/391
https://github.com/allenai/scispacy/issues/392:24,energy efficiency,model,model,24,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:68,energy efficiency,model,model,68,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:211,energy efficiency,model,model,211,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:253,energy efficiency,model,models,253,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:84,integrability,transform,transformers,84,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:138,integrability,transform,transformers,138,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:84,interoperability,transform,transformers,84,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:138,interoperability,transform,transformers,138,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:201,performance,tune,tuned,201,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:24,security,model,model,24,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:68,security,model,model,68,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:211,security,model,model,211,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:253,security,model,models,253,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/392:13,usability,custom,custom,13,How to use a custom NER model in SciSpacy?; I've trained my own NER model using the transformers library. (https://github.com/huggingface/transformers). I was wondering if it's possible to use my fine-tuned NER model in SciSpacy instead of the provided models.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/392
https://github.com/allenai/scispacy/issues/393:54,availability,down,download,54,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:88,availability,state,stated,88,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:121,availability,avail,available,121,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:171,availability,down,downloadable,171,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:305,availability,error,error,305,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:467,availability,error,error,467,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:88,integrability,state,stated,88,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:305,performance,error,error,305,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:467,performance,error,error,467,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:121,reliability,availab,available,121,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:4,safety,permiss,permissions,4,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:121,safety,avail,available,121,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:305,safety,error,error,305,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:467,safety,error,error,467,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:121,security,availab,available,121,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:206,usability,command,command,206,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:305,usability,error,error,305,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:359,usability,command,command,359,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/393:467,usability,error,error,467,"aws permissions for datasets; Hello, . I am trying to download the necessary assets. As stated in #382, ontonotes is not available but med mentions and the TSVs should be downloadable. Yet I get:. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/med_mentions.tar.gz assets/med_mentions.tar.gz. fatal error: Unable to locate credentials. `. and. `Running command: aws s3 cp s3://ai2-s2-scispacy/data/ner/ assets --recursive --exclude '*' --include '*.tsv'. fatal error: Unable to locate credentials. `. Please advise.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/393
https://github.com/allenai/scispacy/issues/394:481,availability,avail,available,481,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:1230,availability,avail,available,1230,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:453,energy efficiency,Current,Currently,453,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:116,integrability,coupl,couple,116,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:549,integrability,Sub,Subject,549,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:826,integrability,pub,publish,826,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:607,interoperability,ontolog,ontologies,607,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:743,interoperability,specif,specifically,743,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:116,modifiability,coupl,couple,116,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:1512,performance,time,time,1512,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:1615,performance,time,time,1615,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:481,reliability,availab,available,481,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:1230,reliability,availab,available,1230,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:481,safety,avail,available,481,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:1230,safety,avail,available,1230,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:481,security,availab,available,481,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:1230,security,availab,available,1230,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:116,testability,coupl,couple,116,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:16,usability,document,documentation,16,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:153,usability,prefer,prefer,153,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:221,usability,clear,clearer,221,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/394:282,usability,document,documentation,282,"Entity Linker - documentation issues and questions; Hello,. I am experimenting with the entity linkers and I have a couple of questions/comments. If you prefer I can make separate issues for each of them but I think it's clearer to have a single issue. First small question: Is the documentation for the linkers and candidate generators outdated? The docstring for CandidateGenerator says. > A candidate generator for entity linking to a KnowledgeBase. Currently, two defaults are available:. > - Unified Medical Language System (UMLS). > - Medical Subject Headings (MESH). But the readme lists a few other ontologies as well (and they do seem to be handled in the code). Second higher level question: I'm interested in your reasons for using specifically 3-gram tf-idf vectorization for ANN for candidate generation? Did you publish a paper or something I could read? I would like to experiment with using pre-trained word embeddings instead, but it seems like a rather obvious idea, so I'm curious if there are reasons you didn't do that in the first place? Related to that, if I wanted to generate an index based on word embeddings - how expensive is the generation of the ANN index? I only have limited computing capabilities available, and the default value for the number of threads in https://github.com/allenai/scispacy/blob/3d153ddad1f11f000f961f7a92c0d862b93c0973/scispacy/candidate_generation.py#L396. > num_threads = 60 # set based on the machine. Worries me a little. I don't want to spend a lot of time preparing this only to find out that the training is way too expensive to be done in a reasonable time. Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/394
https://github.com/allenai/scispacy/issues/395:1749,availability,down,download,1749,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:10,deployability,resourc,resources,10,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:343,deployability,pipelin,pipeline,343,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:392,deployability,pipelin,pipeline,392,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:434,deployability,Pipelin,Pipeline,434,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:10,energy efficiency,resourc,resources,10,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:24,energy efficiency,model,models,24,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:306,energy efficiency,gpu,gpu-id,306,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:951,energy efficiency,model,model,951,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1025,energy efficiency,alloc,allocate,1025,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1046,energy efficiency,GPU,GPU,1046,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1097,energy efficiency,alloc,allocated,1097,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1379,energy efficiency,model,models,1379,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1553,energy efficiency,Current,Currently,1553,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1728,energy efficiency,model,model-best,1728,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1770,energy efficiency,model,model,1770,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:343,integrability,pipelin,pipeline,343,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:392,integrability,pipelin,pipeline,392,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:434,integrability,Pipelin,Pipeline,434,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:446,integrability,transform,transformer,446,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:524,integrability,compon,components,524,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:446,interoperability,transform,transformer,446,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:524,interoperability,compon,components,524,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1342,interoperability,share,share,1342,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:524,modifiability,compon,components,524,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:0,performance,computing resourc,computing resources,0,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:306,performance,gpu,gpu-id,306,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1008,performance,memor,memory,1008,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1046,performance,GPU,GPU,1046,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1192,performance,memor,memory,1192,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:10,safety,resourc,resources,10,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:970,safety,except,exception,970,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:24,security,model,models,24,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:604,security,LOSS,LOSS,604,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:618,security,LOSS,LOSS,618,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:630,security,LOSS,LOSS,630,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:951,security,model,model,951,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1379,security,model,models,1379,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1676,security,access,access,1676,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1728,security,model,model-best,1728,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1770,security,model,model,1770,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:10,testability,resourc,resources,10,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:581,usability,learn,learn,581,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1008,usability,memor,memory,1008,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1192,usability,memor,memory,1192,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1496,usability,custom,customize,1496,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/395:1570,usability,custom,customize,1570,"computing resources and models in output/; I try to train en_core_sci_scibert_parser_tagger following the project.yml. spacy train configs/base_parser_tagger_scibert.cfg --output output/en_core_sci_scibert_parser_tagger --code scispacy/base_project_code.py --paths.vocab_path project_data/vocab_lg.jsonl --gpu-id 0. Then I met:.  Initialized pipeline. ============================= Training pipeline =============================.  Pipeline: ['transformer', 'tagger', 'attribute_ruler', 'lemmatizer',. 'parser'].  Frozen components: ['attribute_ruler', 'lemmatizer'].  Initial learn rate: 5e-05. E # LOSS TRANS... LOSS TAGGER LOSS PARSER TAG_ACC LEMMA_ACC DEP_UAS DEP_LAS SENTS_F SCORE . --- ------ ------------- ----------- ----------- ------- --------- ------- ------- ------- ------. 0 0 0.00 4175.17 8352.18 71.48 0.00 24.43 6.92 0.00 0.17. Epoch 1: 15%| | 347/2300 [08:11<51:33, 1.58s/it] Aborting and saving the final best model. Encountered exception:. RuntimeError('CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 31.75 GiB total capacity; 29.89 GiB already allocated; 11.50 MiB free; 30.27 GiB reserved in total by PyTorch)'). I am wondering how large memory do you usuallly use for training, so that I can try to apply for that in my college. Furthermore, I would appreciate it very much if you could share(if possible) part of the saved models like output/en_core_sci_scibert_parser_tagger somewhere so that it will be very convenient for more people to customize their training based on your previous results. Currently I only customize the training for ""name: ner-train-scibert"", so for the previous steps I can skip them if I have access to ""output/en_core_sci_scibert_parser_tagger/model-best"" and just download and put the model in the assigned path. Thank you so much!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/395
https://github.com/allenai/scispacy/issues/396:1362,deployability,instal,install,1362,"import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creat",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1396,deployability,instal,install,1396,"y.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1232,energy efficiency,CPU,CPU,1232,"AULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). from scispacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(n",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:141,integrability,messag,messages,141,"Getting Warnings when using custom KB; I made my own KB as per #331 and it works perfectly. The only problem is I keep getting these warning messages. Here is my code:. ```. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). from scispacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:141,interoperability,messag,messages,141,"Getting Warnings when using custom KB; I made my own KB as per #331 and it works perfectly. The only problem is I keep getting these warning messages. Here is my code:. ```. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). from scispacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:2121,interoperability,specif,specify,2121,"dgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]. ```. Do you know why this is the case? is there a way to fix this or remove the warning?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:2550,interoperability,specif,specify,2550,"dgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]. ```. Do you know why this is the case? is there a way to fix this or remove the warning?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1858,modifiability,pac,packages,1858,"dgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]. ```. Do you know why this is the case? is there a way to fix this or remove the warning?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:2287,modifiability,pac,packages,2287,"dgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]. ```. Do you know why this is the case? is there a way to fix this or remove the warning?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1232,performance,CPU,CPU,1232,"AULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). from scispacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(n",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1341,performance,perform,performance,1341,"pacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprec",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1479,safety,test,tested,1479,"/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1721,safety,except,except,1721,"ses.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]. ```. Do you know why this is the case? is the",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1479,testability,test,tested,1479,"/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:28,usability,custom,custom,28,"Getting Warnings when using custom KB; I made my own KB as per #331 and it works perfectly. The only problem is I keep getting these warning messages. Here is my code:. ```. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). from scispacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1236,usability,support,supports,1236,"NOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). from scispacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1341,usability,perform,performance,1341,"pacy.linking_utils import KnowledgeBase. from scispacy.linking import *. CustomLinkerPaths_mycustom = LinkerPaths(. ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprec",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1459,usability,custom,custom,1459," ann_index=""../Metas/knowledge base/kb/nmslib_index.bin"",. tfidf_vectorizer=""../Metas/knowledge base/kb/tfidf_vectorizer.joblib"",. tfidf_vectors=""../Metas/knowledge base/kb/tfidf_vectors_sparse.npz"",. concept_aliases_list=""../Metas/knowledge base/kb/concept_aliases.json"",. ). class myKnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndar",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:1827,usability,user,user,1827,"dgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]. ```. Do you know why this is the case? is there a way to fix this or remove the warning?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/396:2256,usability,user,user,2256,"dgeBase):. def __init__(. self,. file_path: str = ""../Metas/knowledge base/custom_kb.jsonl"",. ):. super().__init__(file_path). DEFAULT_PATHS[""myCustom""] = CustomLinkerPaths_mycustom. DEFAULT_KNOWLEDGE_BASES[""myCustom""] = myKnowledgeBase. nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""myCustom"",. ""filter_for_definitions"": False, ""threshold"": ""0.5""}). linker = CandidateGenerator(name=""myCustom""). ```. and I got:. ```. Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2. For maximum performance, you can install NMSLIB from sources . pip install --no-binary :all: nmslib. ```. also when I made my own custom function and tested it, I got another warning. Here is the code:. ```. def get_id(word):. temp_doc = nlp(word). try:. ents = temp_doc.ents[0]. possible_ents = [ent for ent in ents._.kb_ents]. most_likely_ent = possible_ents[0]. return most_likely_ent[0]. except:. return """". . x = get_id(""LV""). print(x). ```. This is the warning for the code above:. ```. home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]. /home/user/.local/lib/python3.8/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]. ```. Do you know why this is the case? is there a way to fix this or remove the warning?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/396
https://github.com/allenai/scispacy/issues/397:367,energy efficiency,model,model,367,Passages in MedQA corpus missing white space between words; Some passages in the MedQA corpus is a long string with no white spaces between the words. The issues are from the raw text from the MedQA books. The issue is of low priority but we might need to consider what we should do with these passages. We hypothesise that these passages will not be inputted in the model. . ![Screenshot 2021-10-01 at 10 27 18](https://user-images.githubusercontent.com/46669248/135837803-10d53b85-843e-4303-96ce-9931ac4f56ee.png). #lowpriority,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/397
https://github.com/allenai/scispacy/issues/397:351,safety,input,inputted,351,Passages in MedQA corpus missing white space between words; Some passages in the MedQA corpus is a long string with no white spaces between the words. The issues are from the raw text from the MedQA books. The issue is of low priority but we might need to consider what we should do with these passages. We hypothesise that these passages will not be inputted in the model. . ![Screenshot 2021-10-01 at 10 27 18](https://user-images.githubusercontent.com/46669248/135837803-10d53b85-843e-4303-96ce-9931ac4f56ee.png). #lowpriority,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/397
https://github.com/allenai/scispacy/issues/397:367,security,model,model,367,Passages in MedQA corpus missing white space between words; Some passages in the MedQA corpus is a long string with no white spaces between the words. The issues are from the raw text from the MedQA books. The issue is of low priority but we might need to consider what we should do with these passages. We hypothesise that these passages will not be inputted in the model. . ![Screenshot 2021-10-01 at 10 27 18](https://user-images.githubusercontent.com/46669248/135837803-10d53b85-843e-4303-96ce-9931ac4f56ee.png). #lowpriority,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/397
https://github.com/allenai/scispacy/issues/397:351,usability,input,inputted,351,Passages in MedQA corpus missing white space between words; Some passages in the MedQA corpus is a long string with no white spaces between the words. The issues are from the raw text from the MedQA books. The issue is of low priority but we might need to consider what we should do with these passages. We hypothesise that these passages will not be inputted in the model. . ![Screenshot 2021-10-01 at 10 27 18](https://user-images.githubusercontent.com/46669248/135837803-10d53b85-843e-4303-96ce-9931ac4f56ee.png). #lowpriority,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/397
https://github.com/allenai/scispacy/issues/397:421,usability,user,user-images,421,Passages in MedQA corpus missing white space between words; Some passages in the MedQA corpus is a long string with no white spaces between the words. The issues are from the raw text from the MedQA books. The issue is of low priority but we might need to consider what we should do with these passages. We hypothesise that these passages will not be inputted in the model. . ![Screenshot 2021-10-01 at 10 27 18](https://user-images.githubusercontent.com/46669248/135837803-10d53b85-843e-4303-96ce-9931ac4f56ee.png). #lowpriority,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/397
https://github.com/allenai/scispacy/issues/398:7,availability,error,error,7,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2117,availability,error,error,2117," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2220,deployability,modul,module,2220," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2434,deployability,modul,module,2434," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2591,deployability,modul,module,2591," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2762,deployability,modul,module,2762," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2771,deployability,Modul,ModuleNotFoundError,2771," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2795,deployability,modul,module,2795," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:392,energy efficiency,load,load,392,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:1682,energy efficiency,load,load,1682,"r colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-pack",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2068,interoperability,format,format,2068," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:1066,modifiability,concern,concerns,1066,"umpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".fo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2220,modifiability,modul,module,2220," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2361,modifiability,pac,packages,2361," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2434,modifiability,modul,module,2434," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2523,modifiability,pac,packages,2523," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2591,modifiability,modul,module,2591," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2680,modifiability,pac,packages,2680," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2762,modifiability,modul,module,2762," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2771,modifiability,Modul,ModuleNotFoundError,2771," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2795,modifiability,modul,module,2795," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:7,performance,error,error,7,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:392,performance,load,load,392,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:1682,performance,load,load,1682,"r colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-pack",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2117,performance,error,error,2117," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:7,safety,error,error,7,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:720,safety,compl,complicated,720,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:920,safety,compl,complicated,920,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:963,safety,review,reviewed,963,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:1002,safety,compl,complex,1002," error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2117,safety,error,error,2117," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2220,safety,modul,module,2220," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2434,safety,modul,module,2434," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2591,safety,modul,module,2591," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2762,safety,modul,module,2762," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2771,safety,Modul,ModuleNotFoundError,2771," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2795,safety,modul,module,2795," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:176,security,token,tokenize,176,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:525,security,loss,loss,525,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:720,security,compl,complicated,720,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:920,security,compl,complicated,920,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:1002,security,compl,complex,1002," error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:963,testability,review,reviewed,963,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:1066,testability,concern,concerns,1066,"umpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".fo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2124,testability,Trace,Traceback,2124," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:7,usability,error,error,7,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:155,usability,stop,stopwords,155,"nmslib error; This is my code . from typing import OrderedDict. from numpy import mod. import scispacy. import spacy. import nltk. from nltk.corpus import stopwords. from nltk.tokenize import word_tokenize. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. from collections import OrderedDict. from pprint import pprint. #nlp = spacy.load(""en_ner_bc5cdr_md""). text = """""". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:1423,usability,stop,stopwords,1423,". I The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2117,usability,error,error,2117," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/398:2825,usability,help,help,2825," on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis.,Chart was reviewed, and I will not reiterate her complex history.,I am asked to see the patient again because of concerns for coagulopathy.,She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now.,She is on total parenteral nutrition (TPN) as well.,LABORATORY DATA:, Labs today showed a white blood . . """""". stop_words = set(stopwords.words('english')). word_tokens = word_tokenize(text). . filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]. . filtered_sentence =[]. . for w in word_tokens:. if w not in stop_words:. filtered_sentence.append(w). nlp = spacy.load(""en_ner_bc5cdr_md""). #linker = UmlsEntityLinker(k=10,max_entities_per_mention = 2). doc = nlp(text). entity = doc.ents. entity = [str(item) for item in entity]. entity = str(OrderedDict.fromkeys(entity)). entity = nlp(entity).ents. for entity in entity:. for umls_ent in entity._.umls_ents:. print(""Entity_name"",entity). Concept_id,Score = umls_ent. print(""concept_id={} Score {}"".format(Concept_id,Score)). . But i am getting an error. Traceback (most recent call last):. File ""C:\Python_projects\Second_tria;\demo.py"", line 9, in <module>. from scispacy.umls_linking import UmlsEntityLinker. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\umls_linking.py"", line 2, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\linking.py"", line 5, in <module>. File ""<frozen zipimport>"", line 259, in load_module. File ""C:\Python39\lib\site-packages\scispacy-0.4.0-py3.9.egg\scispacy\candidate_generation.py"", line 10, in <module>. ModuleNotFoundError: No module named 'nmslib'. please help.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/398
https://github.com/allenai/scispacy/issues/399:9,energy efficiency,model,model,9,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:70,energy efficiency,model,model,70,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:583,energy efficiency,temperatur,temperature,583,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1091,energy efficiency,temperatur,temperature,1091,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1378,energy efficiency,model,model,1378,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1425,energy efficiency,load,loading,1425,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1437,energy efficiency,model,model,1437,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1477,energy efficiency,load,load,1477,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1680,energy efficiency,model,models,1680,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:15,integrability,filter,filters,15,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:117,integrability,filter,filtered,117,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:375,performance,time,times,375,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1425,performance,load,loading,1425,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1477,performance,load,load,1477,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:824,reliability,diagno,diagnoses,824,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1185,reliability,diagno,diagnoses,1185,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:239,safety,compl,complaint,239,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:305,safety,compl,complains,305,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:925,safety,compl,complaint,925,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:963,safety,compl,complains,963,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:9,security,model,model,9,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:70,security,model,model,70,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:239,security,compl,complaint,239,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:305,security,compl,complains,305,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:446,security,sign,significant,446,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:925,security,compl,complaint,925,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:963,security,compl,complains,963,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1378,security,model,model,1378,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1437,security,model,model,1437,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1680,security,model,models,1680,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:824,testability,diagno,diagnoses,824,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1185,testability,diagno,diagnoses,1185,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/399:1268,testability,understand,understanding,1268,"ScispaCy model filters numbers out from text; When using the scispaCy model ""en_core_sci_sm"" numbers in the text get filtered out. One example is:. Original text: _A 59-year-old overweight woman presents to the urgent care clinic with the complaint of severe abdominal pain for the past 2 hours. She also complains of a dull pain in her back with nausea and vomiting several times. Her pain has no relation with food. Her past medical history is significant for recurrent abdominal pain due to cholelithiasis. Her father died at the age of 60 with some form of abdominal cancer. Her temperature is 37C (98.6F), respirations are 15/min, pulse is 67/min, and blood pressure is 122/98 mm Hg. Physical exam is unremarkable. However, a CT scan of the abdomen shows a calcified mass near her gallbladder. Which of the following diagnoses should be excluded first in this patient?_. New text: _overweight woman urgent care clinic complaint severe abdominal pain hours complains dull pain nausea vomiting pain food medical history recurrent abdominal pain cholelithiasis died age abdominal cancer temperature respirations pulse blood pressure mm Hg Physical exam CT scan abdomen gallbladder diagnoses patient_ . In the medical domain, such numbers are usually important for understanding the symptoms of a patient and we expected the numbers to be in kept in the text after using the model. However, this is not the case. . We are loading the model in the following way:. ```. spacy.load(. ""en_core_sci_sm"",. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). ```. Is there an explanation for why numbers are not kept? We have tried various scispaCy models but the issue is still the same.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/399
https://github.com/allenai/scispacy/issues/400:43,deployability,version,version,43,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:149,deployability,fail,fails,149,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:220,deployability,version,version,220,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:296,deployability,releas,release,296,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:308,deployability,version,versions,308,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:353,deployability,version,version,353,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:434,deployability,version,versions,434,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:593,deployability,depend,depends,593,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:812,deployability,depend,depends,812,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1014,deployability,depend,depends,1014,"ed with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1067,deployability,depend,depends,1067,"add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1235,deployability,depend,depends,1235,"dy fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1288,deployability,depend,depends,1288,"you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1435,deployability,depend,depends,1435,"ons of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1488,deployability,depend,depends,1488,">3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 r",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1592,deployability,version,versions,1592,"ends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1683,deployability,depend,depends,1683,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1834,deployability,depend,depends,1834,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1887,deployability,depend,depends,1887,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2125,deployability,depend,depends,2125,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2184,deployability,version,version,2184,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2200,deployability,fail,failed,2200,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:0,energy efficiency,Model,Models,0,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:79,energy efficiency,model,models,79,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:176,energy efficiency,model,models,176,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:324,energy efficiency,model,models,324,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1415,energy efficiency,core,core-sci-sm,1415,". Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.over",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1526,energy efficiency,core,core-sci-sm,1526,",<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1993,energy efficiency,core,core-sci-sm,1993,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2053,energy efficiency,core,core-sci-sm,2053,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2163,energy efficiency,core,core-sci-sm,2163,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:11,integrability,pub,published,11,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:43,integrability,version,version,43,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:220,integrability,version,version,220,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:308,integrability,version,versions,308,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:353,integrability,version,version,353,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:434,integrability,version,versions,434,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:593,integrability,depend,depends,593,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:812,integrability,depend,depends,812,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1014,integrability,depend,depends,1014,"ed with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1067,integrability,depend,depends,1067,"add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1235,integrability,depend,depends,1235,"dy fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1288,integrability,depend,depends,1288,"you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1435,integrability,depend,depends,1435,"ons of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1488,integrability,depend,depends,1488,">3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 r",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1592,integrability,version,versions,1592,"ends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1683,integrability,depend,depends,1683,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1834,integrability,depend,depends,1834,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1887,integrability,depend,depends,1887,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2125,integrability,depend,depends,2125,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2184,integrability,version,version,2184,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:43,modifiability,version,version,43,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:220,modifiability,version,version,220,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:308,modifiability,version,versions,308,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:353,modifiability,version,version,353,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:434,modifiability,version,versions,434,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:593,modifiability,depend,depends,593,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:812,modifiability,depend,depends,812,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1014,modifiability,depend,depends,1014,"ed with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1067,modifiability,depend,depends,1067,"add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1235,modifiability,depend,depends,1235,"dy fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1288,modifiability,depend,depends,1288,"you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1435,modifiability,depend,depends,1435,"ons of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1488,modifiability,depend,depends,1488,">3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 r",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1592,modifiability,version,versions,1592,"ends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1683,modifiability,depend,depends,1683,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1834,modifiability,depend,depends,1834,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1887,modifiability,depend,depends,1887,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2125,modifiability,depend,depends,2125,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2184,modifiability,version,version,2184,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2255,modifiability,pac,packages,2255,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2308,modifiability,pac,packages,2308,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2326,modifiability,pac,packages,2326,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2580,modifiability,Pac,PackageNode,2580,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2607,modifiability,pac,packages,2607,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:149,reliability,fail,fails,149,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2200,reliability,fail,failed,2200,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:593,safety,depend,depends,593,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:812,safety,depend,depends,812,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1014,safety,depend,depends,1014,"ed with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1067,safety,depend,depends,1067,"add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1235,safety,depend,depends,1235,"dy fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1288,safety,depend,depends,1288,"you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1435,safety,depend,depends,1435,"ons of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1488,safety,depend,depends,1488,">3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 r",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1683,safety,depend,depends,1683,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1834,safety,depend,depends,1834,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1887,safety,depend,depends,1887,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2125,safety,depend,depends,2125,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2341,safety,except,except,2341,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2457,safety,except,except,2457,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:0,security,Model,Models,0,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:79,security,model,models,79,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:176,security,model,models,176,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:324,security,model,models,324,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:593,testability,depend,depends,593,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:812,testability,depend,depends,812,"Models not published with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1014,testability,depend,depends,1014,"ed with the latest spacy version; Hi,. I'm trying to add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1067,testability,depend,depends,1067,"add the models such as en_core_sci_sm into my environment, but the resolution fails. This is because the models were not built with the latest spacy version which already fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1235,testability,depend,depends,1235,"dy fixed this typer issue. Would it be possible that you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1288,testability,depend,depends,1288,"you release new versions of the models with the latest spacy version? Would be highly highly appreciated! ```. SolverProblemError. Because no versions of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1435,testability,depend,depends,1435,"ons of spacy match >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1488,testability,depend,depends,1488,">3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0. and spacy (3.0.1) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 r",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1683,testability,depend,depends,1683,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1834,testability,depend,depends,1834,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:1887,testability,depend,depends,1887,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/400:2125,testability,depend,depends,2125,".0.2,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.2) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.3 || >3.0.3,<3.0.4 || >3.0.4,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.3) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.4) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.5 || >3.0.5,<3.0.6 || >3.0.6,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). And because spacy (3.0.5) depends on typer (>=0.3.0,<0.4.0). and spacy (3.0.6) depends on typer (>=0.3.0,<0.4.0), spacy (>=3.0.1,<3.0.7 || >3.0.7,<3.1.0) requires typer (>=0.3.0,<0.4.0). (1) So, because en-core-sci-sm (0.4.0) depends on spacy (>=3.0.1,<3.1.0). and spacy (3.0.7) depends on typer (>=0.3.0,<0.4.0), en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0). . Because no versions of typer match >0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0. and typer (0.3.0) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.3.1 || >0.3.1,<0.3.2 || >0.3.2,<0.4.0) requires click (>=7.1.1,<7.2.0). And because typer (0.3.1) depends on click (>=7.1.1,<7.2.0). and typer (0.3.2) depends on click (>=7.1.1,<7.2.0), typer (>=0.3.0,<0.4.0) requires click (>=7.1.1,<7.2.0). And because en-core-sci-sm (0.4.0) requires typer (>=0.3.0,<0.4.0) (1), en-core-sci-sm (0.4.0) requires click (>=7.1.1,<7.2.0). So, because ehrapy depends on both click (^8.0.2) and en-core-sci-sm (0.4.0), version solving failed. at ~/miniconda3/envs/ehrapy/lib/python3.8/site-packages/poetry/puzzle/solver.py:241 in _solve. 237 packages = result.packages. 238 except OverrideNeeded as e:. 239 return self.solve_in_compatibility_mode(e.overrides, use_latest=use_latest). 240 except SolveFailure as e:.  241 raise SolverProblemError(e). 242 . 243 results = dict(. 244 depth_first_search(. 245 PackageNode(self._package, packages), aggregate_package_nodes. ```. Thanks.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/400
https://github.com/allenai/scispacy/issues/401:193,deployability,configurat,configuration,193,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:15,energy efficiency,model,model,15,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:90,energy efficiency,model,model,90,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:159,energy efficiency,model,model,159,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:238,energy efficiency,model,model,238,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:405,energy efficiency,model,models,405,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:193,integrability,configur,configuration,193,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:215,integrability,compon,components,215,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:226,integrability,transform,transformer,226,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:270,integrability,transform,transformers,270,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:283,integrability,Transform,TransformerModel,283,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:215,interoperability,compon,components,215,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:226,interoperability,transform,transformer,226,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:247,interoperability,architectur,architectures,247,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:270,interoperability,transform,transformers,270,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:283,interoperability,Transform,TransformerModel,283,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:193,modifiability,configur,configuration,193,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:215,modifiability,compon,components,215,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:15,security,model,model,15,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:90,security,model,model,90,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:159,security,model,model,159,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:193,security,configur,configuration,193,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:238,security,model,model,238,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/401:405,security,model,models,405,"Use other bert model in training scibert; I have already successfully trained the scibert model on some other datasets. My next step is to use some other bert model for training. I find in the configuration that:. [components.transformer.model]. @architectures = ""spacy-transformers.TransformerModel.v1"". name = ""allenai/scibert_scivocab_uncased"". tokenizer_config = {""use_fast"": true}. To use other bert models, is it just to replace the name with what I want to try? For example, name='bert-base-uncased'. Or do there still exist some constraints?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/401
https://github.com/allenai/scispacy/issues/402:0,availability,Slo,Slow,0,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:87,availability,slo,slow,87,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2870,availability,slo,slow,2870,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3085,availability,slo,slow,3085,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:5,energy efficiency,load,loading,5,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:48,energy efficiency,load,loading,48,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:160,energy efficiency,profil,profiler,160,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:228,energy efficiency,load,loading,228,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:254,energy efficiency,Profil,Profiler,254,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:308,energy efficiency,reduc,reduced,308,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1334,energy efficiency,load,loads,1334, restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.nda,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2650,energy efficiency,Load,Load,2650,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2666,energy efficiency,model,model,2666,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2676,energy efficiency,model,model,2676,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2690,energy efficiency,load,load,2690,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2804,energy efficiency,model,model,2804,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2835,energy efficiency,model,model,2835,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2875,energy efficiency,load,loading,2875,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2888,energy efficiency,model,model,2888,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2968,energy efficiency,model,model,2968,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2977,energy efficiency,load,load,2977,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2986,energy efficiency,model,model,2986,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2996,energy efficiency,load,loading,2996,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3011,energy efficiency,model,model,3011,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3068,energy efficiency,load,load,3068,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3090,energy efficiency,load,loading,3090,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3106,energy efficiency,profil,profiling,3106,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3117,energy efficiency,profil,profiler,3117,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3137,energy efficiency,Profil,Profile,3137,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3148,energy efficiency,profil,profiler,3148,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3180,energy efficiency,model,model,3180,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3208,energy efficiency,model,model,3208,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3240,energy efficiency,profil,profiler,3240,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3281,energy efficiency,profil,profiler,3281,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1624,interoperability,socket,socket,1624,-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2256,interoperability,format,format,2256,"8 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable().",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:541,modifiability,pac,packages,541,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:709,modifiability,pac,packages,709,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:871,modifiability,deco,decoder,871,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:970,modifiability,deco,decoder,970,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:985,modifiability,deco,decode,985,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1032,modifiability,deco,decompress,1032,"nker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Matc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1053,modifiability,Deco,Decompress,1053, UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 ,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1197,modifiability,pac,packages,1197, we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openq,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2237,modifiability,pac,packages,2237,"pr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. p",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:5,performance,load,loading,5,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:48,performance,load,loading,48,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:160,performance,profil,profiler,160,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:228,performance,load,loading,228,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:254,performance,Profil,Profiler,254,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:297,performance,time,time,297,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:469,performance,Cach,Caches,469,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:637,performance,Cach,Caches,637,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1125,performance,Cach,Caches,1125,esting the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.47,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1334,performance,load,loads,1334, restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.nda,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2165,performance,Cach,Caches,2165,"PFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2446,performance,time,time,2446,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2458,performance,time,time,2458,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2650,performance,Load,Load,2650,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2690,performance,load,load,2690,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2875,performance,load,loading,2875,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2977,performance,load,load,2977,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2996,performance,load,loading,2996,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3004,performance,time,time,3004,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3068,performance,load,load,3068,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3090,performance,load,loading,3090,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3098,performance,time,time,3098,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3106,performance,profil,profiling,3106,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3117,performance,profil,profiler,3117,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3137,performance,Profil,Profile,3137,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3148,performance,profil,profiler,3148,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3172,performance,time,time,3172,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3227,performance,time,time,3227,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3240,performance,profil,profiler,3240,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3281,performance,profil,profiler,3281,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3303,performance,time,time,3303,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:0,reliability,Slo,Slow,0,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:87,reliability,slo,slow,87,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2870,reliability,slo,slow,2870,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3085,reliability,slo,slow,3085,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:127,safety,test,testing,127,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1624,security,soc,socket,1624,-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2666,security,model,model,2666,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2676,security,model,model,2676,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2804,security,model,model,2804,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2835,security,model,model,2835,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2888,security,model,model,2888,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2968,security,model,model,2968,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2986,security,model,model,2986,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3011,security,model,model,3011,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3180,security,model,model,3180,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:3208,security,model,model,3208,"ds). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). profiler.enable(). t0 = time(). model = add_scispacy_linker(model). duration = time() - t0. profiler.disable(). stats = pstats.Stats(profiler).sort_stats(""time""). stats.print_stats(20). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:127,testability,test,testing,127,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:453,usability,User,Users,453,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:621,usability,User,Users,621,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:834,usability,User,Users,834,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:933,usability,User,Users,933,"Slow loading of the pipe `scispacy_linker`; Hi, loading an UMLS linker is particularly slow (~20-30s). It is a real issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1109,usability,User,Users,1109,eal issue when testing the code. I reported the profiler output bellow. Is there anything we can do to speed-up the loading of the linker? ## Profiler output. ```. Ordered by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' ,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:1281,usability,User,Users,1281,by: internal time. List reduced from 951 to 20 due to restriction <20>. ncalls tottime percall cumtime percall filename:lineno(function). 1 19.741 19.741 53.338 53.338 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:55(__init__). 1 18.422 18.422 25.783 25.783 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/candidate_generation.py:116(load_approximate_nearest_neighbours_index). 3359672 16.912 0.000 16.912 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:343(raw_decode). 3359672 3.847 0.000 24.272 0.000 /Users/-/anaconda3/lib/python3.8/json/decoder.py:332(decode). 4023 3.202 0.001 3.202 0.001 {method 'decompress' of 'zlib.Decompress' objects}. 3359672 2.840 0.000 30.230 0.000 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/402:2149,usability,User,Users,2149,"/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/scispacy/linking_utils.py:65(<genexpr>). 3359672 2.818 0.000 28.086 0.000 /Users/-/anaconda3/lib/python3.8/json/__init__.py:299(loads). 6719602 2.603 0.000 2.603 0.000 {method 'match' of 're.Pattern' objects}. 6 2.251 0.375 2.251 0.375 {method 'do_handshake' of '_ssl._SSLSocket' objects}. 6 1.206 0.201 1.206 0.201 {method 'read' of '_ssl._SSLSocket' objects}. 6 1.122 0.187 1.122 0.187 {method 'connect' of '_socket.socket' objects}. 9300568 1.002 0.000 1.002 0.000 {method 'add' of 'set' objects}. 3359671 0.867 0.000 1.565 0.000 <string>:1(__new__). 4033 0.763 0.000 0.763 0.000 {built-in method zlib.crc32}. 3360030 0.704 0.000 0.704 0.000 {built-in method __new__ of type object at 0x10c379808}. 3359928 0.679 0.000 0.679 0.000 {method 'startswith' of 'str' objects}. 6719344 0.581 0.000 0.581 0.000 {method 'end' of 're.Match' objects}. 2 0.525 0.262 0.525 0.262 {method 'astype' of 'numpy.ndarray' objects}. 5 0.474 0.095 4.703 0.941 /Users/-/Library/Caches/pypoetry/virtualenvs/fz-openqa-rEqQaPFC-py3.8/lib/python3.8/site-packages/numpy/lib/format.py:699(read_array). 2 0.369 0.184 0.369 0.184 {method 'copy' of 'numpy.ndarray' objects}. ```. ## Code to reproduce the above results. ```python. import cProfile. import pstats. from time import time. import spacy. from scispacy.abbreviation import AbbreviationDetector # type: ignore. from scispacy.linking import EntityLinker # type: ignore. def load_spacy_model(model_name: str):. """"""Load a ScispaCy model"""""". model = spacy.load(. model_name,. disable=[. ""tok2vec"",. ""tagger"",. ""parser"",. ""attribute_ruler"",. ""lemmatizer"",. ],. ). return model. def add_scispacy_linker(model):. """"""add the entity linker (slow loading)"""""". model.add_pipe(. ""scispacy_linker"",. config={""linker_name"": ""umls""},. ). return model. # load the model (ok loading time). model = load_spacy_model(model_name=""en_core_sci_sm""). # load the linker (slow loading time) + profiling. profiler = cProfile.Profile(). prof",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/402
https://github.com/allenai/scispacy/issues/403:177,availability,error,errors,177,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:202,availability,down,download,202,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:318,availability,avail,available,318,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:113,deployability,version,version,113,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:288,deployability,version,version,288,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:328,deployability,updat,updates,328,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:450,deployability,instal,installed,450,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:20,energy efficiency,Model,Model,20,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:99,energy efficiency,current,current,99,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:230,energy efficiency,model,model,230,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:259,energy efficiency,model,model,259,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:274,energy efficiency,current,current,274,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:113,integrability,version,version,113,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:288,integrability,version,version,288,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:77,interoperability,incompatib,incompatible,77,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:219,interoperability,compatib,compatible,219,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:113,modifiability,version,version,113,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:288,modifiability,version,version,288,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:177,performance,error,errors,177,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:318,reliability,availab,available,318,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:177,safety,error,errors,177,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:318,safety,avail,available,318,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:328,safety,updat,updates,328,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:358,safety,valid,validate,358,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:20,security,Model,Model,20,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:230,security,model,model,230,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:259,security,model,model,259,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:318,security,availab,available,318,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:328,security,updat,updates,328,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:358,security,validat,validate,358,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:0,usability,User,UserWarning,0,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:177,usability,error,errors,177,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/403:252,usability,custom,custom,252,"UserWarning: [W031] Model 'en_skills_ner' (2.1.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate warnings.warn(warn_msg); I have check my entire system, but i dont see spacy 2.3.5 installed. Please advise what need to be done. Using: MacOS. python 3.7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/403
https://github.com/allenai/scispacy/issues/404:1254,availability,consist,consisting,1254,"42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2452,availability,recov,recovery,2452,"uickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only ha",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4342,availability,State,States,4342,"rompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be t",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5003,availability,heal,health,5003,"lifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messagin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5906,availability,heal,health,5906,"dest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collec",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5991,availability,heal,health,5991,"sent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # ch",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6494,availability,heal,healthcare,6494,"ind that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2452,deployability,recov,recovery,2452,"uickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only ha",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7575,deployability,version,version,7575,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:328,energy efficiency,model,model,328,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:385,energy efficiency,load,load,385,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2298,energy efficiency,current,current,2298,"cians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or ne",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2477,energy efficiency,profil,profile,2477,"immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosup",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3219,energy efficiency,current,current,3219,"d risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumb",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1759,integrability,contract,contract,1759,"where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China d",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2952,integrability,sub,subject,2952,"hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4148,integrability,sub,substantiated,4148,"rus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of t",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4342,integrability,State,States,4342,"rompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be t",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5298,integrability,messag,messaging,5298,"ients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunoc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5984,integrability,pub,public,5984,"p represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix =",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5998,integrability,messag,messaging,5998,"health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it t",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6029,integrability,messag,message,6029,"tore employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6764,integrability,messag,messaging,6764,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7575,integrability,version,version,7575,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1372,interoperability,Specif,Specific,1372," = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first ren",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1759,interoperability,contract,contract,1759,"where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China d",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5298,interoperability,messag,messaging,5298,"ients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunoc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5998,interoperability,messag,messaging,5998,"health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it t",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6029,interoperability,messag,message,6029,"tore employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6764,interoperability,messag,messaging,6764,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7567,modifiability,Pac,Package,7567,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7575,modifiability,version,version,7575,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:385,performance,load,load,385,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2477,performance,profil,profile,2477,"immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosup",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6671,performance,time,time,6671," itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python ver",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7365,performance,time,times,7365,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2452,reliability,recov,recovery,2452,"uickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only ha",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:84,safety,input,input,84,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:497,safety,input,input,497,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:535,safety,risk,risk,535,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:594,safety,risk,risk,594,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:906,safety,risk,risk,906,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:960,safety,risk,risk,960,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1125,safety,risk,risk,1125," the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data o",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1201,safety,risk,risk,1201,"linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1662,safety,risk,risk,1662,"rus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1924,safety,risk,risk,1924,"o we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer tre",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2059,safety,risk,risk,2059," medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, o",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2225,safety,risk,risk,2225," was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2452,safety,recov,recovery,2452,"uickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only ha",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3022,safety,risk,risk,3022,"ses, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elde",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3412,safety,risk,risk,3412,"9 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3507,safety,risk,risk,3507,"ocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4059,safety,risk,risk,4059,"ne response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government l",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4089,safety,risk,risk,4089,"hat decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4408,safety,risk,risk,4408,"r risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4960,safety,safe,safe,4960,"osuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and eld",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5329,safety,risk,risk,5329,"the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5388,safety,risk,risk,5388,"cles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple s",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5624,safety,compl,complexity,5624,"D-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5696,safety,risk,risk,5696,"e case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5730,safety,compl,complications,5730," the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5818,safety,risk,risk,5818,"talizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6109,safety,safe,safer,6109,"rving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6192,safety,risk,risk,6192,"dividuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_roo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6274,safety,risk,risk,6274," as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f,",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6636,safety,risk,risk,6636,"some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__ve",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6794,safety,risk,risk,6794,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7005,safety,prevent,prevent,7005,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7499,safety,compl,complete,7499,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:328,security,model,model,328,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:535,security,risk,risk,535,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:594,security,risk,risk,594,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:906,security,risk,risk,906,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:960,security,risk,risk,960,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1125,security,risk,risk,1125," the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data o",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1201,security,risk,risk,1201,"linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1662,security,risk,risk,1662,"rus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1913,security,ident,identified,1913,"s. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their ca",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1924,security,risk,risk,1924,"o we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer tre",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2059,security,risk,risk,2059," medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, o",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2225,security,risk,risk,2225," was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2452,security,recov,recovery,2452,"uickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only ha",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:2587,security,sign,significant,2587,"er patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppres",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3022,security,risk,risk,3022,"ses, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elde",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3105,security,access,access,3105,"In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COV",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3412,security,risk,risk,3412,"9 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:3507,security,risk,risk,3507,"ocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 An analysis from China did note increased rates of infection and morbidity in cancer patients, 8 however, it did not adjust for age, included patients many years out from their cancer treatments, and has been the subject of several responses that contest the conclusion of increased risk to cancer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4059,security,risk,risk,4059,"ne response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government l",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4089,security,risk,risk,4089,"hat decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4408,security,risk,risk,4408,"r risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4897,security,soc,society,4897,"tors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5049,security,govern,government,5049,"D-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5102,security,soc,society,5102,"OVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5329,security,risk,risk,5329,"the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5388,security,risk,risk,5388,"cles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple s",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5624,security,compl,complexity,5624,"D-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5696,security,risk,risk,5696,"e case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5730,security,compl,complications,5730," the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5818,security,risk,risk,5818,"talizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6192,security,risk,risk,6192,"dividuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_roo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6274,security,risk,risk,6274," as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f,",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6600,security,govern,government,6600,"idity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__v",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6636,security,risk,risk,6636,"some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__ve",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6656,security,soc,society,6656," patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:6794,security,risk,risk,6794,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7005,security,preven,prevent,7005,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7499,security,compl,complete,7499,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4335,testability,Unit,United,4335,"tself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk shou",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:84,usability,input,input,84,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:132,usability,behavi,behavior,132,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:497,usability,input,input,497,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:821,usability,minim,minimal,821,"Inconsistent NER results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1013,usability,guid,guide,1013," results; **Describe the bug**. Inconsistent NER results with large input. **To Reproduce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascul",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1096,usability,intuit,intuitive,1096,"duce**. Steps to reproduce the behavior:. Run the following script:. ```. import spacy. from scispacy.linking import EntityLinker. spacy.util.fix_random_seed(42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1254,usability,consist,consisting,1254,"42). lang_model = ""en_core_sci_sm"". # Feel free to try the following model. #lang_model = ""en_ner_bionlp13cg_md"". nlp = spacy.load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1381,usability,guidanc,guidance,1381,"load(lang_model). linker = EntityLinker(resolve_abbreviations=True, name=""umls""). nlp.add_pipe(linker). # Large input. text = ""Title: Rethinking high-risk groups in COVID-19\n\n\n\nHow do we protect our 'high-risk' patient populations? This was the dominant focus of our coronavirus disease 2019 (COVID-19) neurology departmental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transp",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1695,usability,intuit,intuitive-immunosuppression,1695,"ental meeting at the start of the epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or thos",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:1737,usability,person,person,1737,"he epidemic weeks ago, where a neurologist in his late 50s assured us we were at minimal danger from coronavirus, and our efforts should focus on protecting our high-risk patients. But do we know exactly who these 'high-risk' people are? Although there was limited data to guide them, our hospital, the CDC, 1 and various medical associations repeated the intuitive refrain that 'high risk' patients are the 'immunocompromised and elderly.'A hospital-wide high-risk patient working group was established early on, consisting of neuroimmunologists and other physicians across disciplines that care for immunocompromised individuals. Specific guidance for immunocompromised patients regarding COVID-19 was pushed out quickly. Appointments for immunocompromised patients were converted to virtual visits or deferred if possible, before appointments for other patients.The inclusion of immunocompromised patients in the 'high-risk population' for COVID-19 is intuitive-immunosuppression should make a person more likely to contract an infection and may prolong the disease course. However, the data thus far has not borne this out. Early analyses of large Chinese cohorts have identified risk factors such as older age, hypertension, chronic respiratory diseases, and cardiovascular diseases, but not immunosuppression, as risk factors for disease severity in COVID-19. 2 In addition, data on prior related coronavirus outbreaks in MERS 3 and SARS 4 did not show any evidence of increased risk of infection or morbidity in immunocompromised populations.With the current outbreak, reports of 2 heart transplant recipients 5 and the first renal transplant recipient 6 with COVID-19 infection showed a clinical course, recovery, and laboratory profile similar to that of immunocompetent patients. A pediatric liver transplant center in Italy reported no significant pulmonary disease from COVID-19 amongst their patients with autoimmune liver disease, on chemotherapy, or those who were post-transplant. 7 A",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4029,usability,person,person,4029,"ncer patients. 9,10 Indeed, one response raised the point that decreased access to quality medical care, rather than the virus itself, is the primary danger facing cancer patients in the current pandemic. 10 No data exists regarding other transplant, rheumatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:4281,usability,confirm,confirmed,4281,"umatologic or neuroimmunological conditions, which itself prompts the question of whether these patients are indeed at higher risk than the general population.Not only has evidence that immunosuppression causes increased risk in COVID-19 been lacking, there is also a theoretical argument that immunosuppression may be therapeutic. A hyperinflammatory response to COVID-19 may cause a cytokine storm syndrome, driving severe and deadly cases of COVID-19. 11 Clinical investigations into the utility of various immunosuppressive agents in COVID-19, including tocilizumab (an IL-6 inhibitor), Janus kinus (JAK) inhibitors, and others are ongoing. 12 Instead of focusing on immunosuppression, we need to re-consider who qualifies as an 'elderly' person in regards to COVID-19 risk. Advanced older age as a risk factor for COVID-19 infection and death has been well substantiated. Over 1 out of 5 patients in Italy over the age of 80 succumbed to the disease, 13 and according to the CDC, 31-70% of confirmed COVID-19 patients over the age of 85 in the United States require hospitalization. 1 Lay press articles paint the at risk elderly as 'our grandparents,' 'nursing home residents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulner",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:5460,usability,learn,learn,5460,"ents,' or 'retirees.' And yet, while the very elderly in their 80s are most severely affected by the disease, the median age of hospitalized patients with severe COVID-19 in a large retrospective study in China was only 52 years. 14 The case fatality rate for individuals in the 60-69 age group was an unreassuring 3.5% in Italy and 3.6% in China, and hospitalizations in this age group are extremely common. 13 Morbidity may peak in society's oldest members, but anyone older than 50 is far from safe, and many in this group represent our health care workers, grocery store employees, government leaders, caregivers, and other members of society serving essential functions in the midst of this crisis. Unlike immunocompromised individuals, average adults in their 50s or 60s may never have thought of themselves as vulnerable; thus, messaging about their elevated risk should be targeted and unambiguous.The data regarding risk factors for poor outcomes in COVID-19 is far from definitive-as we learn more about this disease, we may find that certain cancers, neuroimmunologic conditions, or immunosuppressive agents do indeed increase morbidity. The medical complexity of some immunocompromised patients may itself lead to higher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regim",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/404:7304,usability,behavi,behavior,7304,"igher risk for nosocomial infections or complications related to hospitalization. Those in their 80s and 90s are at the highest risk from this infection, and we must do everything we can to protect them. However, as health professionals focus on 'immunocompromised and elderly' patients in our public health messaging, we send an implicit message, that others have made explicit, that those outside of these groups are safer. Paradoxically, the physician in his late 50s speaking about protecting high-risk immunocompromised patients at our hospital meeting, may himself be at higher risk than many of the immunocompromised patients he seeks to protect. These issues are consequential-some multiple sclerosis patients are considering delays in their immunosuppressive regimens due to the pandemic, older healthcare workers are coming out of retirement to work on the frontlines, and there is ongoing debate in government about the who will be at risk when we reopen society. It is time to urgently begin the discussion within the medical community on how to target accurate messaging to those at highest risk."". result = nlp(text). medical_entities = result.ents. # Dump the result for later inspection. output = collections.defaultdict(int). output_root = ""./"" # change it to output dir. suffix = 1 # change it to prevent overwritting. import collections. import json. for item in medical_entities:. for umls_ent in item._.kb_ents:. cui, score = umls_ent. output[cui] += 1. with open(osp.join(output_root, f""output_{suffix}.json""), 'w') as f:. json.dump(results[f""attm_{iter_num}""], f, indent=2). ```. **Expected behavior**. I expected running the following script multiple times would have the same result, but the output were inconsistent (different cui and different count for cui). **Environment (please complete the following information):**. - OS: Ubuntu 16.04.7 LTS. - Package version. ```. >>> scispacy.__version__. '0.3.0'. >>> spacy.__version__. '2.3.5'. ```. - Python verions: python:3.6.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/404
https://github.com/allenai/scispacy/issues/405:536,deployability,Version,Version,536,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:331,energy efficiency,load,load,331,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:536,integrability,Version,Version,536,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:536,modifiability,Version,Version,536,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:331,performance,load,load,331,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:182,reliability,doe,doesn,182,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:474,safety,compl,complete,474,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:474,security,compl,complete,474,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/405:258,usability,behavi,behavior,258,"Can't find factory for 'scispacy_linker' for language English; **Describe the bug**. `ValueError: [E002] Can't find factory for 'scispacy_linker' for language English` occurs if one doesn't import `scispacy.linking`. **To Reproduce**. Steps to reproduce the behavior:. ```. import spacy. lang_model = ""en_core_sci_sm"". nlp = spacy.load(lang_model). nlp.add_pipe(""scispacy_linker"",. config={""resolve_abbreviations"": True,. ""linker_name"": ""umls""}). ```. **Environment (please complete the following information):**. - OS: Ubuntu 16.04. - Version:. ```. >>> scispacy.__version__. '0.4.0'. >>> spacy.__version__. '3.0.7'. ```. - Python: `python3.6`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/405
https://github.com/allenai/scispacy/issues/406:22,reliability,doe,doesn,22,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:58,reliability,doe,doesn,58,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:13,safety,detect,detector,13,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:89,safety,input,input,89,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:345,safety,input,input,345,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:13,security,detect,detector,13,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:89,usability,input,input,89,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:146,usability,progress,progressive,146,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:345,usability,input,input,345,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/406:425,usability,progress,progressive,425,"Abbreviation detector doesn't work properly; Abbreviation doesn't happen properly if the input is as follows in scispacy. > (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males. It works as expected if the input is as follows. > Spinal and bulbar muscular atrophy (SBMA) is a gradually progressive neuromuscular disorder in which degeneration of lower motor neurons results in muscle weakness, muscle atrophy, and fasciculations. SBMA occurs only in males.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/406
https://github.com/allenai/scispacy/issues/407:69,deployability,pipelin,pipeline,69,"Is scispacy Entity_linker based on spacy's Entity Linker in terms of pipeline development; Hello, Thank you for amazing work dear Scispacy contributors. My question is simple, I want to know whether scispacy entity linker is based on the https://github.com/explosion/projects/tree/v3/tutorials/nel_emerson authored by Sofie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/407
https://github.com/allenai/scispacy/issues/407:69,integrability,pipelin,pipeline,69,"Is scispacy Entity_linker based on spacy's Entity Linker in terms of pipeline development; Hello, Thank you for amazing work dear Scispacy contributors. My question is simple, I want to know whether scispacy entity linker is based on the https://github.com/explosion/projects/tree/v3/tutorials/nel_emerson authored by Sofie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/407
https://github.com/allenai/scispacy/issues/407:306,security,auth,authored,306,"Is scispacy Entity_linker based on spacy's Entity Linker in terms of pipeline development; Hello, Thank you for amazing work dear Scispacy contributors. My question is simple, I want to know whether scispacy entity linker is based on the https://github.com/explosion/projects/tree/v3/tutorials/nel_emerson authored by Sofie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/407
https://github.com/allenai/scispacy/issues/407:168,testability,simpl,simple,168,"Is scispacy Entity_linker based on spacy's Entity Linker in terms of pipeline development; Hello, Thank you for amazing work dear Scispacy contributors. My question is simple, I want to know whether scispacy entity linker is based on the https://github.com/explosion/projects/tree/v3/tutorials/nel_emerson authored by Sofie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/407
https://github.com/allenai/scispacy/issues/407:168,usability,simpl,simple,168,"Is scispacy Entity_linker based on spacy's Entity Linker in terms of pipeline development; Hello, Thank you for amazing work dear Scispacy contributors. My question is simple, I want to know whether scispacy entity linker is based on the https://github.com/explosion/projects/tree/v3/tutorials/nel_emerson authored by Sofie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/407
https://github.com/allenai/scispacy/issues/409:791,availability,error,error,791,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:923,energy efficiency,cloud,cloudpickle,923,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:1003,energy efficiency,cloud,cloudpickle,1003,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:1109,energy efficiency,cloud,cloudpickle,1109,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:324,integrability,sub,sub,324,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:371,integrability,sub,sub,371,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:421,integrability,sub,sub,421,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:791,performance,error,error,791,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:791,safety,error,error,791,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:804,testability,Trace,Traceback,804,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/409:791,usability,error,error,791,"Usage of entity_linker with pyspark on databricks; I am trying to use entity_linker with pyspark and wanted to register it as an UDF function, with the following . ```. from pyspark.sql.types import ArrayType, FloatType, StringType. import spacy. def getUmls(text):. html = markdown(text). # remove code snippets. html = re.sub(r'<pre>(.*?)</pre>', ' ', html). html = re.sub(r'<code>(.*?)</code >', ' ', html). html = re.sub(r'(.)\1{5,}', ' ', html). # extract text. soup = BeautifulSoup(html, ""html.parser""). text1 = ' '.join(soup.findAll(text=True)). text1 = "" "".join(text1.split()). doc=nlp_sci(text1). umls=[ent_id for ent in linker(doc).ents for ent_id, score in ent._.umls_ents]. return umls. spark.udf.register(""getUmls"", getUmls, ArrayType(StringType())). ```. Getting the following error:. ```. Traceback (most recent call last):. File ""/databricks/spark/python/pyspark/serializers.py"", line 476, in dumps. return cloudpickle.dumps(obj, pickle_protocol). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 72, in dumps. cp.dump(obj). File ""/databricks/spark/python/pyspark/cloudpickle/cloudpickle_fast.py"", line 540, in dump. return Pickler.dump(self, obj). TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. PicklingError: Could not serialize object: TypeError: cannot pickle 'nmslib.dist.FloatIndex' object. ```. Is the work around for such issue",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/409
https://github.com/allenai/scispacy/issues/410:93,modifiability,pac,package,93,"How to solve duplicate abbreviation situation ; Hi,. First of all, thanks for developing the package and the wonderful features. I wanted to ask about how you would solve the problem of duplicate abbreviations. This happens in bio field, although an example that I can think of is. ``` Mindful memoization (MM) ```. In this case, the abbreviationDetector would trace this as. ``` memoization (long form): MM (short form) ```. instead of ""mindful memoization"" as the long form. AFAIK, this is because the detector detects purely the short form letters' occurence. Are there any endeavors to tackle this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/410
https://github.com/allenai/scispacy/issues/410:504,safety,detect,detector,504,"How to solve duplicate abbreviation situation ; Hi,. First of all, thanks for developing the package and the wonderful features. I wanted to ask about how you would solve the problem of duplicate abbreviations. This happens in bio field, although an example that I can think of is. ``` Mindful memoization (MM) ```. In this case, the abbreviationDetector would trace this as. ``` memoization (long form): MM (short form) ```. instead of ""mindful memoization"" as the long form. AFAIK, this is because the detector detects purely the short form letters' occurence. Are there any endeavors to tackle this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/410
https://github.com/allenai/scispacy/issues/410:513,safety,detect,detects,513,"How to solve duplicate abbreviation situation ; Hi,. First of all, thanks for developing the package and the wonderful features. I wanted to ask about how you would solve the problem of duplicate abbreviations. This happens in bio field, although an example that I can think of is. ``` Mindful memoization (MM) ```. In this case, the abbreviationDetector would trace this as. ``` memoization (long form): MM (short form) ```. instead of ""mindful memoization"" as the long form. AFAIK, this is because the detector detects purely the short form letters' occurence. Are there any endeavors to tackle this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/410
https://github.com/allenai/scispacy/issues/410:504,security,detect,detector,504,"How to solve duplicate abbreviation situation ; Hi,. First of all, thanks for developing the package and the wonderful features. I wanted to ask about how you would solve the problem of duplicate abbreviations. This happens in bio field, although an example that I can think of is. ``` Mindful memoization (MM) ```. In this case, the abbreviationDetector would trace this as. ``` memoization (long form): MM (short form) ```. instead of ""mindful memoization"" as the long form. AFAIK, this is because the detector detects purely the short form letters' occurence. Are there any endeavors to tackle this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/410
https://github.com/allenai/scispacy/issues/410:513,security,detect,detects,513,"How to solve duplicate abbreviation situation ; Hi,. First of all, thanks for developing the package and the wonderful features. I wanted to ask about how you would solve the problem of duplicate abbreviations. This happens in bio field, although an example that I can think of is. ``` Mindful memoization (MM) ```. In this case, the abbreviationDetector would trace this as. ``` memoization (long form): MM (short form) ```. instead of ""mindful memoization"" as the long form. AFAIK, this is because the detector detects purely the short form letters' occurence. Are there any endeavors to tackle this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/410
https://github.com/allenai/scispacy/issues/410:361,testability,trace,trace,361,"How to solve duplicate abbreviation situation ; Hi,. First of all, thanks for developing the package and the wonderful features. I wanted to ask about how you would solve the problem of duplicate abbreviations. This happens in bio field, although an example that I can think of is. ``` Mindful memoization (MM) ```. In this case, the abbreviationDetector would trace this as. ``` memoization (long form): MM (short form) ```. instead of ""mindful memoization"" as the long form. AFAIK, this is because the detector detects purely the short form letters' occurence. Are there any endeavors to tackle this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/410
https://github.com/allenai/scispacy/pull/411:0,deployability,Updat,Update,0,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:13,deployability,depend,dependency,13,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:24,deployability,version,version,24,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:59,deployability,releas,release,59,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:130,energy efficiency,current,currently,130,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:13,integrability,depend,dependency,13,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:24,integrability,version,version,24,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:96,interoperability,compatib,compatible,96,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:13,modifiability,depend,dependency,13,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:24,modifiability,version,version,24,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:0,safety,Updat,Update,0,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:13,safety,depend,dependency,13,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:159,safety,test,tests,159,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:0,security,Updat,Update,0,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:13,testability,depend,dependency,13,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/pull/411:159,testability,test,tests,159,Update spacy dependency version; If we can get this done + release then scispacy=0.5.0 would be compatible with medspacy which it currently is not. Passes all tests so there shouldn't be any issues,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/411
https://github.com/allenai/scispacy/issues/412:0,availability,ERROR,ERROR,0,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:15,availability,error,errored,15,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:60,availability,error,error,60,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:106,availability,error,error,106,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:143,availability,error,error,143,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:197,availability,error,error,197,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:247,availability,error,error,247,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:267,availability,error,error,267,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:409,availability,error,error,409,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:593,availability,ERROR,ERROR,593,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:852,availability,ERROR,ERROR,852,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:867,availability,error,errored,867,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:508,deployability,fail,failed,508,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:600,deployability,Fail,Failed,600,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:607,deployability,build,building,607,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:669,deployability,Fail,Failed,669,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:679,deployability,build,build,679,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:693,deployability,Instal,Installing,693,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:767,deployability,instal,install,767,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:351,interoperability,convers,conversion,351,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:714,modifiability,pac,packages,714,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:0,performance,ERROR,ERROR,0,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:15,performance,error,errored,15,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:60,performance,error,error,60,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:106,performance,error,error,106,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:143,performance,error,error,143,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:197,performance,error,error,197,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:247,performance,error,error,247,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:267,performance,error,error,267,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:409,performance,error,error,409,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:593,performance,ERROR,ERROR,593,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:852,performance,ERROR,ERROR,852,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:867,performance,error,errored,867,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:508,reliability,fail,failed,508,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:600,reliability,Fail,Failed,600,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:669,reliability,Fail,Failed,669,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:0,safety,ERROR,ERROR,0,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:15,safety,error,errored,15,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:60,safety,error,error,60,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:106,safety,error,error,106,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:143,safety,error,error,143,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:197,safety,error,error,197,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:247,safety,error,error,247,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:267,safety,error,error,267,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:409,safety,error,error,409,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:593,safety,ERROR,ERROR,593,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:852,safety,ERROR,ERROR,852,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:867,safety,error,errored,867,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:395,security,loss,loss,395,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:0,usability,ERROR,ERROR,0,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:7,usability,Command,Command,7,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:15,usability,error,errored,15,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:37,usability,statu,status,37,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:60,usability,error,error,60,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:106,usability,error,error,106,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:143,usability,error,error,143,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:197,usability,error,error,197,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:247,usability,error,error,247,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:267,usability,error,error,267,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:409,usability,error,error,409,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:416,usability,command,command,416,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:460,usability,Visual,Visual,460,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:593,usability,ERROR,ERROR,593,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:852,usability,ERROR,ERROR,852,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:859,usability,Command,Command,859,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:867,usability,error,errored,867,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/412:889,usability,statu,status,889,"ERROR: Command errored out with exit status 1; # Getting an error on Windows 10 with venv py 3.9. partial error list:. ```cml. nmslib.cc(454): error C2017: illegal escape sequence. nmslib.cc(454): error C2001: newline in constant. nmslib.cc(459): error C2059: syntax error: 'pybind11::enum_<similarity::DistType>'. nmslib.cc(730): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data. error: command 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\x86_amd64\\cl.exe' failed with exit code 2. ----------------------------------------------------------. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scispacy. Running setup.py install for nmslib ... /. ---------------------------------------------------------. ERROR: Command errored out with exit status 1: .... ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/412
https://github.com/allenai/scispacy/issues/413:4,availability,error,error,4,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/413:96,availability,error,error,96,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/413:4,performance,error,error,4,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/413:96,performance,error,error,96,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/413:4,safety,error,error,4,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/413:96,safety,error,error,96,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/413:4,usability,error,error,4,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/413:96,usability,error,error,96,"Re: error using the static vectors in Entity Linking example; RuntimeError: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False. ANy idea how to solve this issue?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/413
https://github.com/allenai/scispacy/issues/414:104,deployability,version,version,104,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:168,deployability,version,version,168,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:176,deployability,instal,installed,176,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:259,deployability,instal,install,259,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:289,deployability,instal,install,289,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:764,deployability,modul,module,764,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:937,deployability,modul,module,937,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:850,energy efficiency,load,load,850,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:104,integrability,version,version,104,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:168,integrability,version,version,168,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:104,modifiability,version,version,104,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:168,modifiability,version,version,168,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:764,modifiability,modul,module,764,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:904,modifiability,pac,packages,904,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:937,modifiability,modul,module,937,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:298,performance,content,content,298,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:617,performance,memor,memory,617,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:850,performance,load,load,850,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:737,safety,input,input-,737,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:764,safety,modul,module,764,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:937,safety,modul,module,937,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:693,testability,Trace,Traceback,693,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:617,usability,memor,memory,617,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/414:737,usability,input,input-,737,"AttributeError: type object 'Language' has no attribute 'factory'; Using Google Colab. Using the latest version of `scispacy` due to some other issues with the default version installed via pip (0.2.x). Attempting to use `en_core_sci_sm-0.4.0`. ```bash. !pip install scispacy==0.4.0. !pip install /content/gdrive/MyDrive/scispacy/en_core_sci_sm-0.4.0/. ```. Attempting to run the entity linker example code:. ```python. import spacy. import scispacy. from scispacy.linking import EntityLinker. ```. I thought this was working previously. I was using `lg` instead of `sm` and then I switched to `sm` partly to explore memory in regard to UMLS. Now this is appearing:. ```python. AttributeError Traceback (most recent call last). <ipython-input-20-200d08a76362> in <module>(). 9 . ---> 10 from scispacy.linking import EntityLinker. 11 . 12 nlp = spacy.load(""en_core_sci_sm""). /usr/local/lib/python3.7/dist-packages/scispacy/linking.py in <module>(). 6 . 7 . ----> 8 @Language.factory(""scispacy_linker""). 9 class EntityLinker:. 10 """""". AttributeError: type object 'Language' has no attribute 'factory'. ```. Any ideas?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/414
https://github.com/allenai/scispacy/issues/415:84,availability,down,downloads,84,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:367,availability,down,downloading,367,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:636,availability,down,download,636,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:38,performance,cach,cache,38,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:495,performance,cach,cache,495,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:31,security,modif,modify,31,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:222,usability,user,users,222,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:306,usability,clear,cleared,306,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:331,usability,clear,cleared,331,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:479,usability,user,user,479,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/415:521,usability,user,users,521,"Enhancement: Provide option to modify cache folder for entity linker knowledge base downloads; https://github.com/allenai/scispacy/blob/2290a80cfe0948e48d8ecfbd60064019d57a6874/scispacy/file_cache.py#L16. For Google Colab users, the `Path.home()` location is `/root/`, which is deleted when the runtime is cleared. As runtimes are cleared fairly often, this means re-downloading the KBs. Perhaps there is a way to alter `Path.home` from `pathlib`? Another option is to allow the user to enter a cache folder, which Colab users could set to their Google Drive (fwiw just a regular folder as seen by python within Colab), thus making the download permanent.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/415
https://github.com/allenai/scispacy/issues/416:18,availability,replic,replicate,18,"How would someone replicate scispacy vectors?; https://github.com/allenai/scispacy/blob/main/docs/index.md. Talks about the datasources used but im not entirely clear on how exactly the vector tables were trained for, say, en_core_sci_md vs en_core_sci_lg. . I didn't seem to find anything in the original scispacy paper either. What specific algorithms/libraries were used, etc?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/416
https://github.com/allenai/scispacy/issues/416:334,interoperability,specif,specific,334,"How would someone replicate scispacy vectors?; https://github.com/allenai/scispacy/blob/main/docs/index.md. Talks about the datasources used but im not entirely clear on how exactly the vector tables were trained for, say, en_core_sci_md vs en_core_sci_lg. . I didn't seem to find anything in the original scispacy paper either. What specific algorithms/libraries were used, etc?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/416
https://github.com/allenai/scispacy/issues/416:161,usability,clear,clear,161,"How would someone replicate scispacy vectors?; https://github.com/allenai/scispacy/blob/main/docs/index.md. Talks about the datasources used but im not entirely clear on how exactly the vector tables were trained for, say, en_core_sci_md vs en_core_sci_lg. . I didn't seem to find anything in the original scispacy paper either. What specific algorithms/libraries were used, etc?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/416
https://github.com/allenai/scispacy/issues/417:133,availability,error,error,133,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:141,availability,ERROR,ERROR,141,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:57,deployability,instal,installing,57,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:154,deployability,depend,dependency,154,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:237,deployability,instal,installed,237,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:294,deployability,depend,dependency,294,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:426,deployability,updat,update,426,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:183,energy efficiency,current,currently,183,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:154,integrability,depend,dependency,154,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:294,integrability,depend,dependency,294,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:305,interoperability,conflict,conflicts,305,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:386,interoperability,incompatib,incompatible,386,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:154,modifiability,depend,dependency,154,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:219,modifiability,pac,packages,219,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:294,modifiability,depend,dependency,294,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:133,performance,error,error,133,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:141,performance,ERROR,ERROR,141,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:174,reliability,doe,does,174,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:133,safety,error,error,133,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:141,safety,ERROR,ERROR,141,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:154,safety,depend,dependency,154,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:294,safety,depend,dependency,294,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:426,safety,updat,update,426,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:426,security,updat,update,426,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:154,testability,depend,dependency,154,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:294,testability,depend,dependency,294,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:441,testability,plan,plans,441,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:0,usability,Support,Support,0,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:133,usability,error,error,133,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:141,usability,ERROR,ERROR,141,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:253,usability,behavi,behaviour,253,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/417:450,usability,support,support,450,"Support for Python 3.9 and Spacy 3.2.2; Dear all, . When installing scispacy in python 3.9 and using spacy 3.2.2 I get the following error . ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. black 22.1.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible. Can you please provide an update on your plans to support python 3.9 and spacy 3.2.2? . Thanks. Achilleas Voutsas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/417
https://github.com/allenai/scispacy/issues/418:216,availability,error,error,216,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/418:216,performance,error,error,216,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/418:216,safety,error,error,216,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/418:76,security,token,tokens,76,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/418:189,security,token,tokens,189,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/418:230,security,token,tokens,230,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/418:292,security,token,tokens,292,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/418:216,usability,error,error,216,"Replacing Abbreviations with the long form; Hi I am trying to go through my tokens and replace abbreviations like cvd, with cardiovascular disease, etc. However whenever I go to replace my tokens I get the following error. 'spacy.tokens.doc.Doc' object has no attribute 'append'. or . 'spacy.tokens.doc.Doc' object has no attribute 'replace'.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/418
https://github.com/allenai/scispacy/issues/419:262,availability,down,download,262,AWS permissions; As noted in #382 and #386 permissions appear a bit wonky here - getting a request for creds on `med_mentions.tar.gz` which is fine since that can be sourced directly from the [source](https://github.com/chanzuckerberg/MedMentions) but the final download command is also bombing on credentials `aws s3 cp ${vars.ner_loc_s3} assets --recursive --exclude '*' --include '*.tsv'`.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/419
https://github.com/allenai/scispacy/issues/419:4,safety,permiss,permissions,4,AWS permissions; As noted in #382 and #386 permissions appear a bit wonky here - getting a request for creds on `med_mentions.tar.gz` which is fine since that can be sourced directly from the [source](https://github.com/chanzuckerberg/MedMentions) but the final download command is also bombing on credentials `aws s3 cp ${vars.ner_loc_s3} assets --recursive --exclude '*' --include '*.tsv'`.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/419
https://github.com/allenai/scispacy/issues/419:43,safety,permiss,permissions,43,AWS permissions; As noted in #382 and #386 permissions appear a bit wonky here - getting a request for creds on `med_mentions.tar.gz` which is fine since that can be sourced directly from the [source](https://github.com/chanzuckerberg/MedMentions) but the final download command is also bombing on credentials `aws s3 cp ${vars.ner_loc_s3} assets --recursive --exclude '*' --include '*.tsv'`.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/419
https://github.com/allenai/scispacy/issues/419:271,usability,command,command,271,AWS permissions; As noted in #382 and #386 permissions appear a bit wonky here - getting a request for creds on `med_mentions.tar.gz` which is fine since that can be sourced directly from the [source](https://github.com/chanzuckerberg/MedMentions) but the final download command is also bombing on credentials `aws s3 cp ${vars.ner_loc_s3} assets --recursive --exclude '*' --include '*.tsv'`.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/419
https://github.com/allenai/scispacy/pull/420:10,availability,down,download,10,Correct a download issue related to s3 auth; add --no-sign-request to med_mentions and core assets,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/420
https://github.com/allenai/scispacy/pull/420:87,energy efficiency,core,core,87,Correct a download issue related to s3 auth; add --no-sign-request to med_mentions and core assets,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/420
https://github.com/allenai/scispacy/pull/420:39,security,auth,auth,39,Correct a download issue related to s3 auth; add --no-sign-request to med_mentions and core assets,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/420
https://github.com/allenai/scispacy/pull/420:54,security,sign,sign-request,54,Correct a download issue related to s3 auth; add --no-sign-request to med_mentions and core assets,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/420
https://github.com/allenai/scispacy/issues/421:259,availability,replic,replicated,259,any guidance on ontonotes prep?; Since ontonotes requires direct licensing from source are there any pointers or scripts to prep for how to convert the corpus format over to the expected train / dev / test splits so that `ud_ontonotes.tar.gz` can be properly replicated locally?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/421
https://github.com/allenai/scispacy/issues/421:159,interoperability,format,format,159,any guidance on ontonotes prep?; Since ontonotes requires direct licensing from source are there any pointers or scripts to prep for how to convert the corpus format over to the expected train / dev / test splits so that `ud_ontonotes.tar.gz` can be properly replicated locally?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/421
https://github.com/allenai/scispacy/issues/421:201,safety,test,test,201,any guidance on ontonotes prep?; Since ontonotes requires direct licensing from source are there any pointers or scripts to prep for how to convert the corpus format over to the expected train / dev / test splits so that `ud_ontonotes.tar.gz` can be properly replicated locally?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/421
https://github.com/allenai/scispacy/issues/421:201,testability,test,test,201,any guidance on ontonotes prep?; Since ontonotes requires direct licensing from source are there any pointers or scripts to prep for how to convert the corpus format over to the expected train / dev / test splits so that `ud_ontonotes.tar.gz` can be properly replicated locally?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/421
https://github.com/allenai/scispacy/issues/421:4,usability,guidanc,guidance,4,any guidance on ontonotes prep?; Since ontonotes requires direct licensing from source are there any pointers or scripts to prep for how to convert the corpus format over to the expected train / dev / test splits so that `ud_ontonotes.tar.gz` can be properly replicated locally?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/421
https://github.com/allenai/scispacy/pull/422:10,deployability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/422
https://github.com/allenai/scispacy/pull/422:10,integrability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/422
https://github.com/allenai/scispacy/pull/422:28,interoperability,compatib,compatibility,28,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/422
https://github.com/allenai/scispacy/pull/422:10,modifiability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/422
https://github.com/allenai/scispacy/pull/422:10,safety,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/422
https://github.com/allenai/scispacy/pull/422:10,testability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/422
https://github.com/allenai/scispacy/pull/423:10,deployability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/423
https://github.com/allenai/scispacy/pull/423:10,integrability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/423
https://github.com/allenai/scispacy/pull/423:28,interoperability,compatib,compatibility,28,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/423
https://github.com/allenai/scispacy/pull/423:10,modifiability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/423
https://github.com/allenai/scispacy/pull/423:10,safety,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/423
https://github.com/allenai/scispacy/pull/423:10,testability,depend,dependency,10,Pin black dependency due to compatibility issue between click (from b; lack) and typer (from spacy),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/423
https://github.com/allenai/scispacy/issues/424:160,deployability,upgrad,upgrade,160,"Compatibility with Apple Silicon; While Spacy v3.2 is made native in Apple Silicon, scispacy requires Spacy v3.0 which is not optimised. . Is there any plan to upgrade Scispacy to make it compatible with Spacy v3.2?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/424
https://github.com/allenai/scispacy/issues/424:126,energy efficiency,optim,optimised,126,"Compatibility with Apple Silicon; While Spacy v3.2 is made native in Apple Silicon, scispacy requires Spacy v3.0 which is not optimised. . Is there any plan to upgrade Scispacy to make it compatible with Spacy v3.2?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/424
https://github.com/allenai/scispacy/issues/424:0,interoperability,Compatib,Compatibility,0,"Compatibility with Apple Silicon; While Spacy v3.2 is made native in Apple Silicon, scispacy requires Spacy v3.0 which is not optimised. . Is there any plan to upgrade Scispacy to make it compatible with Spacy v3.2?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/424
https://github.com/allenai/scispacy/issues/424:188,interoperability,compatib,compatible,188,"Compatibility with Apple Silicon; While Spacy v3.2 is made native in Apple Silicon, scispacy requires Spacy v3.0 which is not optimised. . Is there any plan to upgrade Scispacy to make it compatible with Spacy v3.2?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/424
https://github.com/allenai/scispacy/issues/424:160,modifiability,upgrad,upgrade,160,"Compatibility with Apple Silicon; While Spacy v3.2 is made native in Apple Silicon, scispacy requires Spacy v3.0 which is not optimised. . Is there any plan to upgrade Scispacy to make it compatible with Spacy v3.2?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/424
https://github.com/allenai/scispacy/issues/424:152,testability,plan,plan,152,"Compatibility with Apple Silicon; While Spacy v3.2 is made native in Apple Silicon, scispacy requires Spacy v3.0 which is not optimised. . Is there any plan to upgrade Scispacy to make it compatible with Spacy v3.2?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/424
https://github.com/allenai/scispacy/pull/425:9,deployability,upgrad,upgrade,9,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:51,deployability,updat,update,51,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:85,deployability,updat,update,85,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:158,deployability,updat,update,158,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:235,deployability,releas,release,235,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:38,energy efficiency,model,model,38,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:137,energy efficiency,model,models,137,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:165,energy efficiency,model,models,165,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:9,modifiability,upgrad,upgrade,9,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:51,safety,updat,update,51,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:85,safety,updat,update,85,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:158,safety,updat,update,158,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:175,safety,test,test,175,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:38,security,model,model,38,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:51,security,updat,update,51,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:85,security,updat,update,85,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:137,security,model,models,137,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:158,security,updat,update,158,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:165,security,model,models,165,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:175,testability,test,test,175,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/pull/425:195,usability,confirm,confirm,195,Spacy 32 upgrade; - [x] train scibert model. - [x] update metrics in index.md. - [x] update all mentions of 0.4.0 to 0.5.0. - [x] upload models to aws. - [x] update models in test dockerfile and confirm CI passes afterwards. - [x] run release script (after merge),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/425
https://github.com/allenai/scispacy/issues/426:86,availability,error,error,86,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:185,availability,error,error,185,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:192,availability,error,error,192,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:222,availability,error,error,222,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:881,availability,error,error,881,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1067,availability,error,error,1067,"et this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1141,availability,ERROR,ERROR,1141,"Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1352,availability,error,error,1352,".6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1359,availability,error,error,1359,"'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1389,availability,error,error,1389," ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.m",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2272,availability,error,error,2272," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2458,availability,error,error,2458," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2532,availability,error,error,2532," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2554,availability,failur,failure,2554," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2577,availability,error,error,2577," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2730,availability,failur,failure,2730," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:0,deployability,Instal,Install,0,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:32,deployability,instal,installing,32,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:78,deployability,instal,install,78,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:96,deployability,Build,Building,96,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:144,deployability,Build,Building,144,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:326,deployability,Depend,Dependence,326,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:624,deployability,version,versions,624,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:738,deployability,build,build,738,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:852,deployability,build,building,852,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:965,deployability,Build,Build,965,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1025,deployability,build,build-tools,1025," installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1148,deployability,Fail,Failed,1148,"g wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1155,deployability,build,building,1155,"for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extr",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1217,deployability,Fail,Failed,1217,"h-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSI",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1227,deployability,build,build,1227," python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1241,deployability,Instal,Installing,1241," bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. bui",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1329,deployability,instal,install,1329,"nce list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1415,deployability,instal,install,1415,"""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-bui",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1502,deployability,Depend,Dependence,1502,"ages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1805,deployability,version,versions,1805," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1898,deployability,instal,install,1898," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1977,deployability,instal,install,1977," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2031,deployability,instal,install,2031," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2058,deployability,build,build,2058," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2129,deployability,build,build,2129," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2243,deployability,build,building,2243," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2356,deployability,Build,Build,2356," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2416,deployability,build,build-tools,2416," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2546,deployability,instal,install-failure,2546," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2599,deployability,instal,install,2599," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2730,deployability,fail,failure,2730," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:199,integrability,sub,subprocess-exited-with-error,199,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:326,integrability,Depend,Dependence,326,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:624,integrability,version,versions,624,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1091,integrability,sub,subprocess,1091,"Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-base",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1366,integrability,sub,subprocess-exited-with-error,1366,"1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://vi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1502,integrability,Depend,Dependence,1502,"ages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1805,integrability,version,versions,1805," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2482,integrability,sub,subprocess,2482," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2082,interoperability,standard,standards-based,2082," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:126,modifiability,pac,packages,126,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:326,modifiability,Depend,Dependence,326,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:503,modifiability,pac,packages,503,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:624,modifiability,version,versions,624,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:870,modifiability,extens,extension,870,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1262,modifiability,pac,packages,1262," run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' exten",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1502,modifiability,Depend,Dependence,1502,"ages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1684,modifiability,pac,packages,1684,"ead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1805,modifiability,version,versions,1805," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1949,modifiability,pac,packages,1949," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2261,modifiability,extens,extension,2261," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2607,modifiability,pac,package,2607," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2660,modifiability,pac,package,2660," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:86,performance,error,error,86,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:185,performance,error,error,185,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:192,performance,error,error,192,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:222,performance,error,error,222,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:881,performance,error,error,881,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1067,performance,error,error,1067,"et this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1141,performance,ERROR,ERROR,1141,"Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1352,performance,error,error,1352,".6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1359,performance,error,error,1359,"'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1389,performance,error,error,1389," ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.m",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2272,performance,error,error,2272," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2458,performance,error,error,2458," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2532,performance,error,error,2532," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2554,performance,failur,failure,2554," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2577,performance,error,error,2577," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2730,performance,failur,failure,2730," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1148,reliability,Fail,Failed,1148,"g wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_e",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1217,reliability,Fail,Failed,1217,"h-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSI",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2554,reliability,fail,failure,2554," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2730,reliability,fail,failure,2730," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:86,safety,error,error,86,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:185,safety,error,error,185,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:192,safety,error,error,192,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:222,safety,error,error,222,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:326,safety,Depend,Dependence,326,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:881,safety,error,error,881,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1067,safety,error,error,1067,"et this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1141,safety,ERROR,ERROR,1141,"Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1352,safety,error,error,1352,".6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1359,safety,error,error,1359,"'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1389,safety,error,error,1389," ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.m",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1502,safety,Depend,Dependence,1502,"ages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2272,safety,error,error,2272," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2458,safety,error,error,2458," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2532,safety,error,error,2532," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2577,safety,error,error,2577," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:326,testability,Depend,Dependence,326,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1502,testability,Depend,Dependence,1502,"ages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:86,usability,error,error,86,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:185,usability,error,error,185,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:192,usability,error,error,192,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:222,usability,error,error,222,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:464,usability,User,Users,464,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:536,usability,User,UserWarning,536,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:604,usability,support,supported,604,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:881,usability,error,error,881,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:898,usability,Visual,Visual,898,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:971,usability,Tool,Tools,971,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:987,usability,visual,visualstudio,987,"Install issue with nmslib; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: Setuptoo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1014,usability,visual,visual-cpp-build-tools,1014,"; When installing via pip or with the URL I get this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: set",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1067,usability,error,error,1067,"et this install error: . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1141,usability,ERROR,ERROR,1141,"Building wheel for nmslib (setup.py) ... error. error: subprocess-exited-with-error.  python setup.py bdist_wheel did not run successfully.  exit code: 1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1295,usability,learn,learn,1295,"1. > [9 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C+",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1352,usability,error,error,1352,".6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1359,usability,error,error,1359,"'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1389,usability,error,error,1389," ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.m",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1640,usability,User,Users,1640,"e the underscore name 'description_file' instead. warnings.warn(. running bdist_wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1717,usability,User,UserWarning,1717,"wheel. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output fr",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1785,usability,support,supported,1785," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1910,usability,User,Users,1910," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:1969,usability,command,command,1969," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2098,usability,tool,tools,2098," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2272,usability,error,error,2272," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2289,usability,Visual,Visual,2289," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2362,usability,Tool,Tools,2362," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2378,usability,visual,visualstudio,2378," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2405,usability,visual,visual-cpp-build-tools,2405," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2458,usability,error,error,2458," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2532,usability,error,error,2532," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2577,usability,error,error,2577," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2694,usability,hint,hint,2694," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/426:2745,usability,help,help,2745," compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for nmslib. Running setup.py clean for nmslib. Failed to build nmslib. Installing collected packages: nmslib, conllu, scikit-learn, scispacy. Running setup.py install for nmslib ... error. error: subprocess-exited-with-error.  Running setup.py install for nmslib did not run successfully.  exit code: 1. > [11 lines of output]. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. C:\Users\jklemisch\Anaconda3\envs\nlp\lib\site-packages\setuptools\dist.py:739: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. running install. C:\Users\****\Anaconda3\envs\nlp\lib\site-packages\setuptools\command\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools. warnings.warn(. running build. running build_ext. Extra compilation arguments: ['/EHsc', '/openmp', '/O2', '/DVERSION_INFO=\\""2.1.1\\""']. building 'nmslib' extension. error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/. [end of output]. note: This error originates from a subprocess, and is likely not a problem with pip. error: legacy-install-failure.  Encountered error while trying to install package. > nmslib. note: This is an issue with the package mentioned above, not pip. hint: See above for output from the failure.`. Any help would be appricated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/426
https://github.com/allenai/scispacy/issues/429:880,deployability,depend,dependencies,880,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1001,deployability,pipelin,pipelines,1001,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1529,deployability,integr,integrating,1529,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:880,integrability,depend,dependencies,880,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1001,integrability,pipelin,pipelines,1001,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1529,integrability,integr,integrating,1529,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1024,interoperability,ontolog,ontologies,1024,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1529,interoperability,integr,integrating,1529,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1628,interoperability,ontolog,ontologies,1628,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:414,modifiability,extens,extensions,414,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:880,modifiability,depend,dependencies,880,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1529,modifiability,integr,integrating,1529,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:795,performance,content,content,795,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:930,performance,execution time,execution time,930,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:980,performance,throughput,throughput,980,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1529,reliability,integr,integrating,1529,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:880,safety,depend,dependencies,880,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1085,safety,compl,complement,1085,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1358,safety,valid,validity,1358,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1085,security,compl,complement,1085,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1529,security,integr,integrating,1529,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:880,testability,depend,dependencies,880,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1529,testability,integr,integrating,1529,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1106,usability,support,supported,1106,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1203,usability,user,user-images,1203,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1558,usability,user,users,1558,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/429:1596,usability,support,support,1596,"Entity linking future directions; I was wondering if you all had any thoughts on developments in the python ecosystem for entity linking since the original 2019 ScispaCy paper. I see a number of comparisons in it to MetaMap, some of the early code on adding native entity linking (https://github.com/allenai/scispacy/pull/72, https://github.com/allenai/scispacy/pull/88), and then lots of more recent requests for extensions to linking like https://github.com/allenai/scispacy/issues/428, https://github.com/allenai/scispacy/issues/346, and https://github.com/allenai/scispacy/issues/331 which all got me curious as to whether or not you all are aware of or have potentially considered other methods/libraries for NEN. [Gilda](https://github.com/indralab/gilda) ([paper](https://www.biorxiv.org/content/10.1101/2021.09.10.459803v1)) is one we've been experimenting with since its dependencies are relatively light and its offline execution time is definitely good enough for high-throughput NER + NEN pipelines. The sources/ontologies covered by it include a number that make a useful complement to what's supported in ScispaCy:. <img width=""508"" alt=""Screen Shot 2022-04-14 at 7 23 03 PM"" src=""https://user-images.githubusercontent.com/6130352/163492718-019276cd-4a10-4ca7-812c-1d4229a102f0.png"">. I'm not really advocating for it, and I can't speak to the validity of the methodological differences between it and what you all have done, but I am curious if you all are watching other projects like this and considering either integrating them or pointing users at them if they are looking for support over more nomenclatures/ontologies. Thanks in advance for any insight here and for all the work you've done on this library!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/429
https://github.com/allenai/scispacy/issues/430:296,availability,error,error,296,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:527,availability,servic,service,527,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:555,availability,avail,available,555,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:173,deployability,releas,releases,173,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:228,deployability,instal,install,228,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:267,deployability,instal,install,267,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:315,deployability,fail,failed,315,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:527,deployability,servic,service,527,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:527,integrability,servic,service,527,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:527,modifiability,servic,service,527,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:296,performance,error,error,296,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:315,reliability,fail,failed,315,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:555,reliability,availab,available,555,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:296,safety,error,error,296,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:555,safety,avail,available,555,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:555,security,availab,available,555,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:78,usability,help,helpful,78,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:296,usability,error,error,296,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/430:650,usability,help,help,650,"HTTPSCOnnectionPool for s3=us-west-2.amazonaws.com; Hello. Thank you for this helpful library. I have a problem with :. **https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_bc5cdr_md-0.5.0.tar.gz**. I can install it on colab. but when I try to install it on my pc i get an error : . **upload failed: ./icon.jpg to s3://mybucket/myfolder/icon.jpg HTTPSConnectionPool(host='s3-us-west-1b.amazonaws.com', port=443): Max retries exceeded with url: /mybucket/myfolder/icon.jpg (Caused by : [Errno -2] Name or service not known)**. Other available zones such as ap-south-1a and ap-south-1b are not working on my pc. Could you please help me in this issue? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/430
https://github.com/allenai/scispacy/issues/431:104,availability,error,error,104,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:202,availability,error,error,202,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:209,availability,ERROR,ERROR,209,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:224,availability,error,errored,224,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4588,availability,error,error,4588,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4648,availability,error,error,4648,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4,deployability,instal,install,4,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:12,deployability,fail,failed,12,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:65,deployability,instal,install,65,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:113,deployability,Build,Building,113,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:161,deployability,Build,Building,161,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:457,deployability,instal,install-,457,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:604,deployability,instal,install-,604,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1092,deployability,instal,install-,1092,"llowing error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1180,deployability,Depend,Dependence,1180,"b (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/ho",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1503,deployability,version,versions,1503,"7eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1759,deployability,build,build,1759,"io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/includ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1765,deployability,depend,dependencies,1765,"IO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1807,deployability,build,build-requires,1807,"()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/bas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1868,deployability,build,build,1868,"""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r2549",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3080,deployability,version,version-min,3080,"esult -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/minifor",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3163,deployability,build,building,3163,"ototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Ca",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3201,deployability,build,build,3201,"iforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/p",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3217,deployability,build,build,3217,"/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-pa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3260,deployability,build,build,3260,"askroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Cas",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3314,deployability,build,build,3314,"I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-pack",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3375,deployability,build,build,3375,"on3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/ba",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3440,deployability,build,build,3440,"755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3511,deployability,build,build,3511,".o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-versi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4425,deployability,build,build,4425,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4509,deployability,version,version-min,4509,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4669,deployability,fail,failed,4669,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4328,energy efficiency,core,core,4328,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1180,integrability,Depend,Dependence,1180,"b (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/ho",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1503,integrability,version,versions,1503,"7eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1765,integrability,depend,dependencies,1765,"IO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3080,integrability,version,version-min,3080,"esult -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/minifor",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4509,integrability,version,version-min,4509,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:143,modifiability,pac,packages,143,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1180,modifiability,Depend,Dependence,1180,"b (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/ho",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1382,modifiability,pac,packages,1382,"0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1503,modifiability,version,versions,1503,"7eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1655,modifiability,pac,packages,1655,"3/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1765,modifiability,depend,dependencies,1765,"IO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3080,modifiability,version,version-min,3080,"esult -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/minifor",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3181,modifiability,extens,extension,3181,"ebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/ba",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3933,modifiability,pac,packages,3933,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4028,modifiability,pac,packages,4028,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4123,modifiability,pac,packages,4123,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4218,modifiability,pac,packages,4218,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4313,modifiability,pac,packages,4313,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4509,modifiability,version,version-min,4509,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:104,performance,error,error,104,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:202,performance,error,error,202,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:209,performance,ERROR,ERROR,209,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:224,performance,error,errored,224,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2177,performance,I/o,I/opt,2177,"Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib'",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2247,performance,I/o,I/opt,2247,"ython_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2317,performance,I/o,I/opt,2317,"homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2637,performance,I/o,I/opt,2637,"python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2707,performance,I/o,I/opt,2707,"ionWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/mini",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2777,performance,I/o,I/opt,2777,"ing PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/mini",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3682,performance,I/o,I/opt,3682,"/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3752,performance,I/o,I/opt,3752,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3865,performance,I/o,I/opt,3865,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3960,performance,I/o,I/opt,3960,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4055,performance,I/o,I/opt,4055,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4150,performance,I/o,I/opt,4150,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4245,performance,I/o,I/opt,4245,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4342,performance,I/o,I/opt,4342,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4588,performance,error,error,4588,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4648,performance,error,error,4648,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:12,reliability,fail,failed,12,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4614,reliability,doe,does,4614,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4669,reliability,fail,failed,4669,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:104,safety,error,error,104,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:202,safety,error,error,202,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:209,safety,ERROR,ERROR,209,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:224,safety,error,errored,224,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1151,safety,Compl,Complete,1151,"slib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1180,safety,Depend,Dependence,1180,"b (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/ho",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1765,safety,depend,dependencies,1765,"IO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4588,safety,error,error,4588,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4648,safety,error,error,4648,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:367,security,token,tokenize,367,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:687,security,token,tokenize,687,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1151,security,Compl,Complete,1151,"slib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1180,testability,Depend,Dependence,1180,"b (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/ho",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1765,testability,depend,dependencies,1765,"IO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:104,usability,error,error,104,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:202,usability,error,error,202,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:209,usability,ERROR,ERROR,209,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:216,usability,Command,Command,216,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:224,usability,error,errored,224,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:246,usability,statu,status,246,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:257,usability,command,command,257,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:879,usability,close,close,879,"pip install failed ; `mac m1, conda python3.8 . `when i use `pip install scispacy`, I got the following error . `Building wheels for collected packages: nmslib. Building wheel for nmslib (setup.py) ... error. ERROR: Command errored out with exit status 1:. command: /opt/homebrew/Caskroom/miniforge/base/envs/py38/bin/python3.8 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx7",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1415,usability,User,UserWarning,1415,"43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglx",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:1483,usability,support,supported,1483,"adce14a63b50c7353467eb783/setup.py'""'""'; __file__='""'""'/private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-wheel-2300yec8. cwd: /private/var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/pip-install-07kskzo0/nmslib_897a737adce14a63b50c7353467eb783/. Complete output (27 lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglx",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2165,usability,prototyp,prototypes,2165," lines):. Dependence list: ['pybind11<2.6.2', 'psutil', ""numpy>=1.10.0,<1.17 ; python_version=='2.7'"", ""numpy>=1.10.0 ; python_version>='3.5'""]. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/dist.py:717: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead. warnings.warn(. /opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. buildin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:2625,usability,prototyp,prototypes,2625,"/py38/lib/python3.8/site-packages/setuptools/__init__.py:148: SetuptoolsDeprecationWarning: setup_requires is deprecated. Supply build dependencies using PEP 517 pyproject.toml build-requires. warnings.warn(. running bdist_wheel. running build. running build_ext. creating var. creating var/folders. creating var/folders/1t. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn. creating var/folders/1t/j43r25490v10bltglxtx77_40000gn/T. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpn2z_755h.o -std=c++14. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:3670,usability,prototyp,prototypes,3670,"/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4588,usability,error,error,4588,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4623,usability,support,support,4623,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4648,usability,error,error,4648,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4655,usability,command,command,4655,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/431:4686,usability,statu,status,4686,"rch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c /var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.cpp -o var/folders/1t/j43r25490v10bltglxtx77_40000gn/T/tmpoea47_4d.o -fvisibility=hidden. Extra compilation arguments: ['-O3', '-march=native', '-stdlib=libc++', '-mmacosx-version-min=10.7', '-DVERSION_INFO=""2.1.1""', '-std=c++14', '-fvisibility=hidden']. building 'nmslib' extension. creating build. creating build/temp.macosx-11.0-arm64-3.8. creating build/temp.macosx-11.0-arm64-3.8/tensorflow. creating build/temp.macosx-11.0-arm64-3.8/similarity_search. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/space. creating build/temp.macosx-11.0-arm64-3.8/similarity_search/src/method. gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include -arch arm64 -I./similarity_search/include -Itensorflow -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/pybind11/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/lib/python3.8/site-packages/numpy/core/include -I/opt/homebrew/Caskroom/miniforge/base/envs/py38/include/python3.8 -c nmslib.cc -o build/temp.macosx-11.0-arm64-3.8/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=""2.1.1"" -std=c++14 -fvisibility=hidden. clang: error: the clang compiler does not support '-march=native'. error: command 'gcc' failed with exit status 1`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/431
https://github.com/allenai/scispacy/issues/432:126,availability,error,error,126,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:0,deployability,Instal,Installation,0,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:72,deployability,instal,installation,72,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:155,deployability,instal,installation,155,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:314,deployability,fail,failed,314,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:353,deployability,instal,install,353,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:126,performance,error,error,126,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:314,reliability,fail,failed,314,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:126,safety,error,error,126,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:126,usability,error,error,126,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:181,usability,command,command,181,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:225,usability,Visual,Visual,225,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/432:261,usability,Tool,Tools,261,Installation issue with Python 3.9; There seems to be an issue with the installation of scispacy on Python 3.9. The following error gets thrown during the installation process. . > command 'C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX86\\x64\\cl.exe' failed with exit code 2. I was able to install on Python 3.6 without any issues.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/432
https://github.com/allenai/scispacy/issues/433:372,interoperability,ontolog,ontology,372,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:59,performance,time,time,59,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:206,performance,time,time,206,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:893,performance,time,time,893,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:307,reliability,doe,doesn,307,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:354,safety,compl,complete,354,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:354,security,compl,complete,354,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:177,usability,help,help,177,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:781,usability,user,user-images,781,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/433:916,usability,help,help,916,"MeSH + OMIM entity linkers for a single piece of text at a time; Hi, . First of all, thankyou very much for all the hard work you've put in to make SciSpacy for us. I need some help with NEL; it's my first time using scispacy. I'm quite new to this, but what I know from my research is that the MeSH system doesn't have genetic diseases. Thats why any complete disease ontology that uses MeSH will also use OMIM. My question is: Is there any way to do this with scispacy? Like any way to use both systems for a piece of text so that what MeSH misses OMIM covers. They also have this thing in the NCBI dataset (disease annotated dataset), so for diseases that do not have any id in MeSH they have used the OMIM system for it. (see the image attached). ![Screenshot (75)](https://user-images.githubusercontent.com/84127491/166462649-9bbd3ab6-bd3e-46a9-b7b2-a7f7dcd6b668.png). Thanks for your time reading this. Any help is appreciated! :)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/433
https://github.com/allenai/scispacy/issues/434:48,performance,time,timeline,48,"Spacy >=3.3.0 ; Hi, was wondering if there is a timeline for supporting Spacy >=3.3.0? What pitfalls should i expect if i tried to manually modify the requirements to allow it? thank you.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/434
https://github.com/allenai/scispacy/issues/434:140,security,modif,modify,140,"Spacy >=3.3.0 ; Hi, was wondering if there is a timeline for supporting Spacy >=3.3.0? What pitfalls should i expect if i tried to manually modify the requirements to allow it? thank you.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/434
https://github.com/allenai/scispacy/issues/434:61,usability,support,supporting,61,"Spacy >=3.3.0 ; Hi, was wondering if there is a timeline for supporting Spacy >=3.3.0? What pitfalls should i expect if i tried to manually modify the requirements to allow it? thank you.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/434
https://github.com/allenai/scispacy/issues/435:531,energy efficiency,load,load,531,"RxCUIs when 'rxnorm' is selected; Hi, . First and foremost, thank you so much for all of your efforts on scispacy!  . When ""linker_name"": ""rxnorm"" is selected for NER, can we get the RxCUI of an entity as well as the CUI? This is the code I used:. ```. from scispacy.linking import EntityLinker. import spacy, scispacy. def mesh_extractor(text):. doc = nlp(text). for e in doc.ents:. if e._.kb_ents:. rxcui = e._.kb_ents[0][0]. print(e, rxcui). config = {. ""resolve_abbreviations"": True, . ""linker_name"": ""rxnorm"". }. nlp = spacy.load(""en_core_sci_lg""). nlp.add_pipe(""scispacy_linker"", config=config) . linker = nlp.get_pipe(""scispacy_linker""). text = ""The Aspirin was not helpful so I took Advil to help with my headache."". mesh_extractor(text). ```. and I only got CUIs, no RxCUIs:. ```. Aspirin C0004057. Advil C0593507. ```. Is there any way to map CUI to get RxCUI ? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/435
https://github.com/allenai/scispacy/issues/435:531,performance,load,load,531,"RxCUIs when 'rxnorm' is selected; Hi, . First and foremost, thank you so much for all of your efforts on scispacy!  . When ""linker_name"": ""rxnorm"" is selected for NER, can we get the RxCUI of an entity as well as the CUI? This is the code I used:. ```. from scispacy.linking import EntityLinker. import spacy, scispacy. def mesh_extractor(text):. doc = nlp(text). for e in doc.ents:. if e._.kb_ents:. rxcui = e._.kb_ents[0][0]. print(e, rxcui). config = {. ""resolve_abbreviations"": True, . ""linker_name"": ""rxnorm"". }. nlp = spacy.load(""en_core_sci_lg""). nlp.add_pipe(""scispacy_linker"", config=config) . linker = nlp.get_pipe(""scispacy_linker""). text = ""The Aspirin was not helpful so I took Advil to help with my headache."". mesh_extractor(text). ```. and I only got CUIs, no RxCUIs:. ```. Aspirin C0004057. Advil C0593507. ```. Is there any way to map CUI to get RxCUI ? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/435
https://github.com/allenai/scispacy/issues/435:674,usability,help,helpful,674,"RxCUIs when 'rxnorm' is selected; Hi, . First and foremost, thank you so much for all of your efforts on scispacy!  . When ""linker_name"": ""rxnorm"" is selected for NER, can we get the RxCUI of an entity as well as the CUI? This is the code I used:. ```. from scispacy.linking import EntityLinker. import spacy, scispacy. def mesh_extractor(text):. doc = nlp(text). for e in doc.ents:. if e._.kb_ents:. rxcui = e._.kb_ents[0][0]. print(e, rxcui). config = {. ""resolve_abbreviations"": True, . ""linker_name"": ""rxnorm"". }. nlp = spacy.load(""en_core_sci_lg""). nlp.add_pipe(""scispacy_linker"", config=config) . linker = nlp.get_pipe(""scispacy_linker""). text = ""The Aspirin was not helpful so I took Advil to help with my headache."". mesh_extractor(text). ```. and I only got CUIs, no RxCUIs:. ```. Aspirin C0004057. Advil C0593507. ```. Is there any way to map CUI to get RxCUI ? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/435
https://github.com/allenai/scispacy/issues/435:701,usability,help,help,701,"RxCUIs when 'rxnorm' is selected; Hi, . First and foremost, thank you so much for all of your efforts on scispacy!  . When ""linker_name"": ""rxnorm"" is selected for NER, can we get the RxCUI of an entity as well as the CUI? This is the code I used:. ```. from scispacy.linking import EntityLinker. import spacy, scispacy. def mesh_extractor(text):. doc = nlp(text). for e in doc.ents:. if e._.kb_ents:. rxcui = e._.kb_ents[0][0]. print(e, rxcui). config = {. ""resolve_abbreviations"": True, . ""linker_name"": ""rxnorm"". }. nlp = spacy.load(""en_core_sci_lg""). nlp.add_pipe(""scispacy_linker"", config=config) . linker = nlp.get_pipe(""scispacy_linker""). text = ""The Aspirin was not helpful so I took Advil to help with my headache."". mesh_extractor(text). ```. and I only got CUIs, no RxCUIs:. ```. Aspirin C0004057. Advil C0593507. ```. Is there any way to map CUI to get RxCUI ? Thank you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/435
https://github.com/allenai/scispacy/issues/436:249,availability,error,error,249,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:267,availability,Error,Error,267,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:311,availability,Error,Error,311,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:0,deployability,Releas,Releasing,0,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:51,deployability,depend,dependency,51,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:98,deployability,depend,dependency,98,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:209,deployability,releas,release,209,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:336,deployability,depend,dependency,336,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:418,deployability,releas,releases,418,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:506,deployability,manag,management,506,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:530,deployability,depend,dependency,530,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:604,deployability,depend,dependencies,604,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:693,deployability,releas,releases,693,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:124,energy efficiency,model,models,124,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:506,energy efficiency,manag,management,506,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:51,integrability,depend,dependency,51,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:98,integrability,depend,dependency,98,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:336,integrability,depend,dependency,336,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:530,integrability,depend,dependency,530,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:604,integrability,depend,dependencies,604,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:51,modifiability,depend,dependency,51,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:98,modifiability,depend,dependency,98,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:336,modifiability,depend,dependency,336,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:498,modifiability,pac,package,498,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:530,modifiability,depend,dependency,530,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:604,modifiability,depend,dependencies,604,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:249,performance,error,error,249,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:267,performance,Error,Error,267,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:311,performance,Error,Error,311,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:506,reliability,management tool,management tool,506,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:51,safety,depend,dependency,51,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:98,safety,depend,dependency,98,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:249,safety,error,error,249,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:267,safety,Error,Error,267,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:311,safety,Error,Error,311,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:336,safety,depend,dependency,336,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:506,safety,manag,management,506,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:530,safety,depend,dependency,530,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:604,safety,depend,dependencies,604,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:124,security,model,models,124,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:783,security,team,team,783,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:51,testability,depend,dependency,51,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:98,testability,depend,dependency,98,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:336,testability,depend,dependency,336,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:530,testability,depend,dependency,530,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:604,testability,depend,dependencies,604,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:12,usability,tool,tool,12,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:249,usability,error,error,249,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:267,usability,Error,Error,267,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:311,usability,Error,Error,311,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:517,usability,tool,tool,517,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/436:592,usability,tool,tool,592,"Releasing a tool to PyPi with an `en_ner_craft_md` dependency; We have a an NER project who has a dependency on one of your models namely `en_ner_craft_md ` and potentially others in the future. I'm trying to release our project to PyPi and get the error:. ```. HTTP Error 400: Invalid value for requires_dist. Error: Can't have direct dependency: 'en_ner_craft_md @ https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz'. ```. We're using `poetry` as our package management tool and the dependency is declared as follows in `pyproject.toml`:. ```. [tool.poetry.dependencies.en_ner_craft_md]. url = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_ner_craft_md-0.5.0.tar.gz"". ```. Is there any recommendation from your team for how should we address this? Thanks in advance!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/436
https://github.com/allenai/scispacy/issues/437:171,availability,error,error,171,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:113,deployability,automat,automatically,113,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:177,integrability,messag,message,177,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:177,interoperability,messag,message,177,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:171,performance,error,error,171,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:171,safety,error,error,171,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:113,testability,automat,automatically,113,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:171,usability,error,error,171,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/437:229,usability,user,user-images,229,"EntityLinker Import Kills Kernel; Whenever I use 'from scispacy.linking import EntityLinker' the kernel dies and automatically restarts. I ran it as a script and got this error message:. <img width=""671"" alt=""image"" src=""https://user-images.githubusercontent.com/46234732/174123352-969f6a6f-677a-477f-856e-cfc5e399ffac.png"">. I use a MacOS. How do I fix this?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/437
https://github.com/allenai/scispacy/issues/438:0,availability,ERROR,ERROR,0,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:151,availability,ERROR,ERROR,151,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7925,availability,ERROR,ERROR,7925,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:13,deployability,depend,dependency,13,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:96,deployability,instal,installed,96,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:164,deployability,depend,dependency,164,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:247,deployability,instal,installed,247,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:304,deployability,depend,dependency,304,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:631,deployability,log,log,631,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:647,deployability,log,login,647,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:734,deployability,instal,install,734,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:793,deployability,releas,releases,793,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:921,deployability,instal,install,921,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:980,deployability,releas,releases,980,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1092,deployability,releas,releases,1092,"installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packag",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1206,deployability,releas,releases,1206,"to account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:3920,deployability,log,loggers,3920,"e-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7751,deployability,Instal,Installing,7751,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7833,deployability,instal,installation,7833,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7938,deployability,depend,dependency,7938,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8021,deployability,instal,installed,8021,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8078,deployability,depend,dependency,8078,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8394,deployability,instal,installed,8394,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:42,energy efficiency,current,currently,42,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:193,energy efficiency,current,currently,193,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:422,energy efficiency,core,core-web-sm,422,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1511,energy efficiency,core,core-sci-scibert,1511,"ocanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: nu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1661,energy efficiency,core,core-sci-scibert,1661,"8:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied:",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1819,energy efficiency,core,core-sci-scibert,1819,"t-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied:",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1978,energy efficiency,core,core-sci-scibert,1978,"es/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:2129,energy efficiency,core,core-sci-scibert,2129,".gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshe",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:2288,energy efficiency,core,core-sci-scibert,2288," ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:2452,energy efficiency,core,core-sci-scibert,2452,"n /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /u",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:2604,energy efficiency,core,core-sci-scibert,2604,"3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:2763,energy efficiency,core,core-sci-scibert,2763,".10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.1",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:2921,energy efficiency,core,core-sci-scibert,2921,"3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:3066,energy efficiency,core,core-sci-scibert,3066,"python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satis",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:3226,energy efficiency,core,core-sci-scibert,3226,"ython3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satis",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:3380,energy efficiency,core,core-sci-scibert,3380,"ocal/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement al",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:3528,energy efficiency,core,core-sci-scibert,3528,"sr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.22.4). Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:3686,energy efficiency,core,core-sci-scibert,3686,"usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.4.3). Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:3848,energy efficiency,core,core-sci-scibert,3848,"local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.6). Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert=",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4015,energy efficiency,core,core-sci-scibert,4015,"ite-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.1.2). Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4174,energy efficiency,core,core-sci-scibert,4174,"site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.6). Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4340,energy efficiency,core,core-sci-scibert,4340,"s (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (21.3). Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4502,energy efficiency,core,core-sci-scibert,4502,"3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (60.3.1). Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-s",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4664,energy efficiency,core,core-sci-scibert,4664,"0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.7.7). Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4839,energy efficiency,core,core-sci-scibert,4839,"-core-sci-scibert==0.5.0) (2.28.0). Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5007,energy efficiency,core,core-sci-scibert,5007,"core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5157,energy efficiency,core,core-sci-scibert,5157,".2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/li",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5323,energy efficiency,core,core-sci-scibert,5323,".2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.2",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5504,energy efficiency,core,core-sci-scibert,5504,"cibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5681,energy efficiency,core,core-sci-scibert,5681,"(3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: fi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5884,energy efficiency,core,core-sci-scibert,5884," satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6060,energy efficiency,core,core-sci-scibert,6060,"ed: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6247,energy efficiency,core,core-sci-scibert,6247,"usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /u",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6433,energy efficiency,core,core-sci-scibert,6433,"0/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6616,energy efficiency,core,core-sci-scibert,6616,"ite-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: Mark",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6797,energy efficiency,core,core-sci-scibert,6797,"e-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting unins",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6991,energy efficiency,core,core-sci-scibert,6991,"kages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7169,energy efficiency,core,core-sci-scibert,7169,"/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7351,energy efficiency,core,core-sci-scibert,7351,"3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 w",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7554,energy efficiency,core,core-sci-scibert,7554,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7717,energy efficiency,core,core-sci-scibert,7717,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7967,energy efficiency,current,currently,7967,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8196,energy efficiency,core,core-web-sm,8196,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:13,integrability,depend,dependency,13,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:164,integrability,depend,dependency,164,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:304,integrability,depend,dependency,304,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1446,integrability,transform,transformers,1446,"cy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4990,integrability,transform,transformers,4990,"<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5140,integrability,transform,transformers,5140,"rom spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5223,integrability,transform,transformers,5223,"satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5306,integrability,transform,transformers,5306,"rom spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied:",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6745,integrability,transform,transformers,6745,"g-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6780,integrability,transform,transformers,6780,"/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6939,integrability,transform,transformers,6939,"ed: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's depende",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6974,integrability,transform,transformers,6974,"python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently tak",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7117,integrability,transform,transformers,7117,"charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7152,integrability,transform,transformers,7152,"ocal/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7299,integrability,transform,transformers,7299,"isfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7334,integrability,transform,transformers,7334,"sr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7502,integrability,transform,transformers,7502,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7537,integrability,transform,transformers,7537,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7938,integrability,depend,dependency,7938,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8078,integrability,depend,dependency,8078,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:315,interoperability,conflict,conflicts,315,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:405,interoperability,incompatib,incompatible,405,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:504,interoperability,incompatib,incompatible,504,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:593,interoperability,incompatib,incompatible,593,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1446,interoperability,transform,transformers,1446,"cy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:4990,interoperability,transform,transformers,4990,"<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.2). Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5140,interoperability,transform,transformers,5140,"rom spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (8.0.17). Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5223,interoperability,transform,transformers,5223,"satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:5306,interoperability,transform,transformers,5306,"rom spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.7). Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3.0). Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.8.2). Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (0.8.5). Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (1.11.0). Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.10/site-packages (from spacy-transformers->en-core-sci-scibert==0.5.0) (4.19.4). Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.0.9). Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (5.2.1). Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied:",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6745,interoperability,transform,transformers,6745,"g-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6780,interoperability,transform,transformers,6780,"/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.2.0). Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6939,interoperability,transform,transformers,6939,"ed: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's depende",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:6974,interoperability,transform,transformers,6974,"python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (3.3). Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently tak",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7117,interoperability,transform,transformers,7117,"charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7152,interoperability,transform,transformers,7152,"ocal/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.0.12). Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7299,interoperability,transform,transformers,7299,"isfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7334,interoperability,transform,transformers,7334,"sr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7502,interoperability,transform,transformers,7502,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:7537,interoperability,transform,transformers,7537,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8089,interoperability,conflict,conflicts,8089,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8179,interoperability,incompatib,incompatible,8179,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8278,interoperability,incompatib,incompatible,8278,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:8367,interoperability,incompatib,incompatible,8367,">=3.2.3->en-core-sci-scibert==0.5.0) (1.26.9). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2022.5.18.1). Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (3.7.1). Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.7.0). Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (6.0). Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (2022.6.2). Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers->en-core-sci-scibert==0.5.0) (0.12.1). Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (2.1.1). Installing collected packages: spacy. Attempting uninstall: spacy. Found existing installation: spacy 3.0.7. Uninstalling spacy-3.0.7:. Successfully uninstalled spacy-3.0.7. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. Successfully installed spacy-3.2.4. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:13,modifiability,depend,dependency,13,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:78,modifiability,pac,packages,78,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:164,modifiability,depend,dependency,164,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:229,modifiability,pac,packages,229,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:304,modifiability,depend,dependency,304,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed; Any fix or workaround for this issue:. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. scispacy 0.4.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. en-core-web-sm 3.0.0 requires spacy<3.1.0,>=3.0.0, but you have spacy 3.2.4 which is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1493,modifiability,pac,packages,1493,"ich is incompatible. docanalysis 0.1.1 requires spacy==3.0.7, but you have spacy 3.2.4 which is incompatible. ```. Here's my terminal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
https://github.com/allenai/scispacy/issues/438:1622,modifiability,pac,packages,1622,"inal log:. ```. Last login: Mon Jun 20 11:58:15 on ttys000. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip2 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. zsh: command not found: pip2. emanuelfarruda@Mannys-MacBook-Pro-2021 ~ % pip3 install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz. Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_scibert-0.5.0.tar.gz (417.6 MB). Preparing metadata (setup.py) ... done. Collecting spacy<3.3.0,>=3.2.3. Using cached spacy-3.2.4-cp310-cp310-macosx_10_9_x86_64.whl (6.3 MB). Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.10/site-packages (from en-core-sci-scibert==0.5.0) (1.1.6). Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (7.1.2). Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (4.62.3). Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.3.2). Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.6.1). Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (0.9.1). Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.0) (1.0.7). Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/site-packages (from spacy<3.3.0,>=3.2.3->en-core-sci-scibert==0.5.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/438
