id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/12276:388,safety,modul,module,388,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:511,safety,modul,modulemap,511,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:534,safety,modul,module,534,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:569,safety,log,log,569,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:599,safety,error,error,599,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:654,safety,error,error,654,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:920,safety,modul,module,920,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1075,safety,error,error,1075,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1098,safety,modul,module,1098,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1408,safety,updat,update,1408,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1419,safety,log,log,1419,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1462,safety,updat,updating,1462,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1564,safety,review,review,1564,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1655,safety,log,log,1655,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:304,security,log,log,304,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:569,security,log,log,569,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1408,security,updat,update,1408,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1419,security,log,log,1419,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1462,security,updat,updating,1462,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1655,security,log,log,1655,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:166,testability,diagno,diagnostic,166,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:304,testability,log,log,304,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:425,testability,context,context,425,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:569,testability,log,log,569,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:825,testability,trace,trace,825,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1245,testability,diagno,diagnostic,1245,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1419,testability,log,log,1419,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1564,testability,review,review,1564,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1655,testability,log,log,1655,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1662,testability,simpl,simply,1662,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1748,testability,diagno,diagnostic,1748,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:267,usability,help,helpful,267,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:599,usability,error,error,599,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:654,usability,error,error,654,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1075,usability,error,error,1075,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1196,usability,user,users,1196,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1294,usability,help,helpful,1294,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1620,usability,prefer,prefer,1620,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1662,usability,simpl,simply,1662,"Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. ```. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. ```. does not call out. - that it's during dictionary generation. - that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). - that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). - the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:57,availability,failur,failure,57,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:364,availability,failur,failure,364,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:637,availability,error,error,637,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:692,availability,error,error,692,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1125,availability,error,error,1125,"! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2196,availability,failur,failure,2196,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2318,availability,error,errors,2318,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:57,deployability,fail,failure,57,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:312,deployability,log,log,312,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:364,deployability,fail,failure,364,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:406,deployability,modul,module,406,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:549,deployability,modul,modulemap,549,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:572,deployability,modul,module,572,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:607,deployability,log,log,607,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:869,deployability,stack,stack,869,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:970,deployability,modul,module,970,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1034,deployability,build,build,1034,"ix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1088,deployability,build,build,1088,"commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random syst",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1142,deployability,build,build,1142,"to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1148,deployability,modul,module,1148,"t including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this sho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1468,deployability,updat,update,1468,"ot call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1479,deployability,log,log,1479,"t. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1522,deployability,updat,updating,1522,"tion. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate h",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1595,deployability,fail,fails,1595,"0' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""ap",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1721,deployability,log,log,1721,"n C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would he",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2196,deployability,fail,failure,2196,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2266,deployability,releas,releases,2266,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2332,deployability,log,logs,2332,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:304,energy efficiency,current,current,304,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1706,energy efficiency,current,current,1706,"n compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:795,integrability,messag,message,795,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:947,integrability,sub,submodule,947,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2422,integrability,messag,message,2422,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:795,interoperability,messag,message,795,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2422,interoperability,messag,message,2422,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:406,modifiability,modul,module,406,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:549,modifiability,modul,modulemap,549,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:572,modifiability,modul,module,572,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:970,modifiability,modul,module,970,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1148,modifiability,modul,module,1148,"t including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this sho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:57,performance,failur,failure,57,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:291,performance,time,times,291,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:364,performance,failur,failure,364,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:637,performance,error,error,637,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:692,performance,error,error,692,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1125,performance,error,error,1125,"! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1388,performance,time,time,1388,"g to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the rea",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1436,performance,time,time,1436,"++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which ad",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2196,performance,failur,failure,2196,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2318,performance,error,errors,2318,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:57,reliability,fail,failure,57,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:174,reliability,diagno,diagnostic,174,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:364,reliability,fail,failure,364,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:465,reliability,doe,does,465,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1305,reliability,diagno,diagnostic,1305,"t log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1595,reliability,fail,fails,1595,"0' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""ap",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1814,reliability,diagno,diagnostic,1814,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2062,reliability,diagno,diagnostic,2062,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2196,reliability,fail,failure,2196,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2343,reliability,pra,practice,2343,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:312,safety,log,log,312,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:383,safety,avoid,avoiding,383,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:406,safety,modul,module,406,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:549,safety,modul,modulemap,549,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:572,safety,modul,module,572,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:607,safety,log,log,607,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:637,safety,error,error,637,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:692,safety,error,error,692,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:970,safety,modul,module,970,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1125,safety,error,error,1125,"! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1148,safety,modul,module,1148,"t including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this sho",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1468,safety,updat,update,1468,"ot call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1479,safety,log,log,1479,"t. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1522,safety,updat,updating,1522,"tion. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate h",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1630,safety,review,review,1630,"the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a qui",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1721,safety,log,log,1721,"n C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would he",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2169,safety,review,review,2169,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2318,safety,error,errors,2318,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2332,safety,log,logs,2332,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2539,safety,review,review,2539,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:312,security,log,log,312,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:607,security,log,log,607,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1468,security,updat,update,1468,"ot call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1479,security,log,log,1479,"t. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1522,security,updat,updating,1522,"tion. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate h",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1721,security,log,log,1721,"n C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would he",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2332,security,log,logs,2332,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2372,security,obfusc,obfuscates,2372,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:174,testability,diagno,diagnostic,174,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:312,testability,log,log,312,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:443,testability,context,context,443,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:607,testability,log,log,607,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:875,testability,trace,trace,875,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1305,testability,diagno,diagnostic,1305,"t log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1479,testability,log,log,1479,"t. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1630,testability,review,review,1630,"the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a qui",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1721,testability,log,log,1721,"n C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would he",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1728,testability,simpl,simply,1728,"or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me de",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1814,testability,diagno,diagnostic,1814,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2062,testability,diagno,diagnostic,2062,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2169,testability,review,review,2169,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2332,testability,log,logs,2332,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2539,testability,review,review,2539,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2588,testability,simpl,simple,2588,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:275,usability,help,helpful,275,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:637,usability,error,error,637,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:692,usability,error,error,692,"> Yes, better than the ""That should fix a recent nightly failure with gcc11"" that Philippe commented on, thanks for improving it! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the expe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1125,usability,error,error,1125,"! > . > Compared to just including the actual diagnostic (something Philippe and I generally try to do these days, something that has proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1256,usability,user,users,1256,"as proven super helpful several times), your current log:. > . > ```. > That should fix a recent nightly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1354,usability,help,helpful,1354,"ghtly failure with gcc11 avoiding to require. > module ""bits/ranges_base.h"" in C++20 context. > ```. > . > does not call out. > . > * that it's during dictionary generation. > . > * that the modulemap requires the module feature 'cplusplus20' (your log seems to suggest that the error surfaces when compiled in C++20 mode, while this error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, espec",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1686,usability,prefer,prefer,1686,"is error shows up when compiling in C++14 or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a busine",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1728,usability,simpl,simply,1728,"or 17). > . > * that the issue is also with GCC12 headers (your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me de",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2105,usability,clear,clearer,2105,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2238,usability,support,support,2238,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2318,usability,error,errors,2318,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2588,usability,simpl,simple,2588,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2721,usability,help,help,2721,"your message seems to suggest that it's only with GCC11 headers). > . > * the ""stack trace"", i.e. `/usr/include/c++/12/experimental/string_view:43:10: note: submodule of top-level module 'std' implicitly imported here` and then `/home/sftnight/build/night/LABEL/ROOT-fedora36/SPEC/default/V/master/build/include/Rtypes.h:195:10: fatal error: could not build module 'ROOT_Foundation_Stage1_NoRTTI'` and then `#include ""TIsAProxy.h""`. > . > . > In general we tell our users (+/- always) ""can we please see the actual diagnostic"", and for the same reasons it's super helpful to include them here. The time we discussed this is waaay larger than the time it would have taken you to update the log to what Philippe proposes, rather than updating it to something that tries to address the issues (but seemingly fails?). > . > But it's Philippe's review, I let him comment / deal with this if you still prefer to keep your current commit log. I simply wanted to add an explanation why Philippe suggests the inclusion of the actual diagnostic (and why I found it convincing and do it ever since he propose it to me). This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). I am not sure if pasting a diagnostic from a random system makes this clearer in any form. I agree with you this should have be 1 min review fixing an important failure that we introduced with the c++20 support and some of the new releases of maybe libstdc++. @pcanal I find pasting errors in the logs a bad practice, especially when it obfuscates the real fix. Can you suggest a commit message which adds enough information which makes me happy as well? In general it is a bit unfortunate how the whole review went for this PR. This should been just a simple ""approve"" as I thought we needed a quick fix which I developed in between travels and a business trip... I suspect this would help me define urgent/important in similar circumstances in future...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:158,availability,failur,failure,158,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:808,availability,error,error,808,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1029,availability,error,error,1029,"isconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard libra",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1210,availability,error,error,1210,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1282,availability,failur,failure,1282,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1306,availability,failur,failure,1306,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:69,deployability,modul,module,69,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:158,deployability,fail,failure,158,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:198,deployability,modul,module,198,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:265,deployability,modul,module,265,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:421,deployability,log,log,421,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1282,deployability,fail,failure,1282,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1306,deployability,fail,failure,1306,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1374,deployability,build,build,1374,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1480,deployability,modul,module,1480,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1795,deployability,modul,module,1795,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1990,deployability,modul,module,1990,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1110,integrability,messag,message,1110,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1110,interoperability,messag,message,1110,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:2018,interoperability,standard,standard,2018,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:69,modifiability,modul,module,69,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:198,modifiability,modul,module,198,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:265,modifiability,modul,module,265,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1480,modifiability,modul,module,1480,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1795,modifiability,modul,module,1795,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1990,modifiability,modul,module,1990,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:158,performance,failur,failure,158,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:366,performance,content,content,366,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:808,performance,error,error,808,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1029,performance,error,error,1029,"isconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard libra",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1210,performance,error,error,1210,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1282,performance,failur,failure,1282,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1306,performance,failur,failure,1306,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:158,reliability,fail,failure,158,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1282,reliability,fail,failure,1282,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1306,reliability,fail,failure,1306,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:69,safety,modul,module,69,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:177,safety,avoid,avoiding,177,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:198,safety,modul,module,198,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:265,safety,modul,module,265,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:386,safety,compl,completely,386,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:421,safety,log,log,421,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:715,safety,compl,complete,715,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:808,safety,error,error,808,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1029,safety,error,error,1029,"isconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard libra",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1210,safety,error,error,1210,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1396,safety,compl,complained,1396,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1480,safety,modul,module,1480,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1795,safety,modul,module,1795,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1970,safety,avoid,avoiding,1970,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1990,safety,modul,module,1990,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:386,security,compl,completely,386,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:421,security,log,log,421,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:715,security,compl,complete,715,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1396,security,compl,complained,1396,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:235,testability,context,context,235,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:421,testability,log,log,421,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:908,testability,simpl,simple,908,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1005,testability,simpl,simply,1005,"lev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:808,usability,error,error,808,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:908,usability,simpl,simple,908,"@vgvassilev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module map",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1005,usability,simpl,simply,1005,"lev Let me clarify the disconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1029,usability,error,error,1029,"isconnect. The title says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard libra",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:1210,usability,error,error,1210,"le says ""Add **a** module for experimental/string_view"". The commit says:. That should fix a recent nightly failure with gcc11 avoiding to require. module ""bits/ranges_base.h"" in C++20 context. The code says:. ```. module ""experimental/string_view"" {. export *. header ""experimental/algorithm"". }. ```. . The commit content as-is seems completely unrelated to the commit log as far as I could tell (without doing research on the relationship between `range_base`, `string_view` and `algorithm`. . So I pondered whether the fix was the right fix for a problem I did not know anything about ... . . The right thing to do would have probably be have been to request a complete explanation of what the original problem was, what was the mechanism leading to the error and why this solution was the best solution. This was obviously much more than this seemingly simple fix required. So instead I thought to ask for a very low cost, straight forward solution: simply copy/pasting the error with no additional effort to explain in detail. > Can you suggest a commit message which adds enough information which makes me happy as well? That requires to paraphrase the error and add a few more details. ```. That should fix a recent nightly failure with gcc11. The failure presented during dictionary generation in a C++14 and C++17 build and incorrectly complained about needing the 'cplusplus20' feature for the 'std.bits/ranges_base.h' module. The issue was triggered by an inclusion of `<bits/ranges_base.h>` from `string_view`. This issue exists on gcc11 and gcc12 (and I guess any gcc that made changes to libstdc++ and the experimental/string_view header file). . It seems the issue is solved by exporting `algorithm` as part of the `string_view` module. ```. Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:536,availability,avail,available,536,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:184,deployability,modul,module,184,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:335,deployability,fail,failed,335,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:345,deployability,updat,update,345,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:431,deployability,updat,update,431,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:401,integrability,sub,subtle,401,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:212,interoperability,standard,standard,212,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:184,modifiability,modul,module,184,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:335,reliability,fail,failed,335,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:536,reliability,availab,available,536,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:164,safety,avoid,avoiding,164,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:184,safety,modul,module,184,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:345,safety,updat,update,345,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:431,safety,updat,update,431,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:536,safety,avail,available,536,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:345,security,updat,update,345,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:431,security,updat,update,431,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:536,security,availab,available,536,"> Actually, I still don't know why adding `algorithm` fixes a problem with `range_base.h`, so I can't add that to the commit ... maybe it is something like ""... by avoiding to use the module maps provided by the standard library in those case""? Now that’s something I was looking for! Thank you! I think that’s a mistake in this PR. I failed to update the relevant header as well. The problem is more subtle probably as since some update of gcc it started picking up experimental/string_view which in turn somehow uses the headers only available in c++14 onwards. So perhaps we should re-export string_view… I can look at that tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:33,deployability,log,log,33,"@pcanal, please check the commit log, I think that's good to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:33,safety,log,log,33,"@pcanal, please check the commit log, I think that's good to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:33,security,log,log,33,"@pcanal, please check the commit log, I think that's good to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:33,testability,log,log,33,"@pcanal, please check the commit log, I think that's good to go.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:4,availability,failur,failures,4,The failures seem unrelated. Let's merge this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:4,deployability,fail,failures,4,The failures seem unrelated. Let's merge this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:4,performance,failur,failures,4,The failures seem unrelated. Let's merge this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:4,reliability,fail,failures,4,The failures seem unrelated. Let's merge this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/issues/12277:82,availability,error,error,82,"Oh, and the order. If you call `add42(1)` after the `Declare()`, then there is no error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:82,performance,error,error,82,"Oh, and the order. If you call `add42(1)` after the `Declare()`, then there is no error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:82,safety,error,error,82,"Oh, and the order. If you call `add42(1)` after the `Declare()`, then there is no error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:82,usability,error,error,82,"Oh, and the order. If you call `add42(1)` after the `Declare()`, then there is no error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/pull/12278:11,deployability,build,build,11,"@phsft-bot build just on windows10/cxx14, ROOT-ubuntu2004/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12278
https://github.com/root-project/root/pull/12278:11,deployability,build,build,11,"@phsft-bot build just on windows10/cxx14, ROOT-ubuntu2004/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12278
https://github.com/root-project/root/pull/12278:11,deployability,build,build,11,"@phsft-bot build just on windows10/cxx14, ROOT-ubuntu2004/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12278
https://github.com/root-project/root/pull/12279:166,energy efficiency,alloc,allocate,166,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:521,energy efficiency,alloc,allocated,521,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:640,energy efficiency,alloc,allocator,640,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:654,energy efficiency,alloc,allocation,654,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:868,energy efficiency,alloc,allocator,868,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:782,integrability,buffer,buffer,782,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:6,performance,cach,cache,6,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:126,performance,cach,cache,126,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:415,performance,lock,locked,415,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:629,performance,cach,cache,629,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:415,security,lock,locked,415,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:379,testability,Simpl,Simplest,379,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:379,usability,Simpl,Simplest,379,"> The cache mechanics looks good, but I think we need to discuss it a little more:. > . > * I don't think a thread-local page cache works. In `UnzipClusterImpl()` we allocate pages in (TBB) tasks. > . Oh, you are absolutely right! I didn't thought enough about the implications of this; it might actually happen that pages are returned by a totally different thread (not TBB's). Simplest thing would be to go for a locked data structure (while trying to keep the critical section small). > * I think we should pass a pre-allocated page to `UnsealPage()` instead of the column id. That would result in symmetric appearance of the cache page allocator for allocation an deallocation. I agree that it would result in symmetric use; however, `UnsealPage()` has to reserve an additional buffer for unpacking the page, if needed. Thus, I would leave it as-is or pass a page allocator as an additional (maybe template) argument.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:289,availability,avail,available,289,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:147,energy efficiency,optim,optimized,147,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:157,energy efficiency,alloc,allocation,157,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:276,energy efficiency,alloc,allocator,276,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:36,integrability,interfac,interface,36,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:36,interoperability,interfac,interface,36,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:36,modifiability,interfac,interface,36,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:267,modifiability,scal,scalable,267,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:147,performance,optimiz,optimized,147,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:267,performance,scalab,scalable,267,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:289,reliability,availab,available,289,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:289,safety,avail,available,289,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:289,security,availab,available,289,"I'm closing this PR, as most of the interface changes that were part of it were landed in https://github.com/root-project/root/pull/13208. For the optimized allocation / deallocation, I think we should be taking a look to `tbb_allocator<T>` instead, which uses TBB's scalable allocator if available or otherwise reverts to `malloc` (see https://oneapi-src.github.io/oneTBB/main/tbb_userguide/Which_Dynamic_Libraries_to_Use.html). That should be a different PR though! I'll leave it into your capable hands, @jblomer!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/issues/12286:87,testability,simpl,simply,87,Thank you for the fix! . It appears that while forcing the use of `RooFoamGenerator` I simply skipped that code path...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:87,usability,simpl,simply,87,Thank you for the fix! . It appears that while forcing the use of `RooFoamGenerator` I simply skipped that code path...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/pull/12292:102,availability,error,error,102,"I think @pcanal is after:. > Things did not work. What are ""things"", what does this fix? Was there an error before? etc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:102,performance,error,error,102,"I think @pcanal is after:. > Things did not work. What are ""things"", what does this fix? Was there an error before? etc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:74,reliability,doe,does,74,"I think @pcanal is after:. > Things did not work. What are ""things"", what does this fix? Was there an error before? etc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:102,safety,error,error,102,"I think @pcanal is after:. > Things did not work. What are ""things"", what does this fix? Was there an error before? etc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:102,usability,error,error,102,"I think @pcanal is after:. > Things did not work. What are ""things"", what does this fix? Was there an error before? etc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:221,interoperability,platform,platform,221,I don’t see a problem with this commit. You are welcome to suggest wording. . Cpt is not used by ROOT and not checked. I am quite surprised we spend time on such minor things. . PS: when we fix a compilation problem on a platform do we explain what the entire method/class did?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:149,performance,time,time,149,I don’t see a problem with this commit. You are welcome to suggest wording. . Cpt is not used by ROOT and not checked. I am quite surprised we spend time on such minor things. . PS: when we fix a compilation problem on a platform do we explain what the entire method/class did?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:234,integrability,messag,message,234,"I'm with Vassil here: Things are completely broken right now, there is really not much you can describe being fixed here other than *what* is changed, which is very obvious in this case from the diff and should never be in the commit message anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:234,interoperability,messag,message,234,"I'm with Vassil here: Things are completely broken right now, there is really not much you can describe being fixed here other than *what* is changed, which is very obvious in this case from the diff and should never be in the commit message anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:33,safety,compl,completely,33,"I'm with Vassil here: Things are completely broken right now, there is really not much you can describe being fixed here other than *what* is changed, which is very obvious in this case from the diff and should never be in the commit message anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:33,security,compl,completely,33,"I'm with Vassil here: Things are completely broken right now, there is really not much you can describe being fixed here other than *what* is changed, which is very obvious in this case from the diff and should never be in the commit message anyway.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:74,deployability,instal,install,74,"I would still expect something a ""little"" more specific. For example ""Fix install prefix calculation in cpt rules"". But really I don't get why"". ```. 	CPT_SRC_DIR = install_prefix(). ``` . Why is the src the same as the install prefix? I was hoping that describing how it failed would have help me understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:220,deployability,instal,install,220,"I would still expect something a ""little"" more specific. For example ""Fix install prefix calculation in cpt rules"". But really I don't get why"". ```. 	CPT_SRC_DIR = install_prefix(). ``` . Why is the src the same as the install prefix? I was hoping that describing how it failed would have help me understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:272,deployability,fail,failed,272,"I would still expect something a ""little"" more specific. For example ""Fix install prefix calculation in cpt rules"". But really I don't get why"". ```. 	CPT_SRC_DIR = install_prefix(). ``` . Why is the src the same as the install prefix? I was hoping that describing how it failed would have help me understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:47,interoperability,specif,specific,47,"I would still expect something a ""little"" more specific. For example ""Fix install prefix calculation in cpt rules"". But really I don't get why"". ```. 	CPT_SRC_DIR = install_prefix(). ``` . Why is the src the same as the install prefix? I was hoping that describing how it failed would have help me understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:272,reliability,fail,failed,272,"I would still expect something a ""little"" more specific. For example ""Fix install prefix calculation in cpt rules"". But really I don't get why"". ```. 	CPT_SRC_DIR = install_prefix(). ``` . Why is the src the same as the install prefix? I was hoping that describing how it failed would have help me understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:298,testability,understand,understand,298,"I would still expect something a ""little"" more specific. For example ""Fix install prefix calculation in cpt rules"". But really I don't get why"". ```. 	CPT_SRC_DIR = install_prefix(). ``` . Why is the src the same as the install prefix? I was hoping that describing how it failed would have help me understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:290,usability,help,help,290,"I would still expect something a ""little"" more specific. For example ""Fix install prefix calculation in cpt rules"". But really I don't get why"". ```. 	CPT_SRC_DIR = install_prefix(). ``` . Why is the src the same as the install prefix? I was hoping that describing how it failed would have help me understand.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/pull/12292:123,usability,close,close,123,"Hi @vgvassilev , it seems that this PR is not necessary any more, but please correct me if I am wrong. If not, can we just close it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12292
https://github.com/root-project/root/issues/12293:11,safety,reme,remember,11,"@hahnjo, I remember seeing something similar in clang-repl and then having the TargetTriple be taken from clang instead of guessing: llvm/llvm-project@49f9532165f0cc0485a7da84662ebf63d155652c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:264,deployability,patch,patches,264,"@vgvassilev yes, and I recently implemented the same in Cling: df0905c499a541eaac3be63c0455a07946022983. @ellert any chance you can test a fix interactively before we commit? The above commit probably doesn't apply cleanly, I will prepare a backport for `v6-28-00-patches`...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:201,reliability,doe,doesn,201,"@vgvassilev yes, and I recently implemented the same in Cling: df0905c499a541eaac3be63c0455a07946022983. @ellert any chance you can test a fix interactively before we commit? The above commit probably doesn't apply cleanly, I will prepare a backport for `v6-28-00-patches`...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:132,safety,test,test,132,"@vgvassilev yes, and I recently implemented the same in Cling: df0905c499a541eaac3be63c0455a07946022983. @ellert any chance you can test a fix interactively before we commit? The above commit probably doesn't apply cleanly, I will prepare a backport for `v6-28-00-patches`...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:264,safety,patch,patches,264,"@vgvassilev yes, and I recently implemented the same in Cling: df0905c499a541eaac3be63c0455a07946022983. @ellert any chance you can test a fix interactively before we commit? The above commit probably doesn't apply cleanly, I will prepare a backport for `v6-28-00-patches`...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:264,security,patch,patches,264,"@vgvassilev yes, and I recently implemented the same in Cling: df0905c499a541eaac3be63c0455a07946022983. @ellert any chance you can test a fix interactively before we commit? The above commit probably doesn't apply cleanly, I will prepare a backport for `v6-28-00-patches`...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:132,testability,test,test,132,"@vgvassilev yes, and I recently implemented the same in Cling: df0905c499a541eaac3be63c0455a07946022983. @ellert any chance you can test a fix interactively before we commit? The above commit probably doesn't apply cleanly, I will prepare a backport for `v6-28-00-patches`...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:143,usability,interact,interactively,143,"@vgvassilev yes, and I recently implemented the same in Cling: df0905c499a541eaac3be63c0455a07946022983. @ellert any chance you can test a fix interactively before we commit? The above commit probably doesn't apply cleanly, I will prepare a backport for `v6-28-00-patches`...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12294:254,deployability,automat,automatically,254,"@ellert thanks for the report, I'll need to see if I can get access to a AArch64 system to test. In the meantime, could you see if the symbols appear in the executables or one of the shared libraries? Then they would be in the process and Cling *should* automatically find them...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:183,interoperability,share,shared,183,"@ellert thanks for the report, I'll need to see if I can get access to a AArch64 system to test. In the meantime, could you see if the symbols appear in the executables or one of the shared libraries? Then they would be in the process and Cling *should* automatically find them...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:91,safety,test,test,91,"@ellert thanks for the report, I'll need to see if I can get access to a AArch64 system to test. In the meantime, could you see if the symbols appear in the executables or one of the shared libraries? Then they would be in the process and Cling *should* automatically find them...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:61,security,access,access,61,"@ellert thanks for the report, I'll need to see if I can get access to a AArch64 system to test. In the meantime, could you see if the symbols appear in the executables or one of the shared libraries? Then they would be in the process and Cling *should* automatically find them...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:91,testability,test,test,91,"@ellert thanks for the report, I'll need to see if I can get access to a AArch64 system to test. In the meantime, could you see if the symbols appear in the executables or one of the shared libraries? Then they would be in the process and Cling *should* automatically find them...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:254,testability,automat,automatically,254,"@ellert thanks for the report, I'll need to see if I can get access to a AArch64 system to test. In the meantime, could you see if the symbols appear in the executables or one of the shared libraries? Then they would be in the process and Cling *should* automatically find them...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:240,deployability,version,version,240,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:551,deployability,version,version,551,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1021,deployability,updat,update,1021,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:240,integrability,version,version,240,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:551,integrability,version,version,551,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:757,interoperability,share,shared,757,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:240,modifiability,version,version,240,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:551,modifiability,version,version,551,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1021,safety,updat,update,1021,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1021,security,updat,update,1021,"This problem happens with. * RHEL+EPEL 9 (gcc 11.3.1). * Fedora 36/37 (gcc 12.2.1). * Fedora 38/39 (gcc 13.0.1). But not with:. * RHEL+EPEL 8 (gcc 8.5.0). It seems to be related to an issue that appeared also with the previous LLVM 9 based version of ROOT when gcc 10 was introduced in Fedora 33:. https://bugzilla.redhat.com/show_bug.cgi?id=1830472. From a comment in the above bugzilla report:. On aarch64 -moutline-atomics has been turned on by default, and those symbols are solely in libgcc.a, not in libgcc_s.so.*. The problem with the old ROOT version was fixed when the libgcc_s.so symlink in gcc was replaced by a linker script. This linker script is still there:. $ cat /usr/lib/gcc/aarch64-redhat-linux/12/libgcc_s.so . /* GNU ld script. Use the shared library, but some functions are only in. the static library, so try that secondarily. */. OUTPUT_FORMAT(elf64-littleaarch64). GROUP ( /lib64/libgcc_s.so.1 libgcc.a ). With this linker scripts ROOT worked fine on aarch64 with gcc >= 10. But with the LLVM 13 update it broke again despite the linker script still being there. It still works on RHEL+EPEL 8 with gcc 8 which seems to suggest that it is related to -moutline-atomics which became the default on aarch64 in gcc 10. I hope this will give some ideas about how to fix it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:115,availability,sli,slightly,115,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:201,deployability,fail,failed,201,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:219,deployability,build,build,219,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:549,deployability,upgrad,upgrade,549,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:549,modifiability,upgrad,upgrade,549,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:115,reliability,sli,slightly,115,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:201,reliability,fail,failed,201,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:455,safety,detect,detects,455,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:455,security,detect,detects,455,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:21,usability,help,helped,21,"Thanks @ellert, this helped a lot to get me started into the right direction! As far as I can tell, the problem is slightly different from https://bugzilla.redhat.com/show_bug.cgi?id=1830472; that one failed during the build of ROOT while we now have a problem during JIT compilation, after ROOT has already been built successfully. But we are very likely on the right track here with `-moutline-atomics` because Clang now defaults to enabling that if it detects a `libgcc` newer than 9.3.1 - this explains why it still works with GCC 8. Before the upgrade to LLVM 13, it was working fine everywhere because LLVM 9 didn't know about the `__aarch64_ldadd*` functions, I believe it used a different lowering strategy for atomics...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/pull/12295:34,deployability,fail,fails,34,"Can you rebase, looks like the ci fails at rebasing fedora...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:34,reliability,fail,fails,34,"Can you rebase, looks like the ci fails at rebasing fedora...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:82,availability,failur,failure,82,We should get this merged - seems like an improvement already (despite the Fedora failure).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:82,deployability,fail,failure,82,We should get this merged - seems like an improvement already (despite the Fedora failure).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:82,performance,failur,failure,82,We should get this merged - seems like an improvement already (despite the Fedora failure).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:82,reliability,fail,failure,82,We should get this merged - seems like an improvement already (despite the Fedora failure).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:80,availability,error,errors,80,"Partial revert: https://github.com/root-project/root/pull/12516. This PR causes errors, see https://github.com/root-project/cling/commit/782cc41a6c3c48c697cf4ae43c44d18ddaa46aa9#commitcomment-105357940.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:80,performance,error,errors,80,"Partial revert: https://github.com/root-project/root/pull/12516. This PR causes errors, see https://github.com/root-project/cling/commit/782cc41a6c3c48c697cf4ae43c44d18ddaa46aa9#commitcomment-105357940.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:80,safety,error,errors,80,"Partial revert: https://github.com/root-project/root/pull/12516. This PR causes errors, see https://github.com/root-project/cling/commit/782cc41a6c3c48c697cf4ae43c44d18ddaa46aa9#commitcomment-105357940.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/pull/12295:80,usability,error,errors,80,"Partial revert: https://github.com/root-project/root/pull/12516. This PR causes errors, see https://github.com/root-project/cling/commit/782cc41a6c3c48c697cf4ae43c44d18ddaa46aa9#commitcomment-105357940.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12295
https://github.com/root-project/root/issues/12296:285,energy efficiency,Draw,Draw,285,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:592,energy efficiency,draw,drawn,592,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:779,energy efficiency,draw,drawn,779,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:380,integrability,messag,messages,380,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:735,integrability,messag,message,735,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:380,interoperability,messag,messages,380,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:735,interoperability,messag,message,735,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:350,performance,parallel,parallel,350,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:694,usability,clear,clear,694,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:760,usability,user,user,760,"I tried to reproduce this issue with the following C++ script:. ```. void nan(){. auto g = new TGraph ();. g->AddPoint(0,TMath::QuietNaN());. g->AddPoint(1,TMath::QuietNaN());. g->AddPoint(2,TMath::QuietNaN());. g->AddPoint(3,TMath::QuietNaN());. g->AddPoint(4,TMath::QuietNaN());. g->Draw(""APL"");. }. ```. Like you it gives me a blank canvas but in parallel, I get the following messages in the terminal output:. ```. root [0] . Processing nan.C... Info in <TCanvas::MakeDefCanvas>: created default TCanvas with name c1. Warning in <TCanvas::ResizePad>: Inf/NaN propagated to the pad. Check drawn objects. Warning in <TCanvas::ResizePad>: c1 height changed from 0 to 10. ``` . So it is pretty clear that there NaNs in the data. . The message even invites the user to check the ""drawn objects"". I do not think we can do more than that.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:61,availability,error,error,61,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:279,deployability,modul,module,279,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:480,energy efficiency,Draw,Draw,480,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:669,energy efficiency,Draw,DrawClone,669,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:67,integrability,messag,message,67,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:89,integrability,messag,message,89,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:67,interoperability,messag,message,67,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:89,interoperability,messag,message,89,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:279,modifiability,modul,module,279,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:61,performance,error,error,61,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:61,safety,error,error,61,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:279,safety,modul,module,279,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:194,testability,Trace,Traceback,194,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:61,usability,error,error,61,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:237,usability,User,Users,237,"@LadaOndris I see you are using SWAN may be it swallowed the error message? do you get a message if you use the normal ROOT? I tried to run your script but it gives me:. ```. % python3 nan.py . Traceback (most recent call last):. File ""/Users/couet/roottest/nan.py"", line 8, in <module>. np.arange(num_values, dtype='float'),. NameError: name 'np' is not defined. ```. the script is:. ### nan.py. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. What is `np`? can you provide a running script?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:593,availability,error,error,593,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:295,energy efficiency,Draw,Draw,295,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:484,energy efficiency,Draw,DrawClone,484,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:707,energy efficiency,draw,drawn,707,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:72,integrability,messag,message,72,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:599,integrability,messag,message,599,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:871,integrability,messag,message,871,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:72,interoperability,messag,message,72,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:599,interoperability,messag,message,599,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:871,interoperability,messag,message,871,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:593,performance,error,error,593,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:593,safety,error,error,593,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:534,usability,command,command,534,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:593,usability,error,error,593,"Hello @couet, . thank you for looking into it. SWAN indeed swallows the message informing about the nan values. The following script should run (I forgot to include the numpy import before):. ```. import ROOT. import numpy as np. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values,. np.arange(num_values, dtype='float'),. np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. Running the script from the command line as you suggested indeed produces the expected error message:. ```. $ python3 nan.py. TCanvas::ResizePad:0: RuntimeWarning: Inf/NaN propagated to the pad. Check drawn objects. TCanvas::ResizePad:0: RuntimeWarning: test_canvas height changed from 0 to 10. ```. Running the same code in a SWAN cell produces only the following message: . ```. Welcome to JupyROOT 6.26/08. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:127,availability,error,error,127,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:99,deployability,log,log,99,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:133,integrability,messag,messages,133,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:133,interoperability,messag,messages,133,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:127,performance,error,error,127,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:99,safety,log,log,99,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:127,safety,error,error,127,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:99,security,log,log,99,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:99,testability,log,log,99,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:127,usability,error,error,127,"@LadaOndris : So that's a SWAN issue in that case. I am not a SWAN expert. . In SWAN, Is there any log window showing the ROOT error messages? @etejedor : to you have an idea ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:52,integrability,messag,message-swallowing,52,It does not appear to be a SWAN specific issue. The message-swallowing also happens in locally-run Jupyter notebooks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:32,interoperability,specif,specific,32,It does not appear to be a SWAN specific issue. The message-swallowing also happens in locally-run Jupyter notebooks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:52,interoperability,messag,message-swallowing,52,It does not appear to be a SWAN specific issue. The message-swallowing also happens in locally-run Jupyter notebooks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:3,reliability,doe,does,3,It does not appear to be a SWAN specific issue. The message-swallowing also happens in locally-run Jupyter notebooks.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:107,availability,error,error,107,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:113,integrability,messag,messages,113,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:113,interoperability,messag,messages,113,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:107,performance,error,error,107,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:84,reliability,doe,does,84,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:107,safety,error,error,107,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:11,usability,close,close,11,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:107,usability,error,error,107,"Ok, that's close. @etejedor or @vepadulano are the experts in any case. ROOT itself does the job regarding error messages in case of NaN.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12297:28,interoperability,platform,platform,28,Should this replace the per-platform config files (e.g. ubuntu22.txt) or be a supplementary feature to run both default ubuntu22 config and ubuntu22 with soversion=On?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/pull/12299:30,usability,support,support,30,But consider removing python2 support from master (instead).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12299
https://github.com/root-project/root/pull/12299:24,testability,plan,plan,24,"@vepadulano what is the plan now that this PR didn't make it to 6.30, and Python 2 support will be removed from 6.32 anyway?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12299
https://github.com/root-project/root/pull/12299:83,usability,support,support,83,"@vepadulano what is the plan now that this PR didn't make it to 6.30, and Python 2 support will be removed from 6.32 anyway?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12299
https://github.com/root-project/root/issues/12302:182,deployability,build,build,182,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:304,deployability,build,build,304,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:375,deployability,build,build,375,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:335,integrability,interfac,interface,335,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:335,interoperability,interfac,interface,335,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:335,modifiability,interfac,interface,335,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:95,usability,behavi,behavior,95,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:137,usability,close,close,137,@eguiraud I've briefly experimented with using keywords in the PR body/title to implement this behavior. The problem is that you have to close and re-open the issue to trigger a new build. Clicking 're-run jobs' unintuitively starts a job using the old PR title/body. Would using comments to start a new build from scratch be a better interface? (Something like commenting `/build`),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:3,deployability,build,builds,3,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:38,deployability,build,build,38,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:44,deployability,fail,fails,44,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:151,deployability,build,build,151,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:286,deployability,artifact,artifact,286,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:358,deployability,artifact,artifacts,358,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:44,reliability,fail,fails,44,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:124,security,sign,signal,124,"PR builds are incremental, and if the build fails *due to the changes introduced by the PR* then indeed we need some way to signal that we need a full build. Maybe a label? > due to the changes introduced by the PR. If it's due to some other change in main, introduced between the last artifact and master, unrelated to the PR, then just waiting for the new artifacts to be generated should be fine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:521,availability,sli,slightly,521,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:89,deployability,build,build,89,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:242,deployability,build,build,242,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:355,deployability,build,build,355,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:425,deployability,build,build,425,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:450,deployability,build,build,450,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:488,deployability,build,build,488,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:618,deployability,build,build,618,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:666,deployability,build,build,666,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:458,energy efficiency,current,currently,458,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:37,integrability,sub,submitters,37,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:386,integrability,interfac,interface,386,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:386,interoperability,interfac,interface,386,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:386,modifiability,interfac,interface,386,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:28,performance,time,times,28,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:687,performance,time,time,687,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:521,reliability,sli,slightly,521,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:182,usability,behavi,behavior,182,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:435,usability,command,command,435,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:673,usability,command,command,673,"> Maybe a label? 99% of the times PR submitters will not realize that they needed a full build rather than an incremental before it's too late. As long as the label changes the CI's behavior even if it's added after the fact (after the first build), it sounds like a good solution because it stays there permanently. > Would using comments to start a new build from scratch be a better interface? (Something like commenting /build). A command like `/build` (currently we have `@phsft-bot build [...options...]`) would be slightly worse than a label because on any new push to the PR you would still get an incremental build, and you would have to give the special `/build` command every time, I guess.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:62,availability,state,state,62,"> Maybe a label? The 're-run jobs' button uses the exact same state as the previous run, even if the PR labels have changed. I think the workflow could listen for `on.pull_request.types['labeled']` events and automatically start a new run as soon as it's added. Proceeding pushes to the fork will also see the label.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:209,deployability,automat,automatically,209,"> Maybe a label? The 're-run jobs' button uses the exact same state as the previous run, even if the PR labels have changed. I think the workflow could listen for `on.pull_request.types['labeled']` events and automatically start a new run as soon as it's added. Proceeding pushes to the fork will also see the label.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:62,integrability,state,state,62,"> Maybe a label? The 're-run jobs' button uses the exact same state as the previous run, even if the PR labels have changed. I think the workflow could listen for `on.pull_request.types['labeled']` events and automatically start a new run as soon as it's added. Proceeding pushes to the fork will also see the label.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:198,integrability,event,events,198,"> Maybe a label? The 're-run jobs' button uses the exact same state as the previous run, even if the PR labels have changed. I think the workflow could listen for `on.pull_request.types['labeled']` events and automatically start a new run as soon as it's added. Proceeding pushes to the fork will also see the label.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:209,testability,automat,automatically,209,"> Maybe a label? The 're-run jobs' button uses the exact same state as the previous run, even if the PR labels have changed. I think the workflow could listen for `on.pull_request.types['labeled']` events and automatically start a new run as soon as it's added. Proceeding pushes to the fork will also see the label.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:137,usability,workflow,workflow,137,"> Maybe a label? The 're-run jobs' button uses the exact same state as the previous run, even if the PR labels have changed. I think the workflow could listen for `on.pull_request.types['labeled']` events and automatically start a new run as soon as it's added. Proceeding pushes to the fork will also see the label.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:315,deployability,build,build,315,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:392,deployability,build,build,392,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:430,deployability,build,build,430,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:719,deployability,build,builds,719,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:870,deployability,build,build,870,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:876,deployability,automat,automatically,876,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:42,integrability,event,events,42,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:67,integrability,filter,filter,67,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:168,integrability,filter,filtering,168,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:253,integrability,event,event,253,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:288,integrability,event,event,288,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:83,interoperability,specif,specific,83,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:789,security,auth,authors,789,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:158,testability,emul,emulating,158,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:876,testability,automat,automatically,876,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:378,usability,statu,status,378,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:420,usability,cancel,cancelled,420,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:471,usability,user,user-images,471,"The problem with running on label/comment events is that you can't filter based on specific labels. https://github.com/orgs/community/discussions/26261. When emulating filtering by using a conditional on each job, say by using ... ```yml. if: |. github.event.action == labeled. && github.event.label.name == 'clean build'. ```. ... , adding unrelated labels will still hide the status of the build and instead display a cancelled build. Example:. -----. ![image](https://user-images.githubusercontent.com/82065181/220065683-ae946b8a-fcf7-4eee-9d6f-cf52d29111f3.png). ----. Triggering on pull request comments would be even more annoying with this in mind. I can still open a PR that enables using labels to force clean builds and find a cleaner implementation later. Or we can have the PR authors manually restart the job (e.g. by re-opening the PR) and omit having the build automatically start on added labels",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:27,deployability,build,build,27,"Current idea: add `ci:full-build` (which doesn't trigger a build), then people close & re-open to trigger a build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:59,deployability,build,build,59,"Current idea: add `ci:full-build` (which doesn't trigger a build), then people close & re-open to trigger a build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:108,deployability,build,build,108,"Current idea: add `ci:full-build` (which doesn't trigger a build), then people close & re-open to trigger a build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:0,energy efficiency,Current,Current,0,"Current idea: add `ci:full-build` (which doesn't trigger a build), then people close & re-open to trigger a build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:41,reliability,doe,doesn,41,"Current idea: add `ci:full-build` (which doesn't trigger a build), then people close & re-open to trigger a build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:79,usability,close,close,79,"Current idea: add `ci:full-build` (which doesn't trigger a build), then people close & re-open to trigger a build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/pull/12304:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/issues/12307:75,usability,close,closed,75,"Hi @olemorud and @Axel-Naumann, is this addressed now and the issue can be closed?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:151,availability,error,errors,151,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:439,deployability,fail,failed,439,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:479,deployability,fail,failed,479,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:151,performance,error,errors,151,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:439,reliability,fail,failed,439,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:479,reliability,fail,failed,479,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:62,safety,reme,remember,62,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:146,safety,test,test,146,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:151,safety,error,errors,151,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:433,safety,test,tests,433,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:473,safety,test,tests,473,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:532,safety,input,input,532,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:146,testability,test,test,146,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:433,testability,test,tests,433,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:473,testability,test,tests,473,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:151,usability,error,errors,151,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:318,usability,workflow,workflows,318,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:532,usability,input,input,532,"Sorry for not addressing this issue earlier. Although I don't remember the reasoning, I believe it was concluded that the CI should not be red on test errors. If this is to be changed all there is to it is changing [this line](https://github.com/root-project/root/blob/aae1cd064679f440ad80f39e4ee56bb0c1d9d396/.github/workflows/root-ci-config/build_root.py#LL252C22-L252C22):. ```diff. 251 if result != 0:. - 252 print_warning(""Some tests failed""). + 252 die(result, ""Some tests failed"", shell_log). ```. Would like @Axel-Naumann's input before closing",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:65,availability,failur,failures,65,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:84,availability,failur,failures,84,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:120,availability,failur,failures,120,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:159,availability,failur,failures,159,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:182,availability,state,state,182,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:214,availability,ping,pinging,214,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:59,deployability,build,build,59,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:65,deployability,fail,failures,65,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:84,deployability,fail,failures,84,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:105,deployability,fail,fail,105,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:114,deployability,build,build,114,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:120,deployability,fail,failures,120,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:159,deployability,fail,failures,159,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:175,deployability,fail,failed,175,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:182,integrability,state,state,182,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:65,performance,failur,failures,65,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:84,performance,failur,failures,84,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:120,performance,failur,failures,120,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:159,performance,failur,failures,159,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:65,reliability,fail,failures,65,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:84,reliability,fail,failures,84,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:105,reliability,fail,fail,105,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:120,reliability,fail,failures,120,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:159,reliability,fail,failures,159,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:175,reliability,fail,failed,175,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:79,safety,test,test,79,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:154,safety,test,test,154,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:79,testability,test,test,79,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:154,testability,test,test,154,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:29,usability,clear,clear,29,"Right - @smuzaffar was quite clear that we should separate build failures from test failures. But we now fail for build failures, too, so maybe including test failures in the failed state makes sense? Anyway, just pinging @smuzaffar for his recommendation + arguments before we decide what to do here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:131,availability,failur,failure,131,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:225,availability,failur,failure,225,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:344,availability,failur,failure,344,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:59,deployability,fail,fail,59,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:117,deployability,build,build,117,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:131,deployability,fail,failure,131,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:182,deployability,fail,failed,182,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:225,deployability,fail,failure,225,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:245,deployability,infrastructur,infrastructure,245,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:344,deployability,fail,failure,344,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:131,performance,failur,failure,131,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:225,performance,failur,failure,225,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:344,performance,failur,failure,344,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:59,reliability,fail,fail,59,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:131,reliability,fail,failure,131,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:182,reliability,fail,failed,182,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:225,reliability,fail,failure,225,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:344,reliability,fail,failure,344,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:126,safety,test,test,126,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:296,safety,test,test,296,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:126,testability,test,test,126,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:296,testability,test,test,296,"@Axel-Naumann , yes, for github actions, it makes sense to fail for every thing which should not happen either it is build or test failure. My recommendation for not marking the job failed was for Jenkins type CI where a job failure should mean infrastructure issues which Jenkin's admins (or CI test developers) should look in to. Every other failure should be reported to the code developers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:199,availability,failur,failures,199,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:5,deployability,fail,failing,5,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:199,deployability,fail,failures,199,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:199,performance,failur,failures,199,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:5,reliability,fail,failing,5,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:199,reliability,fail,failures,199,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:41,safety,test,test,41,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:103,safety,test,test,103,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:194,safety,test,test,194,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:41,testability,test,test,41,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:103,testability,test,test,103,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:194,testability,test,test,194,"FWIW failing the job seems to render the test summary less useful because it only shows the succeeding test suites... edit: ah, can be ""fixed"" by always running the upload step, even in case of test failures; see https://github.com/root-project/root/pull/12822",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:28,deployability,artifact,artifacts,28,Another implication is that artifacts weren't uploaded anymore if testing failed; fixed in https://github.com/root-project/root/pull/12830,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:74,deployability,fail,failed,74,Another implication is that artifacts weren't uploaded anymore if testing failed; fixed in https://github.com/root-project/root/pull/12830,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:74,reliability,fail,failed,74,Another implication is that artifacts weren't uploaded anymore if testing failed; fixed in https://github.com/root-project/root/pull/12830,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:66,safety,test,testing,66,Another implication is that artifacts weren't uploaded anymore if testing failed; fixed in https://github.com/root-project/root/pull/12830,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:66,testability,test,testing,66,Another implication is that artifacts weren't uploaded anymore if testing failed; fixed in https://github.com/root-project/root/pull/12830,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/pull/12308:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:59,availability,failur,failure,59,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:133,availability,error,error,133,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:53,deployability,build,build,53,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:59,deployability,fail,failure,59,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:99,deployability,configurat,configuration,99,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:150,deployability,build,build,150,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:99,integrability,configur,configuration,99,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:99,modifiability,configur,configuration,99,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:59,performance,failur,failure,59,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:133,performance,error,error,133,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:59,reliability,fail,failure,59,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:133,safety,error,error,133,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:99,security,configur,configuration,99,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:133,usability,error,error,133,Good catch @ACA4DFA4 ! I wonder why we don't see the build failure in our CI. Can you tell us your configuration and how you got the error during the build ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:27,safety,valid,valid,27,"I think the code before is valid C++, since you can convert `const char * ` to std::string and you can do:. ```. std::string s = "" this "" + std::string(""works "");. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:177,availability,operat,operator,177,"But the code before was doing . ```cpp. ""Key ""+key+"" does not exist in the dictionary."". ```. Which is `const char *` + `const char *` + `const char *`, which do not implement `operator+`. Or am I missing something? [godbolt example](https://godbolt.org/z/4zTszedTT)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:53,reliability,doe,does,53,"But the code before was doing . ```cpp. ""Key ""+key+"" does not exist in the dictionary."". ```. Which is `const char *` + `const char *` + `const char *`, which do not implement `operator+`. Or am I missing something? [godbolt example](https://godbolt.org/z/4zTszedTT)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:72,deployability,configurat,configuration,72,"Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:117,deployability,build,build,117,"Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:72,integrability,configur,configuration,72,"Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:72,modifiability,configur,configuration,72,"Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:72,security,configur,configuration,72,"Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:5,testability,understand,understand,5,"Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:221,availability,down,downloaded,221,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:74,deployability,configurat,configuration,74,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:119,deployability,build,build,119,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:185,deployability,releas,released,185,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:201,deployability,Releas,Releases,201,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:481,deployability,instal,installed,481,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:546,deployability,instal,installed,546,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:569,deployability,version,versions,569,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:654,deployability,configurat,configuration,654,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:824,deployability,Modul,Module,824,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:857,deployability,version,version,857,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:919,deployability,version,version,919,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:997,deployability,Modul,Module,997,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1031,deployability,Build,Building,1031,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1105,deployability,version,version,1105,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1406,deployability,instal,installed,1406,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:74,integrability,configur,configuration,74,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:569,integrability,version,versions,569,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:654,integrability,configur,configuration,654,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:857,integrability,version,version,857,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:919,integrability,version,version,919,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:943,integrability,compon,components,943,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1105,integrability,version,version,1105,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1155,integrability,compon,components,1155,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:316,interoperability,distribut,distributions,316,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:943,interoperability,compon,components,943,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1155,interoperability,compon,components,1155,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:74,modifiability,configur,configuration,74,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:569,modifiability,version,versions,569,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:622,modifiability,pac,packages,622,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:654,modifiability,configur,configuration,654,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:824,modifiability,Modul,Module,824,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:857,modifiability,version,version,857,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:919,modifiability,version,version,919,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:943,modifiability,compon,components,943,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:997,modifiability,Modul,Module,997,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1105,modifiability,version,version,1105,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1155,modifiability,compon,components,1155,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1292,performance,time,time,1292,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:824,safety,Modul,Module,824,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:997,safety,Modul,Module,997,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:74,security,configur,configuration,74,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:654,security,configur,configuration,654,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:7,testability,understand,understand,7,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:1122,usability,minim,minimum,1122,"> Ok I understand. I would wait for @ACA4DFA4 to tell us more about their configuration, including why do they need to build with Python2. Yesterday I just found that root-v6.28/00 was released on the Releases page, then downloaded the tarball and built it with `cmake` (`-DCMAKE_CXX_STANDARD=17`), since the binary distributions don't have ROOT7 features. The OS was Ubuntu 18.04 on Windows 10 (WSL1), and there were `python3.8.0`, `python3.7.5`, `python3.6.9` and `python2.7.17` installed. The default `python3` was `python3.6.9`, with `numpy` installed. The other 2 versions of python3 didn't have `numpy` or any other packages. The output of `cmake` configuration about python was:. ```. -- Could NOT find Python3 (missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS Development NumPy Development.Module Development.Embed) (found version ""3.8.0""). -- Found Python2: /usr/bin/python2.7 (found version ""2.7.17"") found components: Interpreter Development NumPy Development.Module Development.Embed . ... -- Building with -fPIC. -- Found Python3: /usr/bin/python3.8 (found suitable version ""3.8.0"", minimum required is ""3.0"") found components: Interpreter . ```. I don't know why `python3.6` was not chosen but `python3.8`, and why `python3` was not found at the first time. In fact, I have built root-v6.26/00 with `python3.6` successfully when `python3.7` and `python3.8` were not installed before.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:483,availability,error,error,483,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:301,deployability,instal,install,301,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:398,deployability,build,build,398,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:455,integrability,compon,components,455,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:455,interoperability,compon,components,455,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:455,modifiability,compon,components,455,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:483,performance,error,error,483,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:483,safety,error,error,483,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:483,usability,error,error,483,"@ACA4DFA4 the Python executable chosen should be whatever `python3` points to, which probably will be `python3.8`. In the output you pasted, `python3.8` is actually found, what is not found is `missing: Python3_INCLUDE_DIRS Python3_LIBRARIES Python3_NumPy_INCLUDE_DIRS...`. It might be enough to just install `numpy` with `python3`, but that's beside the point of this PR. In your case PyROOT will build directly with Python2 since there are some missing components for 3, hence the error you found. Thanks for the fix! This PR can be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12309:204,availability,mainten,maintenance,204,The prune-container step would have to run `n_runners` times in a matrix to be helpful and it also pollutes the PR job overview. Additionally it shouldn't be the job of the workflow definition to do node maintenance. Decided to move this functionality in the puppet files instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:10,deployability,contain,container,10,The prune-container step would have to run `n_runners` times in a matrix to be helpful and it also pollutes the PR job overview. Additionally it shouldn't be the job of the workflow definition to do node maintenance. Decided to move this functionality in the puppet files instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:55,performance,time,times,55,The prune-container step would have to run `n_runners` times in a matrix to be helpful and it also pollutes the PR job overview. Additionally it shouldn't be the job of the workflow definition to do node maintenance. Decided to move this functionality in the puppet files instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:204,reliability,mainten,maintenance,204,The prune-container step would have to run `n_runners` times in a matrix to be helpful and it also pollutes the PR job overview. Additionally it shouldn't be the job of the workflow definition to do node maintenance. Decided to move this functionality in the puppet files instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:79,usability,help,helpful,79,The prune-container step would have to run `n_runners` times in a matrix to be helpful and it also pollutes the PR job overview. Additionally it shouldn't be the job of the workflow definition to do node maintenance. Decided to move this functionality in the puppet files instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:173,usability,workflow,workflow,173,The prune-container step would have to run `n_runners` times in a matrix to be helpful and it also pollutes the PR job overview. Additionally it shouldn't be the job of the workflow definition to do node maintenance. Decided to move this functionality in the puppet files instead.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12310:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12310
https://github.com/root-project/root/pull/12314:38,energy efficiency,measur,measure,38,Awesome! Can we also add `codecov` to measure given PR test coverage? You can take a look at https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:55,safety,test,test,55,Awesome! Can we also add `codecov` to measure given PR test coverage? You can take a look at https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:55,testability,test,test,55,Awesome! Can we also add `codecov` to measure given PR test coverage? You can take a look at https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:60,testability,coverag,coverage,60,Awesome! Can we also add `codecov` to measure given PR test coverage? You can take a look at https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:182,usability,workflow,workflows,182,Awesome! Can we also add `codecov` to measure given PR test coverage? You can take a look at https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:38,energy efficiency,measur,measure,38,"> Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:55,safety,test,test,55,"> Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:55,testability,test,test,55,"> Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:60,testability,coverag,coverage,60,"> Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:126,usability,workflow,workflows,126,"> Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:243,usability,workflow,workflows,243,"> Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:40,energy efficiency,measur,measure,40,"> > Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). > . > Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-). I did not intend to ask about it in the context of this PR. It was more towards being a very similar feature that's easy to reach.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:57,safety,test,test,57,"> > Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). > . > Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-). I did not intend to ask about it in the context of this PR. It was more towards being a very similar feature that's easy to reach.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:57,testability,test,test,57,"> > Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). > . > Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-). I did not intend to ask about it in the context of this PR. It was more towards being a very similar feature that's easy to reach.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:62,testability,coverag,coverage,62,"> > Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). > . > Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-). I did not intend to ask about it in the context of this PR. It was more towards being a very similar feature that's easy to reach.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:458,testability,context,context,458,"> > Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). > . > Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-). I did not intend to ask about it in the context of this PR. It was more towards being a very similar feature that's easy to reach.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:128,usability,workflow,workflows,128,"> > Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). > . > Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-). I did not intend to ask about it in the context of this PR. It was more towards being a very similar feature that's easy to reach.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:245,usability,workflow,workflows,245,"> > Awesome! Can we also add codecov to measure given PR test coverage? You can take a look at [vgvassilev/clad@57345cf/.github/workflows/ci.yml#L737-L741](https://github.com/vgvassilev/clad/blob/57345cfae9fd3c1ad2fc1f5a4e2e95e0ee4a68ac/.github/workflows/ci.yml#L737-L741). > . > Certainly (I think we have an issue up for this, please check, @vgvassilev or open one). Codecov shouldn't be part of this PR though :-). I did not intend to ask about it in the context of this PR. It was more towards being a very similar feature that's easy to reach.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12315:47,availability,Error,Error,47,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:255,integrability,configur,configure,255,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:232,modifiability,pac,package,232,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:255,modifiability,configur,configure,255,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:47,performance,Error,Error,47,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:47,safety,Error,Error,47,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:255,security,configur,configure,255,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:47,usability,Error,Error,47,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:212,usability,support,support,212,"@agheata What do we need to do to solve:. ```. Error in <TVirtualGeoConverter::Instance()>: . +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:57,availability,Error,Error,57,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:269,integrability,configur,configure,269,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:246,modifiability,pac,package,246,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:269,modifiability,configur,configure,269,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:57,performance,Error,Error,57,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:57,safety,Error,Error,57,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:269,security,configur,configure,269,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:57,usability,Error,Error,57,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:226,usability,support,support,226,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:392,usability,behavi,behavior,392,"> @agheata What do we need to do to solve:. > . > ```. > Error in <TVirtualGeoConverter::Instance()>: . > +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. > It appears that you are missing or having outdated support for VecGeom package. To enable it, configure ROOT with:. > -Dvecgeom -DCMAKE_PREFIX_PATH=<vecgeom_prefix_path>/lib/CMake/VecGeom. > ```. This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:42,availability,error,error,42,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:139,availability,error,errors,139,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:278,availability,Error,Error,278,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:591,availability,error,errors,591,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:248,deployability,Modul,Module,248,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:555,deployability,modul,module,555,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:234,energy efficiency,Load,LoadPlugin,234,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:296,energy efficiency,Load,LoadPCM,296,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:430,energy efficiency,Load,LoadPCM,430,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:28,integrability,transform,transform,28,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:28,interoperability,transform,transform,28,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:107,interoperability,plug,plugin,107,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:248,modifiability,Modul,Module,248,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:555,modifiability,modul,module,555,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:42,performance,error,error,42,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:139,performance,error,errors,139,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:234,performance,Load,LoadPlugin,234,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:278,performance,Error,Error,278,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:296,performance,Load,LoadPCM,296,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:430,performance,Load,LoadPCM,430,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:591,performance,error,errors,591,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:63,reliability,doe,does,63,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:382,reliability,doe,does,382,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:42,safety,error,error,42,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:139,safety,error,errors,139,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:248,safety,Modul,Module,248,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:278,safety,Error,Error,278,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:555,safety,modul,module,555,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:591,safety,error,errors,591,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:42,usability,error,error,42,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:94,usability,support,support,94,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:139,usability,error,errors,139,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:278,usability,Error,Error,278,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:316,usability,User,Users,316,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:591,usability,error,errors,591,"@pcanal actually my idea to transform the error into a warning does not work: without VecGeom support, the plugin mechanism already issues errors if I do:. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. The return value looks wrong by the way, I would expect -1 in this case. Is there a way to check if a module was compiled without issuing errors?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:11,deployability,build,build,11,@phsft-bot build just on ROOT-performance-centos8-multicore/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:30,performance,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:30,usability,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:251,availability,failur,failure,251,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:251,deployability,fail,failure,251,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:306,deployability,build,build,306,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:251,performance,failur,failure,251,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:251,reliability,fail,failure,251,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:312,reliability,doe,does,312,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:242,safety,test,test,242,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:294,safety,test,test,294,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:242,testability,test,test,242,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:294,testability,test,test,294,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:23,usability,behavi,behavior,23,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:321,usability,support,support,321,"> This is the intended behavior for this macro, i.e. it cannot work as intended if the VecGeom converter cannot be instantiated. However, I can make it issue a warning instead, and do raytracing using the unconverted shape. Are you trying to test the failure mode or should we just not run the test if the build does not support it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:29,availability,failur,failure,29,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:29,deployability,fail,failure,29,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:84,deployability,build,build,84,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:152,deployability,build,builds,152,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:29,performance,failur,failure,29,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:29,reliability,fail,failure,29,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:90,reliability,doe,does,90,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:20,safety,test,test,20,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:72,safety,test,test,72,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:115,safety,test,test,115,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:202,safety,test,test,202,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:20,testability,test,test,20,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:72,testability,test,test,72,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:115,testability,test,test,115,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:202,testability,test,test,202,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:99,usability,support,support,99,"> Are you trying to test the failure mode or should we just not run the test if the build does not support it? The test should not run in inappropriate builds, @Axel-Naumann told me how to veto out the test if vecgeom is not enabled, and it seems to work, so we can merge this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12316:4,deployability,fail,failing,4,"The failing tests are due to a mismatch with the key in `fDatasetGroupMap` at https://github.com/root-project/root/blob/000d367906f4dbdd78a78ab26a2d81145ac10321/tree/dataframe/src/RLoopManager.cxx#L718-L720. Other than that, there are other places where `""/""` is still used, e.g. in `RDatasetGroup.cxx` and we should see whether the syntax should be changed there too",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:31,interoperability,mismatch,mismatch,31,"The failing tests are due to a mismatch with the key in `fDatasetGroupMap` at https://github.com/root-project/root/blob/000d367906f4dbdd78a78ab26a2d81145ac10321/tree/dataframe/src/RLoopManager.cxx#L718-L720. Other than that, there are other places where `""/""` is still used, e.g. in `RDatasetGroup.cxx` and we should see whether the syntax should be changed there too",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:4,reliability,fail,failing,4,"The failing tests are due to a mismatch with the key in `fDatasetGroupMap` at https://github.com/root-project/root/blob/000d367906f4dbdd78a78ab26a2d81145ac10321/tree/dataframe/src/RLoopManager.cxx#L718-L720. Other than that, there are other places where `""/""` is still used, e.g. in `RDatasetGroup.cxx` and we should see whether the syntax should be changed there too",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:12,safety,test,tests,12,"The failing tests are due to a mismatch with the key in `fDatasetGroupMap` at https://github.com/root-project/root/blob/000d367906f4dbdd78a78ab26a2d81145ac10321/tree/dataframe/src/RLoopManager.cxx#L718-L720. Other than that, there are other places where `""/""` is still used, e.g. in `RDatasetGroup.cxx` and we should see whether the syntax should be changed there too",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:12,testability,test,tests,12,"The failing tests are due to a mismatch with the key in `fDatasetGroupMap` at https://github.com/root-project/root/blob/000d367906f4dbdd78a78ab26a2d81145ac10321/tree/dataframe/src/RLoopManager.cxx#L718-L720. Other than that, there are other places where `""/""` is still used, e.g. in `RDatasetGroup.cxx` and we should see whether the syntax should be changed there too",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:44,security,RSa,RSampleInfo,44,"mmmh crap, we promise users that the id in `RSampleInfo` will be of the form `<filename>/<treename>`: https://github.com/root-project/root/blob/7c81a10d9fa965b25f35b0ec709d6095a209ac16/tree/dataframe/inc/ROOT/RDF/RSampleInfo.hxx#L30-L31. Thinking...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:213,security,RSa,RSampleInfo,213,"mmmh crap, we promise users that the id in `RSampleInfo` will be of the form `<filename>/<treename>`: https://github.com/root-project/root/blob/7c81a10d9fa965b25f35b0ec709d6095a209ac16/tree/dataframe/inc/ROOT/RDF/RSampleInfo.hxx#L30-L31. Thinking...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:22,usability,user,users,22,"mmmh crap, we promise users that the id in `RSampleInfo` will be of the form `<filename>/<treename>`: https://github.com/root-project/root/blob/7c81a10d9fa965b25f35b0ec709d6095a209ac16/tree/dataframe/inc/ROOT/RDF/RSampleInfo.hxx#L30-L31. Thinking...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:20,interoperability,conflict,conflicts,20,Force-pushed to fix conflicts.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/issues/12319:111,deployability,updat,update,111,"# 6.28.04. **Other items** that still need to be done without any associated GitHub issue:. - [x] `RooFitHS3`: update the docs to reflect the namespace change to `RooFit::JSONIO`. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/11942. - [x] https://github.com/root-project/root/pull/9539. The final commit with the code modernization (others have already been backported in #11960). - [x] https://github.com/root-project/root/pull/11963. - [x] https://github.com/root-project/root/pull/12015. - [x] https://github.com/root-project/root/pull/12022. Only the last one about throwing the exception in `RooAbsArg::redirectServers (the other commits have been backported already in #12057 and #12092). - [x] https://github.com/root-project/root/pull/12180. - [x] https://github.com/root-project/root/pull/12223. - [x] https://github.com/root-project/root/pull/12232. - [x] https://github.com/root-project/root/pull/12219. Except for the first and last commit that relate to the RooFit AD work. - [x] https://github.com/root-project/root/pull/12304. - [x] https://github.com/root-project/root/pull/12442. Only the first two commits that were not already backported. - [x] https://github.com/root-project/root/pull/12447. - [x] https://github.com/root-project/root/pull/12227. - [x] https://github.com/root-project/root/pull/12016. Only the commits 1, 2, 5, 6, 8 that don't change the definition of `RooNumber::infinity()`. - [x] https://github.com/root-project/root/pull/12328. - [x] https://github.com/root-project/root/pull/12330. - [x] https://github.com/root-project/root/pull/12207. - [x] https://github.com/root-project/root/pull/12392. - [x] https://github.com/root-project/root/pull/12340. - [x] https://github.com/root-project/root/pull/12399. - [x] https://github.com/root-project/root/pull/12413. Except for commits 5 and 6 that are un",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:3905,deployability,patch,patches,3905,ject/root/pull/12504. - [x] https://github.com/root-project/root/pull/12459. - [x] https://github.com/root-project/root/pull/12518. - [x] https://github.com/root-project/root/pull/12556. - [x] https://github.com/root-project/root/pull/12578. - [x] https://github.com/root-project/root/pull/12577. - [x] https://github.com/root-project/root/pull/12595. - [x] https://github.com/root-project/root/pull/12608. Only the second commit that does not remove deprecated functionality. - [x] https://github.com/root-project/root/pull/12594. - [x] https://github.com/root-project/root/pull/12640. - [x] https://github.com/root-project/root/pull/12638. - [x] https://github.com/root-project/root/pull/12636. - [x] https://github.com/root-project/root/pull/12614. - [x] https://github.com/root-project/root/pull/12643. - [x] https://github.com/root-project/root/pull/12641. - [x] https://github.com/root-project/root/pull/12647. - [x] https://github.com/root-project/root/pull/12660. - [x] https://github.com/root-project/root/pull/12668. - [x] https://github.com/root-project/root/pull/12682. - [x] https://github.com/root-project/root/pull/12696. - [x] https://github.com/root-project/root/pull/12699. - [x] https://github.com/root-project/root/pull/12702. - [x] https://github.com/root-project/root/pull/12707. - [x] https://github.com/root-project/root/pull/12719. - [x] https://github.com/root-project/root/pull/12658. - [x] https://github.com/root-project/root/pull/12725. - [x] https://github.com/root-project/root/pull/12141. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12590. 2. https://github.com/root-project/root/pull/12618. 3. https://github.com/root-project/root/pull/12620. 4. https://github.com/root-project/root/pull/12630. 5. https://github.com/root-project/root/pull/12681. 6. https://github.com/root-project/root/pull/12708. 7. https://github.com/root-project/root/pull/12723. 8. https://github.com/root-project/root/pull/12733,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:2765,reliability,doe,does,2765,root-project/root/pull/12392. - [x] https://github.com/root-project/root/pull/12340. - [x] https://github.com/root-project/root/pull/12399. - [x] https://github.com/root-project/root/pull/12413. Except for commits 5 and 6 that are unrelated to RooFitHS3. - [x] https://github.com/root-project/root/pull/12467. - [x] https://github.com/root-project/root/pull/12471. - [x] https://github.com/root-project/root/pull/12470. - [x] https://github.com/root-project/root/pull/12487. - [x] https://github.com/root-project/root/pull/12490. - [x] https://github.com/root-project/root/pull/12504. - [x] https://github.com/root-project/root/pull/12459. - [x] https://github.com/root-project/root/pull/12518. - [x] https://github.com/root-project/root/pull/12556. - [x] https://github.com/root-project/root/pull/12578. - [x] https://github.com/root-project/root/pull/12577. - [x] https://github.com/root-project/root/pull/12595. - [x] https://github.com/root-project/root/pull/12608. Only the second commit that does not remove deprecated functionality. - [x] https://github.com/root-project/root/pull/12594. - [x] https://github.com/root-project/root/pull/12640. - [x] https://github.com/root-project/root/pull/12638. - [x] https://github.com/root-project/root/pull/12636. - [x] https://github.com/root-project/root/pull/12614. - [x] https://github.com/root-project/root/pull/12643. - [x] https://github.com/root-project/root/pull/12641. - [x] https://github.com/root-project/root/pull/12647. - [x] https://github.com/root-project/root/pull/12660. - [x] https://github.com/root-project/root/pull/12668. - [x] https://github.com/root-project/root/pull/12682. - [x] https://github.com/root-project/root/pull/12696. - [x] https://github.com/root-project/root/pull/12699. - [x] https://github.com/root-project/root/pull/12702. - [x] https://github.com/root-project/root/pull/12707. - [x] https://github.com/root-project/root/pull/12719. - [x] https://github.com/root-project/root/pull/12658. - [x] https://github.com/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:111,safety,updat,update,111,"# 6.28.04. **Other items** that still need to be done without any associated GitHub issue:. - [x] `RooFitHS3`: update the docs to reflect the namespace change to `RooFit::JSONIO`. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/11942. - [x] https://github.com/root-project/root/pull/9539. The final commit with the code modernization (others have already been backported in #11960). - [x] https://github.com/root-project/root/pull/11963. - [x] https://github.com/root-project/root/pull/12015. - [x] https://github.com/root-project/root/pull/12022. Only the last one about throwing the exception in `RooAbsArg::redirectServers (the other commits have been backported already in #12057 and #12092). - [x] https://github.com/root-project/root/pull/12180. - [x] https://github.com/root-project/root/pull/12223. - [x] https://github.com/root-project/root/pull/12232. - [x] https://github.com/root-project/root/pull/12219. Except for the first and last commit that relate to the RooFit AD work. - [x] https://github.com/root-project/root/pull/12304. - [x] https://github.com/root-project/root/pull/12442. Only the first two commits that were not already backported. - [x] https://github.com/root-project/root/pull/12447. - [x] https://github.com/root-project/root/pull/12227. - [x] https://github.com/root-project/root/pull/12016. Only the commits 1, 2, 5, 6, 8 that don't change the definition of `RooNumber::infinity()`. - [x] https://github.com/root-project/root/pull/12328. - [x] https://github.com/root-project/root/pull/12330. - [x] https://github.com/root-project/root/pull/12207. - [x] https://github.com/root-project/root/pull/12392. - [x] https://github.com/root-project/root/pull/12340. - [x] https://github.com/root-project/root/pull/12399. - [x] https://github.com/root-project/root/pull/12413. Except for commits 5 and 6 that are un",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:745,safety,except,exception,745,"# 6.28.04. **Other items** that still need to be done without any associated GitHub issue:. - [x] `RooFitHS3`: update the docs to reflect the namespace change to `RooFit::JSONIO`. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/11942. - [x] https://github.com/root-project/root/pull/9539. The final commit with the code modernization (others have already been backported in #11960). - [x] https://github.com/root-project/root/pull/11963. - [x] https://github.com/root-project/root/pull/12015. - [x] https://github.com/root-project/root/pull/12022. Only the last one about throwing the exception in `RooAbsArg::redirectServers (the other commits have been backported already in #12057 and #12092). - [x] https://github.com/root-project/root/pull/12180. - [x] https://github.com/root-project/root/pull/12223. - [x] https://github.com/root-project/root/pull/12232. - [x] https://github.com/root-project/root/pull/12219. Except for the first and last commit that relate to the RooFit AD work. - [x] https://github.com/root-project/root/pull/12304. - [x] https://github.com/root-project/root/pull/12442. Only the first two commits that were not already backported. - [x] https://github.com/root-project/root/pull/12447. - [x] https://github.com/root-project/root/pull/12227. - [x] https://github.com/root-project/root/pull/12016. Only the commits 1, 2, 5, 6, 8 that don't change the definition of `RooNumber::infinity()`. - [x] https://github.com/root-project/root/pull/12328. - [x] https://github.com/root-project/root/pull/12330. - [x] https://github.com/root-project/root/pull/12207. - [x] https://github.com/root-project/root/pull/12392. - [x] https://github.com/root-project/root/pull/12340. - [x] https://github.com/root-project/root/pull/12399. - [x] https://github.com/root-project/root/pull/12413. Except for commits 5 and 6 that are un",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:1077,safety,Except,Except,1077,"Hub issue:. - [x] `RooFitHS3`: update the docs to reflect the namespace change to `RooFit::JSONIO`. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/11942. - [x] https://github.com/root-project/root/pull/9539. The final commit with the code modernization (others have already been backported in #11960). - [x] https://github.com/root-project/root/pull/11963. - [x] https://github.com/root-project/root/pull/12015. - [x] https://github.com/root-project/root/pull/12022. Only the last one about throwing the exception in `RooAbsArg::redirectServers (the other commits have been backported already in #12057 and #12092). - [x] https://github.com/root-project/root/pull/12180. - [x] https://github.com/root-project/root/pull/12223. - [x] https://github.com/root-project/root/pull/12232. - [x] https://github.com/root-project/root/pull/12219. Except for the first and last commit that relate to the RooFit AD work. - [x] https://github.com/root-project/root/pull/12304. - [x] https://github.com/root-project/root/pull/12442. Only the first two commits that were not already backported. - [x] https://github.com/root-project/root/pull/12447. - [x] https://github.com/root-project/root/pull/12227. - [x] https://github.com/root-project/root/pull/12016. Only the commits 1, 2, 5, 6, 8 that don't change the definition of `RooNumber::infinity()`. - [x] https://github.com/root-project/root/pull/12328. - [x] https://github.com/root-project/root/pull/12330. - [x] https://github.com/root-project/root/pull/12207. - [x] https://github.com/root-project/root/pull/12392. - [x] https://github.com/root-project/root/pull/12340. - [x] https://github.com/root-project/root/pull/12399. - [x] https://github.com/root-project/root/pull/12413. Except for commits 5 and 6 that are unrelated to RooFitHS3. - [x] https://github.com/root-project/root/pull/12467. - [",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:1962,safety,Except,Except,1962,". - [x] https://github.com/root-project/root/pull/12232. - [x] https://github.com/root-project/root/pull/12219. Except for the first and last commit that relate to the RooFit AD work. - [x] https://github.com/root-project/root/pull/12304. - [x] https://github.com/root-project/root/pull/12442. Only the first two commits that were not already backported. - [x] https://github.com/root-project/root/pull/12447. - [x] https://github.com/root-project/root/pull/12227. - [x] https://github.com/root-project/root/pull/12016. Only the commits 1, 2, 5, 6, 8 that don't change the definition of `RooNumber::infinity()`. - [x] https://github.com/root-project/root/pull/12328. - [x] https://github.com/root-project/root/pull/12330. - [x] https://github.com/root-project/root/pull/12207. - [x] https://github.com/root-project/root/pull/12392. - [x] https://github.com/root-project/root/pull/12340. - [x] https://github.com/root-project/root/pull/12399. - [x] https://github.com/root-project/root/pull/12413. Except for commits 5 and 6 that are unrelated to RooFitHS3. - [x] https://github.com/root-project/root/pull/12467. - [x] https://github.com/root-project/root/pull/12471. - [x] https://github.com/root-project/root/pull/12470. - [x] https://github.com/root-project/root/pull/12487. - [x] https://github.com/root-project/root/pull/12490. - [x] https://github.com/root-project/root/pull/12504. - [x] https://github.com/root-project/root/pull/12459. - [x] https://github.com/root-project/root/pull/12518. - [x] https://github.com/root-project/root/pull/12556. - [x] https://github.com/root-project/root/pull/12578. - [x] https://github.com/root-project/root/pull/12577. - [x] https://github.com/root-project/root/pull/12595. - [x] https://github.com/root-project/root/pull/12608. Only the second commit that does not remove deprecated functionality. - [x] https://github.com/root-project/root/pull/12594. - [x] https://github.com/root-project/root/pull/12640. - [x] https://github.com/root-project/root/pull/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:3905,safety,patch,patches,3905,ject/root/pull/12504. - [x] https://github.com/root-project/root/pull/12459. - [x] https://github.com/root-project/root/pull/12518. - [x] https://github.com/root-project/root/pull/12556. - [x] https://github.com/root-project/root/pull/12578. - [x] https://github.com/root-project/root/pull/12577. - [x] https://github.com/root-project/root/pull/12595. - [x] https://github.com/root-project/root/pull/12608. Only the second commit that does not remove deprecated functionality. - [x] https://github.com/root-project/root/pull/12594. - [x] https://github.com/root-project/root/pull/12640. - [x] https://github.com/root-project/root/pull/12638. - [x] https://github.com/root-project/root/pull/12636. - [x] https://github.com/root-project/root/pull/12614. - [x] https://github.com/root-project/root/pull/12643. - [x] https://github.com/root-project/root/pull/12641. - [x] https://github.com/root-project/root/pull/12647. - [x] https://github.com/root-project/root/pull/12660. - [x] https://github.com/root-project/root/pull/12668. - [x] https://github.com/root-project/root/pull/12682. - [x] https://github.com/root-project/root/pull/12696. - [x] https://github.com/root-project/root/pull/12699. - [x] https://github.com/root-project/root/pull/12702. - [x] https://github.com/root-project/root/pull/12707. - [x] https://github.com/root-project/root/pull/12719. - [x] https://github.com/root-project/root/pull/12658. - [x] https://github.com/root-project/root/pull/12725. - [x] https://github.com/root-project/root/pull/12141. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12590. 2. https://github.com/root-project/root/pull/12618. 3. https://github.com/root-project/root/pull/12620. 4. https://github.com/root-project/root/pull/12630. 5. https://github.com/root-project/root/pull/12681. 6. https://github.com/root-project/root/pull/12708. 7. https://github.com/root-project/root/pull/12723. 8. https://github.com/root-project/root/pull/12733,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:111,security,updat,update,111,"# 6.28.04. **Other items** that still need to be done without any associated GitHub issue:. - [x] `RooFitHS3`: update the docs to reflect the namespace change to `RooFit::JSONIO`. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/11942. - [x] https://github.com/root-project/root/pull/9539. The final commit with the code modernization (others have already been backported in #11960). - [x] https://github.com/root-project/root/pull/11963. - [x] https://github.com/root-project/root/pull/12015. - [x] https://github.com/root-project/root/pull/12022. Only the last one about throwing the exception in `RooAbsArg::redirectServers (the other commits have been backported already in #12057 and #12092). - [x] https://github.com/root-project/root/pull/12180. - [x] https://github.com/root-project/root/pull/12223. - [x] https://github.com/root-project/root/pull/12232. - [x] https://github.com/root-project/root/pull/12219. Except for the first and last commit that relate to the RooFit AD work. - [x] https://github.com/root-project/root/pull/12304. - [x] https://github.com/root-project/root/pull/12442. Only the first two commits that were not already backported. - [x] https://github.com/root-project/root/pull/12447. - [x] https://github.com/root-project/root/pull/12227. - [x] https://github.com/root-project/root/pull/12016. Only the commits 1, 2, 5, 6, 8 that don't change the definition of `RooNumber::infinity()`. - [x] https://github.com/root-project/root/pull/12328. - [x] https://github.com/root-project/root/pull/12330. - [x] https://github.com/root-project/root/pull/12207. - [x] https://github.com/root-project/root/pull/12392. - [x] https://github.com/root-project/root/pull/12340. - [x] https://github.com/root-project/root/pull/12399. - [x] https://github.com/root-project/root/pull/12413. Except for commits 5 and 6 that are un",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:3905,security,patch,patches,3905,ject/root/pull/12504. - [x] https://github.com/root-project/root/pull/12459. - [x] https://github.com/root-project/root/pull/12518. - [x] https://github.com/root-project/root/pull/12556. - [x] https://github.com/root-project/root/pull/12578. - [x] https://github.com/root-project/root/pull/12577. - [x] https://github.com/root-project/root/pull/12595. - [x] https://github.com/root-project/root/pull/12608. Only the second commit that does not remove deprecated functionality. - [x] https://github.com/root-project/root/pull/12594. - [x] https://github.com/root-project/root/pull/12640. - [x] https://github.com/root-project/root/pull/12638. - [x] https://github.com/root-project/root/pull/12636. - [x] https://github.com/root-project/root/pull/12614. - [x] https://github.com/root-project/root/pull/12643. - [x] https://github.com/root-project/root/pull/12641. - [x] https://github.com/root-project/root/pull/12647. - [x] https://github.com/root-project/root/pull/12660. - [x] https://github.com/root-project/root/pull/12668. - [x] https://github.com/root-project/root/pull/12682. - [x] https://github.com/root-project/root/pull/12696. - [x] https://github.com/root-project/root/pull/12699. - [x] https://github.com/root-project/root/pull/12702. - [x] https://github.com/root-project/root/pull/12707. - [x] https://github.com/root-project/root/pull/12719. - [x] https://github.com/root-project/root/pull/12658. - [x] https://github.com/root-project/root/pull/12725. - [x] https://github.com/root-project/root/pull/12141. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12590. 2. https://github.com/root-project/root/pull/12618. 3. https://github.com/root-project/root/pull/12620. 4. https://github.com/root-project/root/pull/12630. 5. https://github.com/root-project/root/pull/12681. 6. https://github.com/root-project/root/pull/12708. 7. https://github.com/root-project/root/pull/12723. 8. https://github.com/root-project/root/pull/12733,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:151,deployability,fail,fails,151,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:410,deployability,patch,patch,410,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:416,deployability,releas,release,416,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:2224,deployability,updat,updates,2224,"ot/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull/12974. - [x] https://github.com/root-project/root/pull/12961. - [x] https://github.com/root-project/root/pull/12934. Excluding the 2nd commit that fixes a problem only present in `master`, and excluding the 4th commit that updates the tutorials. - [x] https://github.com/root-project/root/pull/12998. Only the first commit that is not related to AD. - [x] https://github.com/root-project/root/pull/12987. - [x] https://github.com/root-project/root/pull/13020. - [x] https://github.com/root-project/root/pull/13025. - [x] https://github.com/root-project/root/pull/13033. - [x] https://github.com/root-project/root/pull/12970. - [x] https://github.com/root-project/root/pull/13043. - [x] https://github.com/root-project/root/pull/12848. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12905. 2. https://github.com/root-project/root/pull/12971. 3. https://github.com/root-project/root/pull/13044. 4. https://github.com/root-project/root/pull/13295. 5. https://github.com/root-project/root/pull/12849",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:2789,deployability,patch,patches,2789,"ot/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull/12974. - [x] https://github.com/root-project/root/pull/12961. - [x] https://github.com/root-project/root/pull/12934. Excluding the 2nd commit that fixes a problem only present in `master`, and excluding the 4th commit that updates the tutorials. - [x] https://github.com/root-project/root/pull/12998. Only the first commit that is not related to AD. - [x] https://github.com/root-project/root/pull/12987. - [x] https://github.com/root-project/root/pull/13020. - [x] https://github.com/root-project/root/pull/13025. - [x] https://github.com/root-project/root/pull/13033. - [x] https://github.com/root-project/root/pull/12970. - [x] https://github.com/root-project/root/pull/13043. - [x] https://github.com/root-project/root/pull/12848. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12905. 2. https://github.com/root-project/root/pull/12971. 3. https://github.com/root-project/root/pull/13044. 4. https://github.com/root-project/root/pull/13295. 5. https://github.com/root-project/root/pull/12849",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:126,performance,time,timer,126,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:151,reliability,fail,fails,151,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:137,safety,test,test,137,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:266,safety,test,test,266,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:410,safety,patch,patch,410,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:447,safety,Avoid,Avoid,447,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:544,safety,test,test,544,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:610,safety,test,test,610,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:2224,safety,updat,updates,2224,"ot/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull/12974. - [x] https://github.com/root-project/root/pull/12961. - [x] https://github.com/root-project/root/pull/12934. Excluding the 2nd commit that fixes a problem only present in `master`, and excluding the 4th commit that updates the tutorials. - [x] https://github.com/root-project/root/pull/12998. Only the first commit that is not related to AD. - [x] https://github.com/root-project/root/pull/12987. - [x] https://github.com/root-project/root/pull/13020. - [x] https://github.com/root-project/root/pull/13025. - [x] https://github.com/root-project/root/pull/13033. - [x] https://github.com/root-project/root/pull/12970. - [x] https://github.com/root-project/root/pull/13043. - [x] https://github.com/root-project/root/pull/12848. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12905. 2. https://github.com/root-project/root/pull/12971. 3. https://github.com/root-project/root/pull/13044. 4. https://github.com/root-project/root/pull/13295. 5. https://github.com/root-project/root/pull/12849",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:2789,safety,patch,patches,2789,"ot/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull/12974. - [x] https://github.com/root-project/root/pull/12961. - [x] https://github.com/root-project/root/pull/12934. Excluding the 2nd commit that fixes a problem only present in `master`, and excluding the 4th commit that updates the tutorials. - [x] https://github.com/root-project/root/pull/12998. Only the first commit that is not related to AD. - [x] https://github.com/root-project/root/pull/12987. - [x] https://github.com/root-project/root/pull/13020. - [x] https://github.com/root-project/root/pull/13025. - [x] https://github.com/root-project/root/pull/13033. - [x] https://github.com/root-project/root/pull/12970. - [x] https://github.com/root-project/root/pull/13043. - [x] https://github.com/root-project/root/pull/12848. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12905. 2. https://github.com/root-project/root/pull/12971. 3. https://github.com/root-project/root/pull/13044. 4. https://github.com/root-project/root/pull/13295. 5. https://github.com/root-project/root/pull/12849",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:410,security,patch,patch,410,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:2224,security,updat,updates,2224,"ot/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull/12974. - [x] https://github.com/root-project/root/pull/12961. - [x] https://github.com/root-project/root/pull/12934. Excluding the 2nd commit that fixes a problem only present in `master`, and excluding the 4th commit that updates the tutorials. - [x] https://github.com/root-project/root/pull/12998. Only the first commit that is not related to AD. - [x] https://github.com/root-project/root/pull/12987. - [x] https://github.com/root-project/root/pull/13020. - [x] https://github.com/root-project/root/pull/13025. - [x] https://github.com/root-project/root/pull/13033. - [x] https://github.com/root-project/root/pull/12970. - [x] https://github.com/root-project/root/pull/13043. - [x] https://github.com/root-project/root/pull/12848. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12905. 2. https://github.com/root-project/root/pull/12971. 3. https://github.com/root-project/root/pull/13044. 4. https://github.com/root-project/root/pull/13295. 5. https://github.com/root-project/root/pull/12849",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:2789,security,patch,patches,2789,"ot/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull/12974. - [x] https://github.com/root-project/root/pull/12961. - [x] https://github.com/root-project/root/pull/12934. Excluding the 2nd commit that fixes a problem only present in `master`, and excluding the 4th commit that updates the tutorials. - [x] https://github.com/root-project/root/pull/12998. Only the first commit that is not related to AD. - [x] https://github.com/root-project/root/pull/12987. - [x] https://github.com/root-project/root/pull/13020. - [x] https://github.com/root-project/root/pull/13025. - [x] https://github.com/root-project/root/pull/13033. - [x] https://github.com/root-project/root/pull/12970. - [x] https://github.com/root-project/root/pull/13043. - [x] https://github.com/root-project/root/pull/12848. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12905. 2. https://github.com/root-project/root/pull/12971. 3. https://github.com/root-project/root/pull/13044. 4. https://github.com/root-project/root/pull/13295. 5. https://github.com/root-project/root/pull/12849",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:132,testability,unit,unit,132,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:137,testability,test,test,137,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:266,testability,test,test,266,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:539,testability,unit,unit,539,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:544,testability,test,test,544,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:610,testability,test,test,610,"# 6.28.06. **Other items** that still need to be done without any associated GitHub issue:. - [x] Sometimes, the multiprocess timer unit test randomly fails, as for example [here](https://github.com/root-project/root/pull/12000#issuecomment-1377703232). See if this test can be disabled or if we can find an alternative solution, @Zeff020. . **Other items** that are nice to have but can also be in the next **patch release**:. - [x] `RooFitHS3`: Avoid having to import the default export keys from a file manually (e.g. like [here in the unit test](https://github.com/root-project/root/blob/master/roofit/hs3/test/testRooFitHS3.cxx#L47)). **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12768. Only the first commit that fixes a compiler warning. - [x] https://github.com/root-project/root/pull/12809. - [x] https://github.com/root-project/root/pull/12835. - [x] https://github.com/root-project/root/pull/12741. - [x] https://github.com/root-project/root/pull/12880. - [x] https://github.com/root-project/root/pull/12891. - [x] https://github.com/root-project/root/pull/12877. - [x] https://github.com/root-project/root/pull/12896. - [x] https://github.com/root-project/root/pull/12838. - [x] https://github.com/root-project/root/pull/12909. - [x] https://github.com/root-project/root/pull/12916. - [x] https://github.com/root-project/root/pull/12921. - [x] https://github.com/root-project/root/pull/12927. - [x] https://github.com/root-project/root/pull/12925. - [x] https://github.com/root-project/root/pull/12928. - [x] https://github.com/root-project/root/pull/12938. - [x] https://github.com/root-project/root/pull/12936. - [x] https://github.com/root-project/root/pull/12969. - [x] https://github.com/root-project/root/pull/12962. - [x] https://github.com/root-project/root/pull/12973. - [x] https://github.com/root-project/root/pull",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12326:129,availability,error,error,129,"Indeed, this should return -1. Note that I am missing something to reproduce the problem. It my question it returns -1 which any error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:135,integrability,messag,message,135,"Indeed, this should return -1. Note that I am missing something to reproduce the problem. It my question it returns -1 which any error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:135,interoperability,messag,message,135,"Indeed, this should return -1. Note that I am missing something to reproduce the problem. It my question it returns -1 which any error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:129,performance,error,error,129,"Indeed, this should return -1. Note that I am missing something to reproduce the problem. It my question it returns -1 which any error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:129,safety,error,error,129,"Indeed, this should return -1. Note that I am missing something to reproduce the problem. It my question it returns -1 which any error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:129,usability,error,error,129,"Indeed, this should return -1. Note that I am missing something to reproduce the problem. It my question it returns -1 which any error message.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:23,availability,down,down,23,"@pcanal I tracked this down to having libConverterVG.so leftover from a previous VecGeom-enabled installation in my lib folder. Removing the library manually solves the issue. Sorry for the noise, it shows the importance of cleaning up the installation folder after reconfiguring ROOT. I don't know if anything can/needs to be done on the cling side to detect this, so closing this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:97,deployability,instal,installation,97,"@pcanal I tracked this down to having libConverterVG.so leftover from a previous VecGeom-enabled installation in my lib folder. Removing the library manually solves the issue. Sorry for the noise, it shows the importance of cleaning up the installation folder after reconfiguring ROOT. I don't know if anything can/needs to be done on the cling side to detect this, so closing this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:240,deployability,instal,installation,240,"@pcanal I tracked this down to having libConverterVG.so leftover from a previous VecGeom-enabled installation in my lib folder. Removing the library manually solves the issue. Sorry for the noise, it shows the importance of cleaning up the installation folder after reconfiguring ROOT. I don't know if anything can/needs to be done on the cling side to detect this, so closing this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:353,safety,detect,detect,353,"@pcanal I tracked this down to having libConverterVG.so leftover from a previous VecGeom-enabled installation in my lib folder. Removing the library manually solves the issue. Sorry for the noise, it shows the importance of cleaning up the installation folder after reconfiguring ROOT. I don't know if anything can/needs to be done on the cling side to detect this, so closing this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:353,security,detect,detect,353,"@pcanal I tracked this down to having libConverterVG.so leftover from a previous VecGeom-enabled installation in my lib folder. Removing the library manually solves the issue. Sorry for the noise, it shows the importance of cleaning up the installation folder after reconfiguring ROOT. I don't know if anything can/needs to be done on the cling side to detect this, so closing this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/pull/12331:5,performance,disk,disk,5,"> On-disk representation stays as is, 32bit. . Do you mean 'for Index32` ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:506,availability,cluster,clusters,506,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:559,availability,cluster,cluster,559,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:617,availability,error,error,617,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:261,deployability,patch,patch,261,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:281,deployability,patch,patch,281,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:506,deployability,cluster,clusters,506,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:559,deployability,cluster,cluster,559,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:111,energy efficiency,current,current,111,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:515,integrability,event,events,515,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:7,performance,disk,disk,7,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:617,performance,error,error,617,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:261,safety,patch,patch,261,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:281,safety,patch,patch,281,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:617,safety,error,error,617,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:261,security,patch,patch,261,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:281,security,patch,patch,281,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:617,usability,error,error,617,"> > On-disk representation stays as is, 32bit. > . > Do you mean 'for Index32` ? Yes, this applies only to the current PR. The next PR will add the option to choose the column representation between 64bit and 32bit. Once this is merged, I have in mind one more patch. In this last patch, there would be an additional write option like `SetBigClusters()` or so. So when you start writing, you will then be able to bump all index (offset) columns to 64bit, which you would do if you know that you expect big clusters/events. Otherwise and by default, growing a cluster beyond unzipped 512MB [*] would result in a fatal error. [*] As of 512MB, we could have bit vectors with more than 2^32 elements. Perhaps the limit can be a bit higher still (e.g., taking into account the space taken by the index column itself).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:169,deployability,automat,automatic,169,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:220,deployability,fail,fails,220,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:379,energy efficiency,optim,optimization,379,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:310,integrability,event,events,310,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:379,performance,optimiz,optimization,379,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:220,reliability,fail,fails,220,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:169,testability,automat,automatic,169,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:199,usability,user,user,199,> there would be an additional write option like SetBigClusters() or so. This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:712,availability,cluster,clusters,712,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:177,deployability,automat,automatic,177,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:228,deployability,fail,fails,228,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:712,deployability,cluster,clusters,712,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:387,energy efficiency,optim,optimization,387,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:318,integrability,event,events,318,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:701,integrability,event,events,701,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:387,performance,optimiz,optimization,387,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:649,performance,disk,disk,649,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:228,reliability,fail,fails,228,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:177,testability,automat,automatic,177,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:207,usability,user,user,207,"> > there would be an additional write option like SetBigClusters() or so. > . > This might be an okay temporary solution but we probably should think of way to make the switch automatic (we wouldn't want a user many hours jobs fails because the limit is reached unexpectedly because there is a few unexpectedly large events (unless I mis-understood the point/goal and this is 'just' an optimization). Fair point. I guess that's possible but a little hairy to implement correctly. Perhaps as a first step, let's see the difference with splitting and compression in file size between 64bit and 32bit offsets. Because another option would be 64bit on-disk offsets by default and an option ""I promise my events and clusters are small"" `SetSmallClusters()`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12333:46,availability,servic,services,46,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:520,availability,Error,Error,520,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:26,deployability,log,log,26,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:46,deployability,servic,services,46,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:98,deployability,build,build,98,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:148,deployability,build,build,148,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:274,deployability,build,build,274,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:308,deployability,build,build,308,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:314,deployability,build,build,314,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:425,deployability,build,build,425,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:459,deployability,build,build,459,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:465,deployability,build,build,465,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:590,deployability,configurat,configuration,590,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:711,deployability,instal,installation,711,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:798,deployability,contain,containing,798,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:914,deployability,instal,installed,914,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:12,integrability,configur,configure-out,12,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:46,integrability,servic,services,46,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:590,integrability,configur,configuration,590,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:12,modifiability,configur,configure-out,12,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:46,modifiability,servic,services,46,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:582,modifiability,pac,package,582,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:590,modifiability,configur,configuration,590,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:877,modifiability,pac,package,877,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:520,performance,Error,Error,520,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:26,safety,log,log,26,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:520,safety,Error,Error,520,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:12,security,configur,configure-out,12,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:26,security,log,log,26,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:590,security,configur,configuration,590,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:26,testability,log,log,26,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:253,usability,command,command,253,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:341,usability,tool,tools,341,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:404,usability,command,command,404,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:492,usability,tool,tools,492,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12333:520,usability,Error,Error,520,"Nope: [clad-configure-out.log](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/168645/parsed_console/job/root-pullrequests-build/168645/parsed_console/log_content.html#ERROR1) says. ```. CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Warning:. Ignoring extra path from command line:. ""/mnt/build/workspace/root-pullrequests-build/build/interpreter/llvm/src/tools/clang/include"". CMake Error at CMakeLists.txt:110 (find_package):. Could not find a package configuration file provided by ""Clang"" with any of. the following names:. ClangConfig.cmake. clang-config.cmake. Add the installation prefix of ""Clang"" to CMAKE_PREFIX_PATH or set. ""Clang_DIR"" to a directory containing one of the above files. If ""Clang"". provides a separate development package or SDK, be sure it has been. installed. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/pull/12335:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12335
https://github.com/root-project/root/pull/12335:4,availability,failur,failure,4,The failure of `test_stressgraphics` is due to https://github.com/root-project/root/pull/12235.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12335
https://github.com/root-project/root/pull/12335:4,deployability,fail,failure,4,The failure of `test_stressgraphics` is due to https://github.com/root-project/root/pull/12235.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12335
https://github.com/root-project/root/pull/12335:4,performance,failur,failure,4,The failure of `test_stressgraphics` is due to https://github.com/root-project/root/pull/12235.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12335
https://github.com/root-project/root/pull/12335:4,reliability,fail,failure,4,The failure of `test_stressgraphics` is due to https://github.com/root-project/root/pull/12235.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12335
https://github.com/root-project/root/pull/12336:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12336
https://github.com/root-project/root/pull/12336:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12336
https://github.com/root-project/root/pull/12340:166,energy efficiency,model,models,166,"@guitargeek from my side this is ready to merge (I hope). there might be further stuff to be done for the inclusion of more complicated scenarios such as histfactory models with regularization terms, which is WIP, but perhaps this is a good intermediate place to merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:136,modifiability,scenario,scenarios,136,"@guitargeek from my side this is ready to merge (I hope). there might be further stuff to be done for the inclusion of more complicated scenarios such as histfactory models with regularization terms, which is WIP, but perhaps this is a good intermediate place to merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:241,modifiability,interm,intermediate,241,"@guitargeek from my side this is ready to merge (I hope). there might be further stuff to be done for the inclusion of more complicated scenarios such as histfactory models with regularization terms, which is WIP, but perhaps this is a good intermediate place to merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:124,safety,compl,complicated,124,"@guitargeek from my side this is ready to merge (I hope). there might be further stuff to be done for the inclusion of more complicated scenarios such as histfactory models with regularization terms, which is WIP, but perhaps this is a good intermediate place to merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:124,security,compl,complicated,124,"@guitargeek from my side this is ready to merge (I hope). there might be further stuff to be done for the inclusion of more complicated scenarios such as histfactory models with regularization terms, which is WIP, but perhaps this is a good intermediate place to merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:166,security,model,models,166,"@guitargeek from my side this is ready to merge (I hope). there might be further stuff to be done for the inclusion of more complicated scenarios such as histfactory models with regularization terms, which is WIP, but perhaps this is a good intermediate place to merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:12,availability,failur,failures,12,"As the test failures are only related to HistFactory, I think it is better to split this PR in a non-HistFactory and a HistFactory part. The non-HistFactory part is now opened: https://github.com/root-project/root/pull/12392. Once that one is merged, I will rebase this PR such that only the HistFactory commits remain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:12,deployability,fail,failures,12,"As the test failures are only related to HistFactory, I think it is better to split this PR in a non-HistFactory and a HistFactory part. The non-HistFactory part is now opened: https://github.com/root-project/root/pull/12392. Once that one is merged, I will rebase this PR such that only the HistFactory commits remain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:12,performance,failur,failures,12,"As the test failures are only related to HistFactory, I think it is better to split this PR in a non-HistFactory and a HistFactory part. The non-HistFactory part is now opened: https://github.com/root-project/root/pull/12392. Once that one is merged, I will rebase this PR such that only the HistFactory commits remain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:12,reliability,fail,failures,12,"As the test failures are only related to HistFactory, I think it is better to split this PR in a non-HistFactory and a HistFactory part. The non-HistFactory part is now opened: https://github.com/root-project/root/pull/12392. Once that one is merged, I will rebase this PR such that only the HistFactory commits remain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:7,safety,test,test,7,"As the test failures are only related to HistFactory, I think it is better to split this PR in a non-HistFactory and a HistFactory part. The non-HistFactory part is now opened: https://github.com/root-project/root/pull/12392. Once that one is merged, I will rebase this PR such that only the HistFactory commits remain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:7,testability,test,test,7,"As the test failures are only related to HistFactory, I think it is better to split this PR in a non-HistFactory and a HistFactory part. The non-HistFactory part is now opened: https://github.com/root-project/root/pull/12392. Once that one is merged, I will rebase this PR such that only the HistFactory commits remain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12341:94,availability,failur,failures,94,"@bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). Can the commits be squashed and merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12341:94,deployability,fail,failures,94,"@bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). Can the commits be squashed and merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12341:94,performance,failur,failures,94,"@bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). Can the commits be squashed and merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12341:94,reliability,fail,failures,94,"@bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). Can the commits be squashed and merged?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12341:96,availability,failur,failures,96,"> @bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). > . > Can the commits be squashed and merged? Thanks Jonas! I'll cross-check and squash and merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12341:96,deployability,fail,failures,96,"> @bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). > . > Can the commits be squashed and merged? Thanks Jonas! I'll cross-check and squash and merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12341:96,performance,failur,failures,96,"> @bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). > . > Can the commits be squashed and merged? Thanks Jonas! I'll cross-check and squash and merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12341:96,reliability,fail,failures,96,"> @bellenot, this seems to work very well! I was just triggering a CI rerun (the Windows 64 bit failures are unrelated and also seen in other PRs). > . > Can the commits be squashed and merged? Thanks Jonas! I'll cross-check and squash and merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12341
https://github.com/root-project/root/pull/12346:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12346
https://github.com/root-project/root/pull/12348:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:193,deployability,contain,contain,193,"There is a reference (so internally: a pointer) to the RooAbsMinimizerFcn inside the light-weight functors. These functors can still get cloned, right? So is it possible that those clones will contain dangling references?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:408,integrability,wrap,wraps,408,"Yes, you understood this right. Do you think this is a problem? It is not a new behavior in the context of ROOT math: for example the [GradFunctor](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1GradFunctor.html#af7c06950b37bea8844b81f53b0bf41df) does the same, only that it takes the object by pointer and not by reference. In practice `RooAbsMinimizer`, always lives as long as the RooMinimizer that wraps the `ROOT::Math::Minimizer`, so I don't think this is a problem. Or is there something that I forgot to consider?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:253,reliability,doe,does,253,"Yes, you understood this right. Do you think this is a problem? It is not a new behavior in the context of ROOT math: for example the [GradFunctor](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1GradFunctor.html#af7c06950b37bea8844b81f53b0bf41df) does the same, only that it takes the object by pointer and not by reference. In practice `RooAbsMinimizer`, always lives as long as the RooMinimizer that wraps the `ROOT::Math::Minimizer`, so I don't think this is a problem. Or is there something that I forgot to consider?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:334,reliability,pra,practice,334,"Yes, you understood this right. Do you think this is a problem? It is not a new behavior in the context of ROOT math: for example the [GradFunctor](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1GradFunctor.html#af7c06950b37bea8844b81f53b0bf41df) does the same, only that it takes the object by pointer and not by reference. In practice `RooAbsMinimizer`, always lives as long as the RooMinimizer that wraps the `ROOT::Math::Minimizer`, so I don't think this is a problem. Or is there something that I forgot to consider?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:96,testability,context,context,96,"Yes, you understood this right. Do you think this is a problem? It is not a new behavior in the context of ROOT math: for example the [GradFunctor](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1GradFunctor.html#af7c06950b37bea8844b81f53b0bf41df) does the same, only that it takes the object by pointer and not by reference. In practice `RooAbsMinimizer`, always lives as long as the RooMinimizer that wraps the `ROOT::Math::Minimizer`, so I don't think this is a problem. Or is there something that I forgot to consider?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:80,usability,behavi,behavior,80,"Yes, you understood this right. Do you think this is a problem? It is not a new behavior in the context of ROOT math: for example the [GradFunctor](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1GradFunctor.html#af7c06950b37bea8844b81f53b0bf41df) does the same, only that it takes the object by pointer and not by reference. In practice `RooAbsMinimizer`, always lives as long as the RooMinimizer that wraps the `ROOT::Math::Minimizer`, so I don't think this is a problem. Or is there something that I forgot to consider?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:431,usability,Minim,Minimizer,431,"Yes, you understood this right. Do you think this is a problem? It is not a new behavior in the context of ROOT math: for example the [GradFunctor](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1GradFunctor.html#af7c06950b37bea8844b81f53b0bf41df) does the same, only that it takes the object by pointer and not by reference. In practice `RooAbsMinimizer`, always lives as long as the RooMinimizer that wraps the `ROOT::Math::Minimizer`, so I don't think this is a problem. Or is there something that I forgot to consider?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:345,integrability,messag,message,345,"It's not a problem right now, just worried about the future. Some adventurous user may some day take the cloned functor and try to call DoEval when the RooAbsMinimizerFcn is already gone. Making sure it still exists could be done with a `weak_ptr`, but then you need to put the thing itself in a `shared_ptr` as well, which may give off a mixed message...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:345,interoperability,messag,message,345,"It's not a problem right now, just worried about the future. Some adventurous user may some day take the cloned functor and try to call DoEval when the RooAbsMinimizerFcn is already gone. Making sure it still exists could be done with a `weak_ptr`, but then you need to put the thing itself in a `shared_ptr` as well, which may give off a mixed message...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:136,reliability,DoE,DoEval,136,"It's not a problem right now, just worried about the future. Some adventurous user may some day take the cloned functor and try to call DoEval when the RooAbsMinimizerFcn is already gone. Making sure it still exists could be done with a `weak_ptr`, but then you need to put the thing itself in a `shared_ptr` as well, which may give off a mixed message...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:78,usability,user,user,78,"It's not a problem right now, just worried about the future. Some adventurous user may some day take the cloned functor and try to call DoEval when the RooAbsMinimizerFcn is already gone. Making sure it still exists could be done with a `weak_ptr`, but then you need to put the thing itself in a `shared_ptr` as well, which may give off a mixed message...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:363,deployability,resourc,resources,363,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:469,deployability,manag,management,469,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:541,deployability,manag,manage,541,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:552,deployability,resourc,resources,552,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:363,energy efficiency,resourc,resources,363,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:469,energy efficiency,manag,management,469,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:541,energy efficiency,manag,manage,541,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:552,energy efficiency,resourc,resources,552,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:522,integrability,messag,messages,522,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:356,interoperability,share,shared,356,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:522,interoperability,messag,messages,522,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:363,performance,resourc,resources,363,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:462,performance,memor,memory,462,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:552,performance,resourc,resources,552,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:193,safety,compl,complexity,193,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:363,safety,resourc,resources,363,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:433,safety,prevent,prevent,433,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:469,safety,manag,management,469,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:541,safety,manag,manage,541,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:552,safety,resourc,resources,552,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:193,security,compl,complexity,193,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:433,security,preven,prevent,433,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:363,testability,resourc,resources,363,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:552,testability,resourc,resources,552,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:79,usability,User,Users,79,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:160,usability,person,personally,160,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:213,usability,clear,clear,213,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:445,usability,user,user,445,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:462,usability,memor,memory,462,"Well, that argument would apply to 95 % percent of the classes in ROOT then :D Users that are adventurous to use this probably also know about C++ ownership. I personally don't think the added complexity and less clear ownership when using `shared_ptr` + `weak_ptr` is justified in this case. I think `shared_ptr` should only be used when there are really shared resources in the implementation details, not as a general solution to prevent the user from making memory management mistakes. As you say, it gives also mixed messages on how to manage the resources. Would you be okay with leaving it like this for now? We can always revisit this if need be...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:191,integrability,sub,suboptimal,191,"I think the `weak_ptr` is actually meant for exactly cases like this, but the problem is indeed that it needs a `shared_ptr` as well, and if you don't already have that, you're left with two suboptimal design options. C++ needs a `std::non_owning_reference` for this situation. Anyway, sure, let's leave it like this then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:101,deployability,contain,contains,101,"If I have understood well, the issue is that now the Functor class passed to the RooMinimizer/Fitter contains a pointer to the RooMinimizerFcn that can disappear. I think the problem is that we expose the Fitter class in the RooMinimizer and it is a static pointer. The Fitter returns a cloned copy of the FCN (the functor) and it can be alive when the RooMinimizer and RooMinimizerFcn are gone. A possible solution is to change the RooMinimizer to use just the ROOT::Math::Minimizer and do not expose the functor to the user. I think this can be fixed later",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:194,security,expos,expose,194,"If I have understood well, the issue is that now the Functor class passed to the RooMinimizer/Fitter contains a pointer to the RooMinimizerFcn that can disappear. I think the problem is that we expose the Fitter class in the RooMinimizer and it is a static pointer. The Fitter returns a cloned copy of the FCN (the functor) and it can be alive when the RooMinimizer and RooMinimizerFcn are gone. A possible solution is to change the RooMinimizer to use just the ROOT::Math::Minimizer and do not expose the functor to the user. I think this can be fixed later",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:495,security,expos,expose,495,"If I have understood well, the issue is that now the Functor class passed to the RooMinimizer/Fitter contains a pointer to the RooMinimizerFcn that can disappear. I think the problem is that we expose the Fitter class in the RooMinimizer and it is a static pointer. The Fitter returns a cloned copy of the FCN (the functor) and it can be alive when the RooMinimizer and RooMinimizerFcn are gone. A possible solution is to change the RooMinimizer to use just the ROOT::Math::Minimizer and do not expose the functor to the user. I think this can be fixed later",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:474,usability,Minim,Minimizer,474,"If I have understood well, the issue is that now the Functor class passed to the RooMinimizer/Fitter contains a pointer to the RooMinimizerFcn that can disappear. I think the problem is that we expose the Fitter class in the RooMinimizer and it is a static pointer. The Fitter returns a cloned copy of the FCN (the functor) and it can be alive when the RooMinimizer and RooMinimizerFcn are gone. A possible solution is to change the RooMinimizer to use just the ROOT::Math::Minimizer and do not expose the functor to the user. I think this can be fixed later",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:521,usability,user,user,521,"If I have understood well, the issue is that now the Functor class passed to the RooMinimizer/Fitter contains a pointer to the RooMinimizerFcn that can disappear. I think the problem is that we expose the Fitter class in the RooMinimizer and it is a static pointer. The Fitter returns a cloned copy of the FCN (the functor) and it can be alive when the RooMinimizer and RooMinimizerFcn are gone. A possible solution is to change the RooMinimizer to use just the ROOT::Math::Minimizer and do not expose the functor to the user. I think this can be fixed later",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12349:28,reliability,doe,does,28,"Thanks for your fix, but it does not work. The saved image does not correspond to the initial image. See:. <img width=""789"" alt=""Screenshot 2023-02-21 at 15 40 46"" src=""https://user-images.githubusercontent.com/4697738/220375889-e0f3f0d3-dc6a-4323-8dae-39586bb1f0c2.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:59,reliability,doe,does,59,"Thanks for your fix, but it does not work. The saved image does not correspond to the initial image. See:. <img width=""789"" alt=""Screenshot 2023-02-21 at 15 40 46"" src=""https://user-images.githubusercontent.com/4697738/220375889-e0f3f0d3-dc6a-4323-8dae-39586bb1f0c2.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:177,usability,user,user-images,177,"Thanks for your fix, but it does not work. The saved image does not correspond to the initial image. See:. <img width=""789"" alt=""Screenshot 2023-02-21 at 15 40 46"" src=""https://user-images.githubusercontent.com/4697738/220375889-e0f3f0d3-dc6a-4323-8dae-39586bb1f0c2.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:15,safety,review,review,15,@couet can you review my fix?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:15,testability,review,review,15,@couet can you review my fix?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:41,testability,simpl,simplify,41,"I add commit to fix compiler warning and simplify a bit code. @couet, can I merge it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:41,usability,simpl,simplify,41,"I add commit to fix compiler warning and simplify a bit code. @couet, can I merge it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12351:35,availability,avail,available,35,The required backports in LLVM are available here: https://github.com/hahnjo/root/tree/riscv-backports,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:35,reliability,availab,available,35,The required backports in LLVM are available here: https://github.com/hahnjo/root/tree/riscv-backports,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:35,safety,avail,available,35,The required backports in LLVM are available here: https://github.com/hahnjo/root/tree/riscv-backports,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:35,security,availab,available,35,The required backports in LLVM are available here: https://github.com/hahnjo/root/tree/riscv-backports,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:69,energy efficiency,core,core,69,@Axel-Naumann @pcanal I would appreciate one of you looking over the core config part,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12353:15,safety,test,testing,15,"@ellert again, testing on AArch64 would be greatly appreciated! I made sure that the flag makes it to the relevant places (and emits a warning on x86), but I don't think I have an AArch64 system around for easy verification...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:15,testability,test,testing,15,"@ellert again, testing on AArch64 would be greatly appreciated! I made sure that the flag makes it to the relevant places (and emits a warning on x86), but I don't think I have an AArch64 system around for easy verification...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:211,testability,verif,verification,211,"@ellert again, testing on AArch64 would be greatly appreciated! I made sure that the flag makes it to the relevant places (and emits a warning on x86), but I don't think I have an AArch64 system around for easy verification...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:202,availability,echo,echo,202,I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__` . ~~~. [ellert@aarch64-test01 ~][PROD]$ g++ -v 2>&1 | grep Target. Target: aarch64-redhat-linux. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __arm64__. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __aarch64__. #define __aarch64__ 1. ~~~. Compare:. https://github.com/root-project/root/blob/a55cd5db4ba0f9b7811f49d60fdce3fc1f600f39/core/foundation/inc/ROOT/RConfig.hxx#L209. My test with the proposed change from this PR (but with the changed condition) was successful. Thank you!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:280,availability,echo,echo,280,I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__` . ~~~. [ellert@aarch64-test01 ~][PROD]$ g++ -v 2>&1 | grep Target. Target: aarch64-redhat-linux. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __arm64__. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __aarch64__. #define __aarch64__ 1. ~~~. Compare:. https://github.com/root-project/root/blob/a55cd5db4ba0f9b7811f49d60fdce3fc1f600f39/core/foundation/inc/ROOT/RConfig.hxx#L209. My test with the proposed change from this PR (but with the changed condition) was successful. Thank you!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:448,energy efficiency,core,core,448,I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__` . ~~~. [ellert@aarch64-test01 ~][PROD]$ g++ -v 2>&1 | grep Target. Target: aarch64-redhat-linux. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __arm64__. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __aarch64__. #define __aarch64__ 1. ~~~. Compare:. https://github.com/root-project/root/blob/a55cd5db4ba0f9b7811f49d60fdce3fc1f600f39/core/foundation/inc/ROOT/RConfig.hxx#L209. My test with the proposed change from this PR (but with the changed condition) was successful. Thank you!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:494,safety,test,test,494,I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__` . ~~~. [ellert@aarch64-test01 ~][PROD]$ g++ -v 2>&1 | grep Target. Target: aarch64-redhat-linux. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __arm64__. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __aarch64__. #define __aarch64__ 1. ~~~. Compare:. https://github.com/root-project/root/blob/a55cd5db4ba0f9b7811f49d60fdce3fc1f600f39/core/foundation/inc/ROOT/RConfig.hxx#L209. My test with the proposed change from this PR (but with the changed condition) was successful. Thank you!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:494,testability,test,test,494,I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__` . ~~~. [ellert@aarch64-test01 ~][PROD]$ g++ -v 2>&1 | grep Target. Target: aarch64-redhat-linux. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __arm64__. [ellert@aarch64-test01 ~][PROD]$ echo | g++ -dM -E -x c++ - | grep __aarch64__. #define __aarch64__ 1. ~~~. Compare:. https://github.com/root-project/root/blob/a55cd5db4ba0f9b7811f49d60fdce3fc1f600f39/core/foundation/inc/ROOT/RConfig.hxx#L209. My test with the proposed change from this PR (but with the changed condition) was successful. Thank you!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:93,testability,simpl,simply,93,"> I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__`. Oh yes, my bad, I simply copied from the line above which is for Apple / macOS. Thanks for catching, fixing, and confirming that the approach works. Then we can merge this and backport for 6.28/02 :smiley:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:93,usability,simpl,simply,93,"> I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__`. Oh yes, my bad, I simply copied from the line above which is for Apple / macOS. Thanks for catching, fixing, and confirming that the approach works. Then we can merge this and backport for 6.28/02 :smiley:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:188,usability,confirm,confirming,188,"> I don't think `#if __arm64__` will work. Should be `#ifdef __aarch64__`. Oh yes, my bad, I simply copied from the line above which is for Apple / macOS. Thanks for catching, fixing, and confirming that the approach works. Then we can merge this and backport for 6.28/02 :smiley:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12356:11,deployability,build,build,11,"@phsft-bot build just on mac11arm/default, mac12arm/default, mac13arm/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12356
https://github.com/root-project/root/pull/12356:11,deployability,build,build,11,"@phsft-bot build just on mac11arm/default, mac12arm/default, mac13arm/default with flags -DCTEST_TEST_EXCLUDE_NONE=ON",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12356
https://github.com/root-project/root/pull/12357:22,usability,statu,status,22,"@eguiraud, what's the status of this PR? Can we just merge it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12357
https://github.com/root-project/root/pull/12357:29,interoperability,conflict,conflict,29,"@guitargeek besides the dumb conflict to resolve, this is probably ok to merge as long as people (namely @vepadulano and @pcanal) are ok with keeping ` std::numeric_limits<Long64_t>::max()` instead of `kMaxEntries` sometimes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12357
https://github.com/root-project/root/pull/12357:34,deployability,updat,updated,34,I resolved the merge conflict and updated to use `kMaxEntries` (since this is the semantic accurate alias).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12357
https://github.com/root-project/root/pull/12357:21,interoperability,conflict,conflict,21,I resolved the merge conflict and updated to use `kMaxEntries` (since this is the semantic accurate alias).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12357
https://github.com/root-project/root/pull/12357:82,interoperability,semant,semantic,82,I resolved the merge conflict and updated to use `kMaxEntries` (since this is the semantic accurate alias).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12357
https://github.com/root-project/root/pull/12357:34,safety,updat,updated,34,I resolved the merge conflict and updated to use `kMaxEntries` (since this is the semantic accurate alias).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12357
https://github.com/root-project/root/pull/12357:34,security,updat,updated,34,I resolved the merge conflict and updated to use `kMaxEntries` (since this is the semantic accurate alias).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12357
https://github.com/root-project/root/issues/12358:144,availability,avail,available,144,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:240,deployability,automat,automatically,240,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:233,energy efficiency,load,loaded,233,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:233,performance,load,loaded,233,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:103,reliability,doe,does,103,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:144,reliability,availab,available,144,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:144,safety,avail,available,144,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:144,security,availab,available,144,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/issues/12358:240,testability,automat,automatically,240,I'll take a look at this as soon as possible. One possible reason why it would have worked before (and does not in the standalone) might be the available of a compiled dictionary for that class through a library (from Athena and co) loaded automatically by hadd.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12358
https://github.com/root-project/root/pull/12363:352,availability,cluster,clusters,352,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:611,availability,error,error,611,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:633,availability,error,error,633,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:728,availability,avail,available,728,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:755,availability,avail,available,755,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1036,availability,avail,available,1036,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1089,availability,avail,available,1089,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:352,deployability,cluster,clusters,352,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:94,energy efficiency,core,cores,94,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:375,energy efficiency,core,cores,375,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:417,energy efficiency,core,core,417,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:466,energy efficiency,core,cores,466,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:519,energy efficiency,core,core,519,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:624,interoperability,standard,standard,624,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:299,performance,cach,cache,299,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:545,performance,time,times,545,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:611,performance,error,error,611,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:633,performance,error,error,633,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:668,performance,Memor,Memory,668,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:682,performance,Memor,Memory,682,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:765,performance,memor,memory,765,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:952,performance,time,time,952,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:959,performance,Memor,Memory,959,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1029,performance,memor,memory,1029,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1082,performance,memor,memory,1082,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:728,reliability,availab,available,728,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:755,reliability,availab,available,755,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1036,reliability,availab,available,1036,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1089,reliability,availab,available,1089,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:316,safety,test,tests,316,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:530,safety,test,test,530,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:611,safety,error,error,611,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:633,safety,error,error,633,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:728,safety,avail,available,728,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:755,safety,avail,available,755,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:978,safety,test,test,978,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1036,safety,avail,available,1036,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1089,safety,avail,available,1089,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:728,security,availab,available,728,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:755,security,availab,available,755,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1036,security,availab,available,1036,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1089,security,availab,available,1089,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:316,testability,test,tests,316,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:530,testability,test,test,530,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:978,testability,test,test,978,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:611,usability,error,error,611,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:633,usability,error,error,633,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:668,usability,Memor,Memory,668,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:682,usability,Memor,Memory,682,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:765,usability,memor,memory,765,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:910,usability,user,user,910,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:959,usability,Memor,Memory,959,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1029,usability,memor,memory,1029,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1082,usability,memor,memory,1082,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1195,usability,user,user-images,1195,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1498,usability,user,user-images,1498,"## Example benchmark of the effects of this PR. ### Setup. Hardware. * AMD 5950x (16 physical cores). * 64 GB RAM. * 1 TB NVMe SSD. Software. * Python 3.11, GCC 12. * dask 2023.2.0. Benchmark. * dimuon tutorial, using distrdf+dask. * 1 file, stored on local SSD. The file is preloaded in filesystem cache before the tests run. * ~2GB of data, 75 TTree clusters. * 2 physical cores. One Dask worker is spawned on each core. The benchmark is run keeping the number of cores fixed, increasing the number of partitions per core. Each test is run 10 times, plots show mean value at each number of partitions and the error is the standard error of the mean. ## Results. ### Memory usage. Memory is taken from `psutil.virtual_memory().available`, i.e. the total available memory on the system. The benchmark is the ""only"" process running on the system (i.e. the machine is disconnected from the internet and no other user applications are running at the same time). Memory used by the test run is computed as the difference between the memory available before running the analysis and the memory available at the end of the analysis, before exiting the Python script. ![avoid_rejitting_memory](https://user-images.githubusercontent.com/15638895/220674757-66fda652-9b61-4c11-8877-0fd3962833b4.png). ### Runtime. Runtime is computed as the runtime of the analysis, from right before creating the RDataFrame to the moment when the results of the computations are obtained. ![avoid_rejitting_runtime](https://user-images.githubusercontent.com/15638895/220674777-f6756062-73e6-447d-9f91-9b46096180f4.png).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:79,deployability,updat,updated,79,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:409,deployability,contain,contains,409,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:869,deployability,log,logic,869,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:445,energy efficiency,current,current,445,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:494,energy efficiency,current,current,494,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:503,interoperability,distribut,distributed,503,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:1005,interoperability,distribut,distributed,1005,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:79,safety,updat,updated,79,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:183,safety,test,tests,183,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:869,safety,log,logic,869,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:79,security,updat,updated,79,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:426,security,ident,identifier,426,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:869,security,log,logic,869,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:183,testability,test,tests,183,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:869,testability,log,logic,869,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:891,testability,simpl,simple,891,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:170,usability,clear,clearer,170,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:852,usability,help,helps,852,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:891,usability,simpl,simple,891,"Thank you so much @eguiraud for the comments! I have addressed all of them and updated the commits accordingly, also splitting them in smaller commits to make intentions clearer. New tests are still missing, but I would appreciate if you could take another look. In particular, these changes hopefully streamline the code a bit:. * `rdf_uuid`: this was previously not well named, since we need something that contains both an identifier for the current RDataFrame instance and also one for the current (distributed) execution of that RDataFrame (e.g. to separate to consecutive triggers of the computation graph). I have added the type `ExecutionIdentifier` that holds both. This class is now used everywhere (in Ranges.py, HeadNode.py) and should improve readability. * I merged `CloneResultPtr` and `CloneResultMap` into `CloneResultAndAction`. This helps making the logic in DistRDF more simple (i.e. is what allows the usage of `singledispatch` to distinguish different ways of cloning actions of the distributed computation graph).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:265,availability,failur,failure,265,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:299,availability,error,error,299,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:265,deployability,fail,failure,265,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:330,deployability,updat,updated,330,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:182,energy efficiency,reduc,reduce,182,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:305,integrability,messag,message,305,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:364,integrability,messag,message,364,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:305,interoperability,messag,message,305,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:364,interoperability,messag,message,364,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:265,performance,failur,failure,265,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:299,performance,error,error,299,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:265,reliability,fail,failure,265,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:85,safety,test,tests,85,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:260,safety,test,test,260,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:299,safety,error,error,299,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:330,safety,updat,updated,330,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:345,safety,test,test,345,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:330,security,updat,updated,330,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:85,testability,test,tests,85,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:260,testability,test,test,260,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:345,testability,test,test,345,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:299,usability,error,error,299,"Thank you @vepadulano ! I'm happy to do another pass, but I'd rather do so after the tests are added: it takes me around half a day of work to go through a PR this size, I'd like to reduce the amount of passes... :sweat_smile: . (the warnings are real and the test failure is because of an expected error message that needs to be updated in the test -- or the new message needs to match the old one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:35,availability,failur,failures,35,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:9,deployability,depend,depends,9,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:35,deployability,fail,failures,35,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:9,integrability,depend,depends,9,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:9,modifiability,depend,depends,9,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:35,performance,failur,failures,35,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:35,reliability,fail,failures,35,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:9,safety,depend,depends,9,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:9,testability,depend,depends,9,This now depends on #12981 for the failures on ubuntu18,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:71,availability,failur,failure,71,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:71,deployability,fail,failure,71,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:71,performance,failur,failure,71,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:71,reliability,fail,failure,71,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:6,safety,test,tests,6,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:6,testability,test,tests,6,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:114,testability,simpl,simplified,114,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:114,usability,simpl,simplified,114,"Added tests for the C++ mechanisms, and attempt at fixing the ubuntu18 failure (see last commit) with a much more simplified approach w.r.t. https://github.com/root-project/root/pull/12981, which should not be needed anymore (let's see what the CI thinks).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:19,interoperability,distribut,distributed,19,Added tests on the distributed RDF side too. @eguiraud this is now ready for review again,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:6,safety,test,tests,6,Added tests on the distributed RDF side too. @eguiraud this is now ready for review again,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:77,safety,review,review,77,Added tests on the distributed RDF side too. @eguiraud this is now ready for review again,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:6,testability,test,tests,6,Added tests on the distributed RDF side too. @eguiraud this is now ready for review again,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12363:77,testability,review,review,77,Added tests on the distributed RDF side too. @eguiraud this is now ready for review again,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12363
https://github.com/root-project/root/pull/12365:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12365
https://github.com/root-project/root/issues/12370:124,deployability,instal,installed,124,"Hi @bsunanda ,. Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:154,deployability,version,version,154,"Hi @bsunanda ,. Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:154,integrability,version,version,154,"Hi @bsunanda ,. Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:154,modifiability,version,version,154,"Hi @bsunanda ,. Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:34,testability,simpl,simple,34,"Hi @bsunanda ,. Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:34,usability,simpl,simple,34,"Hi @bsunanda ,. Can you provide a simple reproducer of your case? Together with some information about your system (how you installed ROOT etc., compiler version etc.)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:77,availability,failur,failure,77,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:77,deployability,fail,failure,77,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:150,deployability,log,log-file,150,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:166,deployability,log,log,166,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:77,performance,failur,failure,77,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:77,reliability,fail,failure,77,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:150,safety,log,log-file,150,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:166,safety,log,log,166,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:150,security,log,log-file,150,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:166,security,log,log,166,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:150,testability,log,log-file,150,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:166,testability,log,log,166,Alternatively you can run `valgrind` to get more information on this kind of failure:. ```. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. ```.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:354,availability,failur,failure,354,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:354,deployability,fail,failure,354,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:422,deployability,log,log-file,422,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:438,deployability,log,log,438,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:188,integrability,Sub,Subject,188,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:758,integrability,Messag,Message,758,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:758,interoperability,Messag,Message,758,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:354,performance,failur,failure,354,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:354,reliability,fail,failure,354,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:422,safety,log,log-file,422,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:438,safety,log,log,438,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:422,security,log,log-file,422,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:438,security,log,log,438,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:650,security,auth,auth,650,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:422,testability,log,log-file,422,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:438,testability,log,log,438,"Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:925,availability,failur,failure,925,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:50,deployability,depend,depends,50,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:116,deployability,log,log,116,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:925,deployability,fail,failure,925,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:993,deployability,log,log-file,993,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1009,deployability,log,log,1009,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:50,integrability,depend,depends,50,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:480,integrability,Sub,Subject,480,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:759,integrability,Sub,Subject,759,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1329,integrability,Messag,Message,1329,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1329,interoperability,Messag,Message,1329,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:50,modifiability,depend,depends,50,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:925,performance,failur,failure,925,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:925,reliability,fail,failure,925,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:50,safety,depend,depends,50,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:65,safety,input,input,65,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:116,safety,log,log,116,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:993,safety,log,log-file,993,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1009,safety,log,log,1009,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:116,security,log,log,116,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:993,security,log,log-file,993,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1009,security,log,log,1009,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1221,security,auth,auth,1221,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:50,testability,depend,depends,50,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:116,testability,log,log,116,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:993,testability,log,log-file,993,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1009,testability,log,log,1009,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:65,usability,input,input,65,"Dear Philippe. Sorry for late response. The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. I cannot find out the real reason from this. Could you point out where I should look into this?? Thanks and regards. Sunanda. ________________________________. From: Sunanda Banerjee ***@***.***>. Sent: 28 February 2023 14:10. To: root-project/root ***@***.***>; root-project/root ***@***.***>. Cc: Mention ***@***.***>. Subject: RE: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Thanks Philippe - I shall try that. ________________________________. From: Philippe Canal ***@***.***. Sent: 27 February 2023 18:50. To: root-project/root. Cc: Sunanda Banerjee; Mention. Subject: Re: [root-project/root] Getting a crash while reading a Root Tree (Issue #12370). Alternatively you can run valgrind to get more information on this kind of failure:. valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp --log-file=val.01.log myexecutable myargs. —. Reply to this email directly, view it on GitHub<https://github.com/root-project/root/issues/12370#issuecomment-1446778005>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABGMZOSBSY5NDNIO7K6JZEDWZTSPBANCNFSM6AAAAAAVFHT3OU>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:14,deployability,log,log,14,> here is the log file which came from running valgrind. I don't find this; could you attach it at https://github.com/root-project/root/issues/12370 please?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:14,safety,log,log,14,> here is the log file which came from running valgrind. I don't find this; could you attach it at https://github.com/root-project/root/issues/12370 please?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:14,security,log,log,14,> here is the log file which came from running valgrind. I don't find this; could you attach it at https://github.com/root-project/root/issues/12370 please?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:14,testability,log,log,14,> here is the log file which came from running valgrind. I don't find this; could you attach it at https://github.com/root-project/root/issues/12370 please?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:8,deployability,log,log,8,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:72,deployability,log,log,72,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:8,safety,log,log,8,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:72,safety,log,log,72,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:8,security,log,log,8,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:72,security,log,log,72,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:8,testability,log,log,8,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:72,testability,log,log,72,[val.01.log](https://github.com/root-project/root/files/10955061/val.01.log).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:59,deployability,depend,depends,59,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1302,deployability,stack,stack,1302,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:59,integrability,depend,depends,59,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:203,integrability,pub,public,203,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:372,integrability,pub,public,372,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:505,integrability,pub,public,505,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:613,integrability,pub,public,613,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:815,integrability,pub,public,815,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:984,integrability,pub,public,984,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1117,integrability,pub,public,1117,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:1225,integrability,pub,public,1225,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:59,modifiability,depend,depends,59,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:59,safety,depend,depends,59,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:59,testability,depend,depends,59,"The relevant part:. ```. ==9375== Conditional jump or move depends on uninitialised value(s). ==9375== at 0x44AFDA: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== . ==9375== Invalid read of size 4. ==9375== at 0x44B009: CalibMonitor::correctEnergy(double&, long long const&) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4496BB: CalibMonitor::goodTrack(double&, double&, long long const&, bool) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4467E8: CalibMonitor::Loop(long long) (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== by 0x4664CA: main (in /afs/cern.ch/work/s/sunanda/public/CMSSW_12_4_6/relval/d22gm/CalibMain.exe). ==9375== Address 0x0 is not stack'd, malloc'd or (recently) free'd. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:209,availability,fault,fault,209,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:12,deployability,depend,depends,12,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:78,deployability,log,log,78,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:209,energy efficiency,fault,fault,209,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:12,integrability,depend,depends,12,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:12,modifiability,depend,depends,12,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:209,performance,fault,fault,209,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:123,reliability,Doe,Does,123,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:209,reliability,fault,fault,209,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:12,safety,depend,depends,12,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:27,safety,input,input,27,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:78,safety,log,log,78,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:209,safety,fault,fault,209,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:78,security,log,log,78,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:12,testability,depend,depends,12,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:78,testability,log,log,78,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:27,usability,input,input,27,> The crash depends on the input file. I landed with one file and here is the log file which came from running valgrind. . Does the crash with valgrind have the same symptoms as the original problem (i.e. seg fault in `TStreamerInfoActions::VectorLooper::ReadCollectionBool`)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:202,testability,context,context,202,"Dear @bsunanda , I am sorry to read that problem hit you and to come back to this matter now. For me the issue cannot be reproduced, however, I invite you to re-open a similar ticket with the necessary context in order for us to fix any potential problem affecting CMS simulation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/issues/12370:269,testability,simul,simulation,269,"Dear @bsunanda , I am sorry to read that problem hit you and to come back to this matter now. For me the issue cannot be reproduced, however, I invite you to re-open a similar ticket with the necessary context in order for us to fix any potential problem affecting CMS simulation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12370
https://github.com/root-project/root/pull/12376:71,integrability,sub,sub,71,"Thanks for the review! > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. Thus, in order to avoid `#include`ing `RNTupleModel.hxx`, I left `RNTupleModelChangeset` in the `ROOT::Experimental::Detail` namespace instead. That was my preference, although we can take the other way, i.e. nest the class and `#include` the header; should we? The rest of the comments, I'll address this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:191,reliability,doe,does,191,"Thanks for the review! > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. Thus, in order to avoid `#include`ing `RNTupleModel.hxx`, I left `RNTupleModelChangeset` in the `ROOT::Experimental::Detail` namespace instead. That was my preference, although we can take the other way, i.e. nest the class and `#include` the header; should we? The rest of the comments, I'll address this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:15,safety,review,review,15,"Thanks for the review! > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. Thus, in order to avoid `#include`ing `RNTupleModel.hxx`, I left `RNTupleModelChangeset` in the `ROOT::Experimental::Detail` namespace instead. That was my preference, although we can take the other way, i.e. nest the class and `#include` the header; should we? The rest of the comments, I'll address this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:258,safety,avoid,avoid,258,"Thanks for the review! > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. Thus, in order to avoid `#include`ing `RNTupleModel.hxx`, I left `RNTupleModelChangeset` in the `ROOT::Experimental::Detail` namespace instead. That was my preference, although we can take the other way, i.e. nest the class and `#include` the header; should we? The rest of the comments, I'll address this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:15,testability,review,review,15,"Thanks for the review! > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. Thus, in order to avoid `#include`ing `RNTupleModel.hxx`, I left `RNTupleModelChangeset` in the `ROOT::Experimental::Detail` namespace instead. That was my preference, although we can take the other way, i.e. nest the class and `#include` the header; should we? The rest of the comments, I'll address this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:396,usability,prefer,preference,396,"Thanks for the review! > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. Thus, in order to avoid `#include`ing `RNTupleModel.hxx`, I left `RNTupleModelChangeset` in the `ROOT::Experimental::Detail` namespace instead. That was my preference, although we can take the other way, i.e. nest the class and `#include` the header; should we? The rest of the comments, I'll address this week.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:50,integrability,sub,sub,50,"> > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. > . > This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. I see, let's leave `RNTupleModelChangeset` as is then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:176,reliability,doe,does,176,"> > Let's also make the `RNTupleModelChangeset` a sub class of `RNTupleModel`. > . > This was actually intentional, as the class is forward-declared in `RPageStorage.hxx`. C++ does not allow forward-declaring a nested class. I see, let's leave `RNTupleModelChangeset` as is then.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:124,availability,error,error,124,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:337,availability,error,error,337,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:74,deployability,build,build,74,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:80,deployability,build,build,80,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:124,performance,error,error,124,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:337,performance,error,error,337,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:124,safety,error,error,124,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:337,safety,error,error,337,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:437,safety,review,review,437,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:491,safety,review,review,491,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:437,testability,review,review,437,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:491,testability,review,review,491,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:124,usability,error,error,124,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12376:337,usability,error,error,337,"> * [2023-04-13T13:06:09.466Z] /data/sftnight/workspace/root-pullrequests-build/build/include/ROOT/RNTupleModel.hxx:156:10: error: no matching function for call to ‘ROOT::Experimental::RNTupleModel::AddField<std::array<double, 2> >(std::pair<std::basic_string_view<char>, std::basic_string_view<char> >&, std::array<double, 2>*&)’. This error is due to a prior merge of #12519. @jblomer, we need to rebase; I'll do that after the second review, as I think rebasing will make the incremental review harder.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12376
https://github.com/root-project/root/pull/12377:135,availability,servic,services,135,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:210,availability,Failur,Failure,210,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:2,deployability,Build,Build,2,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:8,deployability,fail,failed,8,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:56,deployability,build,build,56,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:90,deployability,build,build,90,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:135,deployability,servic,services,135,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:187,deployability,build,build,187,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:210,deployability,Fail,Failure,210,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:135,integrability,servic,services,135,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:135,modifiability,servic,services,135,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:210,performance,Failur,Failure,210,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:8,reliability,fail,failed,8,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/pull/12377:210,reliability,Fail,Failure,210,> Build failed on windows10/cxx14. > Running on null:C:\build\workspace\root-pullrequests-build. > [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169198/console). Failure is totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12377
https://github.com/root-project/root/issues/12378:79,deployability,releas,release,79,My attempt at a standalone reproducer have not been successful yet. Is there a release of Athena with a debug build of ROOT I can use to debug?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:110,deployability,build,build,110,My attempt at a standalone reproducer have not been successful yet. Is there a release of Athena with a debug build of ROOT I can use to debug?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:35,deployability,build,builds,35,"Hi Philippe - we have debug Athena builds with ROOT 6.26.8 :. % source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/V02-01-05/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. Using Athena/23.0.20 [cmake] with platform x86_64-centos7-gcc11-dbg. 	at /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-dbg/2023-03-06T2101. % root. | Welcome to ROOT 6.26/08 https://root.cern |. root [0] TClass::GetClass(""MissingETBase::Types::jetlink_t""). (TClass *) nullptr. root [1] TClass::GetClass(""MissingETBase::Types::jetlink_t""). (TClass *) 0x3db8330.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:233,interoperability,platform,platform,233,"Hi Philippe - we have debug Athena builds with ROOT 6.26.8 :. % source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/V02-01-05/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. Using Athena/23.0.20 [cmake] with platform x86_64-centos7-gcc11-dbg. 	at /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-dbg/2023-03-06T2101. % root. | Welcome to ROOT 6.26/08 https://root.cern |. root [0] TClass::GetClass(""MissingETBase::Types::jetlink_t""). (TClass *) nullptr. root [1] TClass::GetClass(""MissingETBase::Types::jetlink_t""). (TClass *) 0x3db8330.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:175,deployability,contain,contains,175,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:595,deployability,build,build,595,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:720,deployability,build,build,720,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:837,deployability,build,build,837,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:843,deployability,build,build,843,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:941,deployability,Instal,InstallArea,941,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:1136,deployability,Instal,InstallArea,1136,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:729,energy efficiency,current,currently,729,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:646,integrability,coupl,couple,646,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:646,modifiability,coupl,couple,646,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:425,reliability,doe,does,425,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:234,safety,test,test,234,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:49,testability,understand,understanding,49,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:234,testability,test,test,234,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:646,testability,coupl,couple,646,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:37,usability,progress,progress,37,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:569,usability,guid,guides,569,"Hi Marcin,. That worked and did some progress in understanding the problem. A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef (in the same dictionary). In order to test any solution to the problem I still need a standalone reproducer and I am still having some difficulties. In particular in my attempts to reproduce the dictionary generation the typedef does not appear in the dictionary nor in the rootmap file. Weirder even, when I follow the [instructions](https://atlassoftwaredocs.web.cern.ch/guides/build_release/) to build Athena from scratch (on zeus.lbl.gov; done a couple of weeks ago), I get a different rootmap file (however because the build is currently (for other reason) partially broken I did not try with it):. ```. grep jetlink_t ../atlas_working/build/build/Athena/_CPack_Packages/Linux/RPM/Athena_23.0.17_x86_64-centos7-gcc11-opt/usr/Athena/23.0.17/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. ```. vs. ```. grep jetlink_t /cvmfs/atlas-nightlies.cern.ch/repo/sw/master_Athena_x86_64-centos7-gcc11-opt/2023-03-05T2101/Athena/23.0.20/InstallArea/x86_64-centos7-gcc11-opt/lib/Athena.rootmap. typedef MissingETBase::Types::jetlink_t. ```. So I am not sure what I am doing different in my reproducer and in my local Athena.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:899,availability,echo,echo,899,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:956,availability,echo,echo,956,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:203,deployability,build,building,203,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:287,deployability,build,build,287,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:451,deployability,contain,contains,451,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:998,deployability,build,build,998,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:1008,deployability,build,build,1008,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:778,energy efficiency,current,current,778,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:907,integrability,Event,Event,907,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:52,interoperability,xml,xml,52,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:496,interoperability,xml,xml,496,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:302,modifiability,pac,packages,302,"Hi Philippe,. I added this typedef to the selection.xml file just a few days ago, that's why you don't see it in Athena 23.0.17. But if you take the latest 23.0.19 (or the master) it will be there. Btw, building an entire Athena (if that is what you tried) is a big deal. Much easier to build selected packages - I will include recipe at the bottom. > A potential work-around would be requested the dictionary for the 2 level of namespace/struct that contains the typedef . You mean in selection.xml? Do you have an example of that that I could try myself? Cheers, Marcin. ==========================================. Athena setup for development:. ----------------------------------------------------------. source /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/AtlasSetup/current/AtlasSetup/scripts/asetup.sh master,latest,Athena,dbg. git clone https://gitlab.cern.ch/atlas/athena.git athena. echo ""+ Event/xAOD/xAODMissingET"" > package_filters.txt. echo ""- .*"" >> package_filters.txt. mkdir build. cd build. cmake -DATLAS_PACKAGE_FILTER_FILE=../package_filters.txt ../athena/Projects/WorkDir. make. source ./x86_64-centos7-gcc11-opt/setup.sh . % grep jetlink ./x86_64-centos7-gcc11-opt/lib/WorkDir.rootmap . typedef MissingETBase::Types::jetlink_t.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:304,deployability,modul,module,304,I now have a standalone reproducer. The main feature I was missing is that the target of the type is an instance of a class template with a default parameter; consequently it does not have a forward declaration provide as part of the dictionary. It is likely that moving to dictionary using the new 'c++ module' features (where dictionary don't need to have any forward declaration) would work around the issue. I am moving forward to test solution to the original issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:148,modifiability,paramet,parameter,148,I now have a standalone reproducer. The main feature I was missing is that the target of the type is an instance of a class template with a default parameter; consequently it does not have a forward declaration provide as part of the dictionary. It is likely that moving to dictionary using the new 'c++ module' features (where dictionary don't need to have any forward declaration) would work around the issue. I am moving forward to test solution to the original issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:304,modifiability,modul,module,304,I now have a standalone reproducer. The main feature I was missing is that the target of the type is an instance of a class template with a default parameter; consequently it does not have a forward declaration provide as part of the dictionary. It is likely that moving to dictionary using the new 'c++ module' features (where dictionary don't need to have any forward declaration) would work around the issue. I am moving forward to test solution to the original issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:175,reliability,doe,does,175,I now have a standalone reproducer. The main feature I was missing is that the target of the type is an instance of a class template with a default parameter; consequently it does not have a forward declaration provide as part of the dictionary. It is likely that moving to dictionary using the new 'c++ module' features (where dictionary don't need to have any forward declaration) would work around the issue. I am moving forward to test solution to the original issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:304,safety,modul,module,304,I now have a standalone reproducer. The main feature I was missing is that the target of the type is an instance of a class template with a default parameter; consequently it does not have a forward declaration provide as part of the dictionary. It is likely that moving to dictionary using the new 'c++ module' features (where dictionary don't need to have any forward declaration) would work around the issue. I am moving forward to test solution to the original issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:435,safety,test,test,435,I now have a standalone reproducer. The main feature I was missing is that the target of the type is an instance of a class template with a default parameter; consequently it does not have a forward declaration provide as part of the dictionary. It is likely that moving to dictionary using the new 'c++ module' features (where dictionary don't need to have any forward declaration) would work around the issue. I am moving forward to test solution to the original issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:435,testability,test,test,435,I now have a standalone reproducer. The main feature I was missing is that the target of the type is an instance of a class template with a default parameter; consequently it does not have a forward declaration provide as part of the dictionary. It is likely that moving to dictionary using the new 'c++ module' features (where dictionary don't need to have any forward declaration) would work around the issue. I am moving forward to test solution to the original issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/issues/12378:0,usability,Confirm,Confirming,0,Confirming this is working now. Thanks Philippe!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12378
https://github.com/root-project/root/pull/12379:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12379
https://github.com/root-project/root/pull/12379:0,availability,Failur,Failures,0,Failures are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12379
https://github.com/root-project/root/pull/12379:0,deployability,Fail,Failures,0,Failures are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12379
https://github.com/root-project/root/pull/12379:0,performance,Failur,Failures,0,Failures are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12379
https://github.com/root-project/root/pull/12379:0,reliability,Fail,Failures,0,Failures are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12379
https://github.com/root-project/root/pull/12381:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12381
https://github.com/root-project/root/pull/12383:23,integrability,sub,subscription,23,"### Screenshot of view subscription menu. <img width=""595"" alt=""Screenshot 2023-02-25 at 6 30 06 AM"" src=""https://user-images.githubusercontent.com/2516492/221362953-f5c4d6e8-9af9-46bb-9212-18f7f4774e57.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12383
https://github.com/root-project/root/pull/12383:36,usability,menu,menu,36,"### Screenshot of view subscription menu. <img width=""595"" alt=""Screenshot 2023-02-25 at 6 30 06 AM"" src=""https://user-images.githubusercontent.com/2516492/221362953-f5c4d6e8-9af9-46bb-9212-18f7f4774e57.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12383
https://github.com/root-project/root/pull/12383:114,usability,user,user-images,114,"### Screenshot of view subscription menu. <img width=""595"" alt=""Screenshot 2023-02-25 at 6 30 06 AM"" src=""https://user-images.githubusercontent.com/2516492/221362953-f5c4d6e8-9af9-46bb-9212-18f7f4774e57.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12383
https://github.com/root-project/root/pull/12383:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12383
https://github.com/root-project/root/pull/12389:41,safety,test,test,41,"I assigned this to @egpbos who wrote the test. Let's wait for his review before merging. I'm curious to hear his opinion, but as far as I know the `EXPECT_EQ` is intended here because the results are expected to be identical even bitwise. But maybe that is unreasonable to achieve and `EXPECT_DOUBLE_EQ` is sufficient?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:66,safety,review,review,66,"I assigned this to @egpbos who wrote the test. Let's wait for his review before merging. I'm curious to hear his opinion, but as far as I know the `EXPECT_EQ` is intended here because the results are expected to be identical even bitwise. But maybe that is unreasonable to achieve and `EXPECT_DOUBLE_EQ` is sufficient?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:215,security,ident,identical,215,"I assigned this to @egpbos who wrote the test. Let's wait for his review before merging. I'm curious to hear his opinion, but as far as I know the `EXPECT_EQ` is intended here because the results are expected to be identical even bitwise. But maybe that is unreasonable to achieve and `EXPECT_DOUBLE_EQ` is sufficient?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:41,testability,test,test,41,"I assigned this to @egpbos who wrote the test. Let's wait for his review before merging. I'm curious to hear his opinion, but as far as I know the `EXPECT_EQ` is intended here because the results are expected to be identical even bitwise. But maybe that is unreasonable to achieve and `EXPECT_DOUBLE_EQ` is sufficient?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:66,testability,review,review,66,"I assigned this to @egpbos who wrote the test. Let's wait for his review before merging. I'm curious to hear his opinion, but as far as I know the `EXPECT_EQ` is intended here because the results are expected to be identical even bitwise. But maybe that is unreasonable to achieve and `EXPECT_DOUBLE_EQ` is sufficient?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:110,availability,error,errors,110,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:299,availability,error,errors,299,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:806,availability,error,errors,806,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:926,availability,down,down,926,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:75,deployability,fail,fail,75,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:651,deployability,fail,fail,651,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:593,integrability,sub,subtle,593,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:110,performance,error,errors,110,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:136,performance,time,time,136,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:299,performance,error,errors,299,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:806,performance,error,errors,806,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:75,reliability,fail,fail,75,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:651,reliability,fail,fail,651,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:69,safety,test,tests,69,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:110,safety,error,errors,110,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:299,safety,error,errors,299,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:806,safety,error,errors,806,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:42,testability,understand,understand,42,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:69,testability,test,tests,69,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:169,testability,understand,understand,169,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:316,testability,understand,understand,316,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:110,usability,error,errors,110,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:233,usability,document,document,233,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:299,usability,error,errors,299,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:484,usability,confirm,confirmation,484,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:806,usability,error,errors,806,"Sorry for the late reply! I would like to understand why exactly the tests fail. We're dealing with summation errors like these all the time in RooFit. Imho, we need to understand as exactly as possible where they come from and then document that. If we cannot do that, then we should treat them as errors, until we understand the fundamental limits, e.g. from hardware summation implementations. I can well imagine that that is the root cause here, but I would like to see some hard confirmation of that. The reason I'm so insistent on this is that I've spent the past year trying to unravel subtle bugs involving multiple summations that may either fail because of implementation issues (like e.g. was the case for KahanSum) or because of fundamental limits in algorithms (Kahan summation also still has errors) or because of fundamental hardware limits or single vs double vs long double precision, etcetera. Trying to pin down exactly what is going on is a huge pain. Those are my 2 cents here, sorry for being a pain in the ass :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:107,deployability,fail,failed,107,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:107,reliability,fail,failed,107,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:246,reliability,doe,does,246,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:123,safety,test,testing,123,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:336,safety,test,tests,336,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:69,security,hardcod,hardcoding,69,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:282,security,hardcod,hardcode,282,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:123,testability,test,testing,123,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:336,testability,test,tests,336,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:19,usability,document,documented,19,"Btw, one way I've ""documented"" one of these fundamental limits is by hardcoding some ""random"" numbers that failed and then testing *those* with EXPECT_DOUBLE_EQ (and maybe also EXPECT_NE to be even more precise), while another random number that does EXPECT_EQ match you could also hardcode. It's very tedious, but I think it makes our tests actually useful for tracing bugs in the future.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:158,deployability,fail,fail,158,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:553,energy efficiency,optim,optimized,553,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:619,integrability,complian,compliant,619,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:174,interoperability,architectur,architectures,174,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:553,performance,optimiz,optimized,553,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:732,performance,perform,performance,732,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:158,reliability,fail,fail,158,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:283,reliability,doe,doesn,283,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:136,safety,test,test,136,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:619,safety,compl,compliant,619,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:236,security,ident,identical,236,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:619,security,compl,compliant,619,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:136,testability,test,test,136,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:732,usability,perform,performance,732,"Hi, I was sent here from https://github.com/root-project/root/pull/12784 and I'm a bit worried that we have, for multiple months now, a test that is known to fail on non-x86 architectures. My question would be: Why do you want bit-wise identical results for sums? `EXPECT_DOUBLE_EQ` doesn't allow arbitrarily large deviations, but only 4 ULPs which is enough to account for rounding in (well-behaved) algorithms, but will still catch most other problems. As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:219,availability,down,down,219,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:878,availability,down,down,878,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1023,availability,robust,robustness,1023,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1035,availability,reliab,reliability,1035,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1364,availability,error,errors,1364,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:586,deployability,integr,integration,586,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1492,deployability,resourc,resources,1492,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1548,deployability,resourc,resources,1548,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1492,energy efficiency,resourc,resources,1492,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1518,energy efficiency,current,currently,1518,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1548,energy efficiency,resourc,resources,1548,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:226,integrability,sub,subtle,226,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:586,integrability,integr,integration,586,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1072,integrability,compon,components,1072,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:315,interoperability,Convers,Conversely,315,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:586,interoperability,integr,integration,586,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1072,interoperability,compon,components,1072,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:586,modifiability,integr,integration,586,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1072,modifiability,compon,components,1072,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:198,performance,time,time,198,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:740,performance,parallel,parallelized,740,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1130,performance,perform,performance,1130,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1364,performance,error,errors,1364,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1412,performance,time,times,1412,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1492,performance,resourc,resources,1492,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1548,performance,resourc,resources,1548,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1584,performance,time,time,1584,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:586,reliability,integr,integration,586,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1023,reliability,robust,robustness,1023,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1035,reliability,reliab,reliability,1035,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1611,reliability,doe,doesn,1611,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1659,reliability,pra,practical,1659,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:59,safety,test,test,59,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:158,safety,test,tests,158,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:250,safety,test,tests,250,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:335,safety,test,tests,335,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:432,safety,test,tests,432,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:501,safety,test,tests,501,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:599,safety,test,tests,599,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1023,safety,robust,robustness,1023,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1035,safety,reliabil,reliability,1035,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1364,safety,error,errors,1364,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1492,safety,resourc,resources,1492,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1548,safety,resourc,resources,1548,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:586,security,integr,integration,586,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:726,security,trust,trust,726,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:59,testability,test,test,59,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:158,testability,test,tests,158,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:250,testability,test,tests,250,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:335,testability,test,tests,335,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:427,testability,Unit,Unit,427,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:432,testability,test,tests,432,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:496,testability,unit,unit,496,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:501,testability,test,tests,501,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:586,testability,integr,integration,586,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:599,testability,test,tests,599,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:667,testability,simpl,simply,667,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:872,testability,trace,trace,872,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1492,testability,resourc,resources,1492,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1548,testability,resourc,resources,1548,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:624,usability,close,closest,624,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:667,usability,simpl,simply,667,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:716,usability,user,users,716,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:840,usability,experien,experience,840,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1130,usability,perform,performance,1130,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1284,usability,person,personally,1284,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1364,usability,error,errors,1364,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1669,usability,help,help,1669,"I agree that it is an unfortunate circumstance to have the test not passing. However, I still urge you to consider the effect on debugability removing strict tests will have. I have wasted a lot of time trying to track down a subtle bug due to loose tests which left me unable to determine where the bug came from. Conversely, setting tests strictly and tracing discrepancies, I found a different bug in the Kahan sum: #11940. Unit tests especially should be as strict as possible. In absence of unit tests (which unfortunately is the case for the parts of RooFit I worked on), strict ""integration"" tests like these are the closest I could get. Note also that it was simply part of my original assignment: to ensure users can trust the new parallelized methods, I built them to be bit-wise exactly equal to the old methods. So, I know from experience how tedious it is to trace down these bit-wise differences to their actual concrete source, but also think that because we are dealing with scientific software, precision, robustness, reliability and interpretability (of components and hence the whole) are important. Of course, performance is an important factor too, but it's just one of the aspects. We want the end-results of experiments to be accurate and explainable, right? I personally at least don't like when I have to sell a ""because of floating point errors"", because I've been bitten by them a few times now. Now, I'm also well aware that the project only has a given amount of resources and I myself am currently more or less out of resources (I can spend only my free time), so my vote probably doesn't count strongly :) If I could be of more practical help in this, I would definitely be happy to, but I also don't have a non-x86 machine, so it's not feasible for me to do much right now. So, feel free to make a call on this as you all best see fit!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:360,energy efficiency,model,models,360,"Btw, one additional thought on this accuracy/performance trade-off (also following earlier discussions in the PPP channel): perhaps a good way to ""solve"" this is by not hardcoding one trade-off choice, but by allowing the users to choose what's best for their particular problems. I could imagine users would like a fast-mode for iteration on designing RooFit models and a precision-mode for the final calculation, for instance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:45,performance,perform,performance,45,"Btw, one additional thought on this accuracy/performance trade-off (also following earlier discussions in the PPP channel): perhaps a good way to ""solve"" this is by not hardcoding one trade-off choice, but by allowing the users to choose what's best for their particular problems. I could imagine users would like a fast-mode for iteration on designing RooFit models and a precision-mode for the final calculation, for instance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:169,security,hardcod,hardcoding,169,"Btw, one additional thought on this accuracy/performance trade-off (also following earlier discussions in the PPP channel): perhaps a good way to ""solve"" this is by not hardcoding one trade-off choice, but by allowing the users to choose what's best for their particular problems. I could imagine users would like a fast-mode for iteration on designing RooFit models and a precision-mode for the final calculation, for instance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:360,security,model,models,360,"Btw, one additional thought on this accuracy/performance trade-off (also following earlier discussions in the PPP channel): perhaps a good way to ""solve"" this is by not hardcoding one trade-off choice, but by allowing the users to choose what's best for their particular problems. I could imagine users would like a fast-mode for iteration on designing RooFit models and a precision-mode for the final calculation, for instance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:45,usability,perform,performance,45,"Btw, one additional thought on this accuracy/performance trade-off (also following earlier discussions in the PPP channel): perhaps a good way to ""solve"" this is by not hardcoding one trade-off choice, but by allowing the users to choose what's best for their particular problems. I could imagine users would like a fast-mode for iteration on designing RooFit models and a precision-mode for the final calculation, for instance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:222,usability,user,users,222,"Btw, one additional thought on this accuracy/performance trade-off (also following earlier discussions in the PPP channel): perhaps a good way to ""solve"" this is by not hardcoding one trade-off choice, but by allowing the users to choose what's best for their particular problems. I could imagine users would like a fast-mode for iteration on designing RooFit models and a precision-mode for the final calculation, for instance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:297,usability,user,users,297,"Btw, one additional thought on this accuracy/performance trade-off (also following earlier discussions in the PPP channel): perhaps a good way to ""solve"" this is by not hardcoding one trade-off choice, but by allowing the users to choose what's best for their particular problems. I could imagine users would like a fast-mode for iteration on designing RooFit models and a precision-mode for the final calculation, for instance.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:177,availability,error,errors,177,"This puts us into the unfortunate spot that the solution which is widely used across most other software packages dealing with this kind of situation (ie, allowing the rounding errors) is not acceptable, but at the same time nobody is willing to spend the (considerable amount of) time to find another solution that you would be happy with. /cc @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:105,modifiability,pac,packages,105,"This puts us into the unfortunate spot that the solution which is widely used across most other software packages dealing with this kind of situation (ie, allowing the rounding errors) is not acceptable, but at the same time nobody is willing to spend the (considerable amount of) time to find another solution that you would be happy with. /cc @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:177,performance,error,errors,177,"This puts us into the unfortunate spot that the solution which is widely used across most other software packages dealing with this kind of situation (ie, allowing the rounding errors) is not acceptable, but at the same time nobody is willing to spend the (considerable amount of) time to find another solution that you would be happy with. /cc @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:220,performance,time,time,220,"This puts us into the unfortunate spot that the solution which is widely used across most other software packages dealing with this kind of situation (ie, allowing the rounding errors) is not acceptable, but at the same time nobody is willing to spend the (considerable amount of) time to find another solution that you would be happy with. /cc @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:281,performance,time,time,281,"This puts us into the unfortunate spot that the solution which is widely used across most other software packages dealing with this kind of situation (ie, allowing the rounding errors) is not acceptable, but at the same time nobody is willing to spend the (considerable amount of) time to find another solution that you would be happy with. /cc @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:177,safety,error,errors,177,"This puts us into the unfortunate spot that the solution which is widely used across most other software packages dealing with this kind of situation (ie, allowing the rounding errors) is not acceptable, but at the same time nobody is willing to spend the (considerable amount of) time to find another solution that you would be happy with. /cc @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:177,usability,error,errors,177,"This puts us into the unfortunate spot that the solution which is widely used across most other software packages dealing with this kind of situation (ie, allowing the rounding errors) is not acceptable, but at the same time nobody is willing to spend the (considerable amount of) time to find another solution that you would be happy with. /cc @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:170,deployability,resourc,resources,170,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:170,energy efficiency,resourc,resources,170,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:355,interoperability,architectur,architecture,355,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:111,performance,time,time,111,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:170,performance,resourc,resources,170,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:213,reliability,pra,pragmatic,213,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:18,safety,compl,completely,18,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:170,safety,resourc,resources,170,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:18,security,compl,completely,18,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:170,testability,resourc,resources,170,"Yep. And again, I completely realize that the reasonable thing for me to do in this case would be to spend the time to make my own wishes come true, but I don't have the resources right now unfortunately. Another pragmatic, but kinda ugly solution could be to have a compile flag in there that switches between EXPECT_EQ and EXPECT_DOUBLE_EQ based on the architecture. Then everybody can at least get on with things and maybe someone will come along later to fix things. Anyway, indeed, maybe Axel can decide :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:224,availability,failur,failure,224,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:345,availability,failur,failure,345,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:634,availability,failur,failure,634,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:224,deployability,fail,failure,224,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:345,deployability,fail,failure,345,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:634,deployability,fail,failure,634,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:224,performance,failur,failure,224,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:345,performance,failur,failure,345,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:634,performance,failur,failure,634,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:224,reliability,fail,failure,224,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:345,reliability,fail,failure,345,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:634,reliability,fail,failure,634,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:647,reliability,doe,does,647,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:65,safety,input,input,65,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:300,safety,test,test,300,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:340,safety,test,test,340,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:411,safety,test,test,411,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:465,safety,test,test,465,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:629,safety,test,test,629,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:300,testability,test,test,300,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:340,testability,test,test,340,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:411,testability,test,test,411,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:465,testability,test,test,465,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:629,testability,test,test,629,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:65,usability,input,input,65,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:564,usability,clear,clear,564,"I cannot decide, that's up to you @egpbos and @lmoneta given the input by @hahnjo and me here. Please consider this:. IIUC you are interpreting this lack of bitwise equality as a bug. In that case our approach is to fix the failure asap. If ""asap"" isn't happening because reasons then we disable the test, and create a bug report about the test failure, reminding ourselves (you, @egpbos in this case) that the test needs to be fixed and re-enabled. ""Disabling the test"" can as well be a switch from equality to equality-with-range, as long as the GitHub issue is clear which commit needs to be reverted to reprouce the original test failure. How does that sound?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:372,availability,down,down,372,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:628,deployability,log,log,628,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:659,deployability,log,log,659,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:708,deployability,log,log,708,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:896,deployability,log,log,896,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:917,deployability,log,log,917,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:966,deployability,log,log,966,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1034,deployability,log,log,1034,"imary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1421,deployability,log,log,1421,"f::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1745,deployability,log,log,1745,""", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::ex",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1824,deployability,log,log,1824,"uble extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2404,deployability,log,log,2404,"e call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identic",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3467,deployability,log,log,3467,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3531,deployability,depend,depending,3531,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:100,energy efficiency,optim,optimized,100,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:166,integrability,complian,compliant,166,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3531,integrability,depend,depending,3531,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3423,interoperability,platform,platforms,3423,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:426,modifiability,exten,extendedTerm,426,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2745,modifiability,exten,extendedTerm,2745,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3519,modifiability,paramet,parameters,3519,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3531,modifiability,depend,depending,3531,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:100,performance,optimiz,optimized,100,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:279,performance,perform,performance,279,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:166,safety,compl,compliant,166,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:345,safety,test,testRooAbsL,345,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:628,safety,log,log,628,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:659,safety,log,log,659,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:683,safety,test,test,683,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:708,safety,log,log,708,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:733,safety,test,test,733,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:750,safety,test,test,750,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:758,safety,test,test,758,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:776,safety,test,test,776,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:792,safety,test,test,792,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:809,safety,test,test,809,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:896,safety,log,log,896,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:917,safety,log,log,917,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:966,safety,log,log,966,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1034,safety,log,log,1034,"imary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1125,safety,test,test,1125,"structions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1152,safety,test,test,1152,"ly IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1421,safety,log,log,1421,"f::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1745,safety,log,log,1745,""", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::ex",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1799,safety,test,test,1799,"17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1824,safety,log,log,1824,"uble extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2106,safety,test,test,2106,"ng output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2159,safety,test,test,2159,"990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2177,safety,test,test,2177," extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2307,safety,test,test,2307,"```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2404,safety,log,log,2404,"e call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identic",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3467,safety,log,log,3467,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3513,safety,input,input,3513,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3531,safety,depend,depending,3531,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:166,security,compl,compliant,166,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:628,security,log,log,628,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:659,security,log,log,659,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:708,security,log,log,708,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:896,security,log,log,896,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:917,security,log,log,917,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:966,security,log,log,966,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1034,security,log,log,1034,"imary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1421,security,log,log,1421,"f::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1745,security,log,log,1745,""", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::ex",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1824,security,log,log,1824,"uble extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2404,security,log,log,2404,"e call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identic",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3399,security,ident,identical,3399,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3467,security,log,log,3467,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:345,testability,test,testRooAbsL,345,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:628,testability,log,log,628,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:659,testability,log,log,659,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:683,testability,test,test,683,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:708,testability,log,log,708,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:733,testability,test,test,733,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:750,testability,test,test,750,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:758,testability,test,test,758,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:776,testability,test,test,776,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:792,testability,test,test,792,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:809,testability,test,test,809,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:896,testability,log,log,896,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:917,testability,log,log,917,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:966,testability,log,log,966,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1034,testability,log,log,1034,"imary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa m",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1125,testability,test,test,1125,"structions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1152,testability,test,test,1152,"ly IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1421,testability,log,log,1421,"f::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1745,testability,log,log,1745,""", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::ex",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1799,testability,test,test,1799,"17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1824,testability,log,log,1824,"uble extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2106,testability,test,test,2106,"ng output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2159,testability,test,test,2159,"990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2177,testability,test,test,2177," extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2307,testability,test,test,2307,"```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2404,testability,log,log,2404,"e call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identic",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3467,testability,log,log,3467,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3531,testability,depend,depending,3531,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:279,usability,perform,performance,279,"> As to where these come from, my primary suspect would be fused-multiply-add instructions or other optimized floating point instructions that are not fully IEEE-754 compliant. I don't know exactly where, but I also don't think that you want to disable them globally and pay the performance penalty... Yep: At least for the first difference in `testRooAbsL` that I hunted down, mac13arm has a fused instruction in `RooAbsPdf::extendedTerm`. If instead of. https://github.com/root-project/root/blob/b7b8646c53724503b3c603de4cf633bc78270b5f/roofit/roofitcore/src/RooAbsPdf.cxx#L820-L822. I put. ```c++. printf("" expected = %.17g, log = %.17g\n"", expected, std::log(expected));. double test = sumEntries * std::log(expected);. printf("" test = %.17g\n"", test);. test = expected - test;. printf("" test = %.17g\n"", test);. #if 0. double extra = doOffset. ? (expected - sumEntries) - sumEntries * (std::log(expected) - std::log(sumEntries)). : expected - sumEntries * std::log(expected);. #endif. double extra = expected - sumEntries * std::log(expected);. printf("" extra = %.17g\n"", extra);. ```. I get the following output:. ```. test = 2390.5943542960845. test = -1990.5943542960845. extra = -1990.5943542960847. ```. with the corresponding assembly code being (with some annotations; the `fmsub` is at `ca518`). ```. ca4d0: 00 41 60 1e fmov d0, d8. ca4d4: c9 1c 07 94 bl 0x2917f8 <_write+0x2917f8> # likely the call to std::log. ca4d8: 0b 40 60 1e fmov d11, d0. ca4dc: e0 07 00 fd str d0, [sp, #8]. ca4e0: e8 03 00 fd str d8, [sp]. ca4e4: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3513,usability,input,input,3513,"ta&, RooLinkedList const&)+0x6e8>. ca4e8: 00 78 36 91 add x0, x0, #3486. ca4ec: ff 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""expected = %.17g, log = %.17g"". ca4f0: 6c 09 6a 1e fmul d12, d11, d10 # test = sumEntries * std::log(expected). ca4f4: ec 03 00 fd str d12, [sp]. ca4f8: 33 10 00 f0 adrp x19, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x6fc>. ca4fc: 73 16 37 91 add x19, x19, #3525. ca500: e0 03 13 aa mov x0, x19. ca504: f9 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca508: 00 39 6c 1e fsub d0, d8, d12 # test = expected - test;. ca50c: e0 03 00 fd str d0, [sp]. ca510: e0 03 13 aa mov x0, x19. ca514: f5 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""test = %.17g"". ca518: 4b a1 4b 1f fmsub d11, d10, d11, d8 # extra = expected - sumEntries * std::log(expected). ca51c: eb 03 00 fd str d11, [sp]. ca520: 20 10 00 f0 adrp x0, 0x2d1000 <RooAbsPdf::createNLL(RooAbsData&, RooLinkedList const&)+0x724>. ca524: 00 70 37 91 add x0, x0, #3548. ca528: f0 1c 07 94 bl 0x2918e8 <_write+0x2918e8> # print ""extra = %.17g"". ca52c: 28 21 60 1e fcmp d9, #0.0. ca530: 60 00 00 54 b.eq 0xca53c <RooAbsPdf::extendedTerm(double, double, double, bool) const+0x29c>. ca534: 20 19 6a 1e fdiv d0, d9, d10 # this is the branch sumEntriesW2 != 0.0. ca538: 6b 09 60 1e fmul d11, d11, d0 # with a division and multiplication. ca53c: 60 41 60 1e fmov d0, d11 # store the return value into d0. ca540: fd 7b 47 a9 ldp x29, x30, [sp, #112]. ca544: f4 4f 46 a9 ldp x20, x19, [sp, #96]. ca548: f6 57 45 a9 ldp x22, x21, [sp, #80]. ca54c: e9 23 44 6d ldp d9, d8, [sp, #64]. ca550: eb 2b 43 6d ldp d11, d10, [sp, #48]. ca554: ed 33 42 6d ldp d13, d12, [sp, #32]. ca558: ff 03 02 91 add sp, sp, #128. ca55c: c0 03 5f d6 ret. ```. There are other problems with expecting bit-wise identical output across platforms. For example `std::exp` and `std::log` can return different results for certain input parameters, depending on how they are implemented and rounding of the result.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:286,availability,operat,operation,286,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:465,availability,error,errors,465,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:575,availability,operat,operations,575,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:614,availability,error,errors,614,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:407,deployability,fail,failing,407,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:703,energy efficiency,current,current,703,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:374,integrability,event,event,374,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:192,modifiability,exten,extendedTerm,192,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:711,modifiability,paramet,parameters,711,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:465,performance,error,errors,465,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:614,performance,error,errors,614,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:407,reliability,fail,failing,407,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:92,safety,Test,TestStatistics,92,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:394,safety,test,test,394,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:465,safety,error,errors,465,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:614,safety,error,errors,614,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:68,testability,understand,understand,68,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:92,testability,Test,TestStatistics,92,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:394,testability,test,test,394,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:465,usability,error,errors,465,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:614,usability,error,errors,614,"@hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1595,availability,operat,operation,1595,"ts.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1774,availability,error,errors,1774,"er partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1922,availability,operat,operations,1922,"rent `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2023,availability,operat,operations,2023,"tition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2205,availability,operat,operations,2205,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2244,availability,error,errors,2244,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2630,availability,avail,available,2630,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2681,availability,avail,available,2681,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1158,deployability,fail,fail,1158,"se it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > O",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1251,deployability,fail,fail,1251,"... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1716,deployability,fail,failing,1716," sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1978,deployability,depend,depending,1978," be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2080,deployability,depend,depending,2080," `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of e",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2112,deployability,version,versions,2112,"ventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good ide",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2966,deployability,fail,fail,2966,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1885,energy efficiency,optim,optimizing,1885,"e FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2122,energy efficiency,optim,optimization,2122,"` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't k",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2333,energy efficiency,current,current,2333,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:596,integrability,event,events,596,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:711,integrability,sub,sub,711,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:715,integrability,event,event,715,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1048,integrability,event,events,1048," still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1112,integrability,Sub,SubEventSections,1112,"dL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1236,integrability,Event,EventSections,1236,"ame result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1683,integrability,event,event,1683,"efore returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always avail",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1978,integrability,depend,depending,1978," be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2080,integrability,depend,depending,2080," `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of e",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2112,integrability,version,versions,2112,"ventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good ide",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:460,interoperability,platform,platform,460,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2093,interoperability,platform,platform,2093,"onstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:194,modifiability,exten,extendedTerm,194,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:545,modifiability,exten,extendedTerm,545,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:933,modifiability,exten,extendedTerm,933,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:999,modifiability,exten,extendedTerm,999,"hnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1978,modifiability,depend,depending,1978," be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2080,modifiability,depend,depending,2080," `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of e",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2112,modifiability,version,versions,2112,"ventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good ide",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2341,modifiability,paramet,parameters,2341,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2465,modifiability,extens,extension,2465,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2901,modifiability,exten,extendedTerm,2901,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1774,performance,error,errors,1774,"er partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1885,performance,optimiz,optimizing,1885,"e FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2122,performance,optimiz,optimization,2122,"` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't k",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2244,performance,error,errors,2244,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1158,reliability,fail,fail,1158,"se it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > O",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1251,reliability,fail,fail,1251,"... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1716,reliability,fail,failing,1716," sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2630,reliability,availab,available,2630,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2681,reliability,availab,available,2681,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2966,reliability,fail,fail,2966,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:94,safety,Test,TestStatistics,94,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1292,safety,test,test,1292,"carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes imp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1703,safety,test,test,1703,"r the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1774,safety,error,errors,1774,"er partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1978,safety,depend,depending,1978," be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2080,safety,depend,depending,2080," `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of e",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2244,safety,error,errors,2244,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2630,safety,avail,available,2630,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2681,safety,avail,available,2681,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2961,safety,test,test,2961,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1450,security,ident,identical,1450,"same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2630,security,availab,available,2630,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2681,security,availab,available,2681,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:3033,security,ident,identical,3033,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:70,testability,understand,understand,70,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:94,testability,Test,TestStatistics,94,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1292,testability,test,test,1292,"carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes imp",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1703,testability,test,test,1703,"r the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1978,testability,depend,depending,1978," be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2080,testability,depend,depending,2080," `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of e",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2961,testability,test,test,2961,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:485,usability,close,closely,485,"> @hahnjo hm that's an interesting clue, but then I still don't fully understand why `RooFit::TestStatistics::RooUnbinnedL` would give a different answer, because it also just calls `RooAbsPdf::extendedTerm`, so it should still get the exact same result... Yes, you are absolutely right, I got carried away by finding the first / one of the differences by comparing x86 to mac13arm. Looking some more why `RooUnbinnedL` gives two different results on the same platform, it is actually closely related: in `RooUnbinnedL::evaluatePartition`, the `extendedTerm` is added to the first partition, if `events.begin_fraction == 0`. With one big partition, this is added at the very end, just before returning. For the sub event sections, it is added to the first partition and the other partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1774,usability,error,errors,1774,"er partitions are later added on top. This exhibits different rounding, which is *triggered* by mac13arm using the FMA instructions and having a different `extendedTerm` than x86. One solution to this would be to add the `extendedTerm` to the last partition, that is if `events.end_fraction == 1`. This fixes `SimBinnedConstrainedTest.SubEventSections` on `mac13arm`, but makes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2244,usability,error,errors,2244,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2778,usability,hint,hint,2778,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:2783,usability,hint,hint,2783,"kes it fail on x86 (didn't investigate why). It also makes `SimBinnedConstrainedTest.EventSections` fail (both on `mac13arm` and x86) - this test looks even worse in terms of floating point arithmetic, since it expects summing up two partitions individually and then adding the result being bitwise identical to summing up the whole range at once. From what I can see, this is only working by chance right now. > Or is the problem that the FMA operation on the different parts of the sum (the likelihood is calculated over multiple event ranges in the test that is failing, which are summed afterwards) has higher rounding errors on non-x86 so that in the end the result indeed differs? See above; the additional problem is that the (optimizing) compiler will insert FMA operations if it sees fit (and is allowed to do so). So depending on how the code and the arithmetic operations are formulated, you may get different results depending on platform, software versions, optimization level, hardware, etc. > Or, even more problematically, could such FMA operations also cause similar rounding errors on x86 so that EXPECT_EQ indeed becomes impossible (and I just got lucky with the current parameters on x86)? On x86, you are saved by the fact that, as far as I can tell, FMA instructions only come from some SIMD extension that the compiler cannot use unconditionally. This is different on AArch64 (and apparently also PPC64LE) where it appears it is in the base ISA and always available. But yes, if in the future FMA is always available on x86 or you compile (parts of) the code with vector instructions (`RooBatchCompute`, hint hint), you can potentially run into the same problem. For another point regarding ""lucky"", see above that adding the `extendedTerm` to the last partition already makes one other test fail... In conclusion, I urge you to reconsider expecting bit-wise identical results. I think I've provided plenty of evidence why it's not a good idea, I don't know what more to say...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1146,availability,error,error,1146,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1359,availability,operat,operations,1359,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:328,deployability,fail,fails,328,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:472,deployability,fail,fail,472,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:489,deployability,fail,fails,489,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:640,deployability,fail,fail,640,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:681,deployability,fail,fails,681,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:722,deployability,contain,contained,722,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1355,energy efficiency,CPU,CPU,1355,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:26,integrability,sub,subevent-section,26,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:313,integrability,Event,EventSections,313,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:391,integrability,Sub,SubEventSections,391,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:514,integrability,Event,EventSections,514,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:559,integrability,Event,EventSections,559,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:618,integrability,event,event-splitting,618,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:741,integrability,Event,EventSections,741,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:957,integrability,event,events,957,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:997,integrability,event,events,997,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1583,integrability,sub,subsidiary,1583,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1842,integrability,Event,EventSections,1842,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1541,modifiability,exten,extended,1541,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1146,performance,error,error,1146,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1355,performance,CPU,CPU,1355,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1397,performance,parallel,parallel,1397,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:328,reliability,fail,fails,328,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:472,reliability,fail,fail,472,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:489,reliability,fail,fails,489,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:640,reliability,fail,fail,640,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:681,reliability,fail,fails,681,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:840,reliability,doe,doesn,840,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1242,reliability,doe,doesn,1242,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:43,safety,test,tests,43,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:466,safety,test,tests,466,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:634,safety,test,tests,634,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:697,safety,test,tests,697,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:756,safety,test,tests,756,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:769,safety,compl,complete,769,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1146,safety,error,error,1146,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1172,safety,test,tests,1172,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1214,safety,Test,TestStatistics,1214,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1282,safety,test,tests,1282,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1380,safety,except,except,1380,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1422,safety,Test,TestStatistics,1422,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1857,safety,test,tests,1857,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:769,security,compl,complete,769,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:43,testability,test,tests,43,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:466,testability,test,tests,466,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:634,testability,test,tests,634,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:697,testability,test,tests,697,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:756,testability,test,tests,756,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1172,testability,test,tests,1172,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1214,testability,Test,TestStatistics,1214,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1282,testability,test,tests,1282,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1422,testability,Test,TestStatistics,1422,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1857,testability,test,tests,1857,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:178,usability,confirm,confirmed,178,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12389:1146,usability,error,error,1146,"You convinced me that the subevent-section tests should be `EXPECT_DOUBLE_EQ`. > From what I can see, this is only working by chance right now. You are right! This can easily be confirmed (even just on my x86 laptop) by changing the seed on line 66. Setting it to some other values, the `SimBinnedConstrainedTest.EventSections` fails sometimes (e.g. seed = 24) and `SimBinnedConstrainedTest.SubEventSections` as well (e.g. seed = 255). Some seeds even make multiple tests fail, e.g. 25534 fails `BinnedDatasetTest.EventSections` and `SimBinnedConstrainedTest.EventSections` and 2 makes both `SimBinnedConstrainedTest` event-splitting tests fail. I was not able to find a seed that fails the other tests, so it seems to be contained to the `*EventSections` tests. To be complete, I think we should add the explanation of why this comparison doesn't work, which is that **the calculations are**, in fact, **different**. We're comparing a single-section (""all events"") calculation to multi-section (""events section 1"" + ""section 2"" + ...). Obviously, this can give differences due to rounding from FMA or just Kahan summation which also has a small error sometimes. In other tests in the `RooAbsL` and other `RooFit::TestStatistics` suite, this doesn't typically apply. In most of the tests, we're trying to do the exact same calculation (""same"" in terms of CPU operations as well), except either in parallel or through the `TestStatistics` classes instead of the old `RooNLLVar` tree. Sometimes different ordering can change results, like the extended term you mentioned, but also the subsidiary term. Anyway, for this PR: I will suggest an explanation comment and after that it can be merged (@guitargeek agrees, we discussed it in the RooFit dev meeting just now). I will also open an issue reminding us to also apply this change to the two `EventSections` tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12389
https://github.com/root-project/root/pull/12390:91,availability,toler,tolerance,91,"Rebased due to commit f237213f79718d083fe2ad0ef17de0b114a20e19 which increased the allowed tolerance a bit to fix the mac arm build. However, that increase is not sufficient for ix86 and the tolerance must be increased further to not fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12390
https://github.com/root-project/root/pull/12390:191,availability,toler,tolerance,191,"Rebased due to commit f237213f79718d083fe2ad0ef17de0b114a20e19 which increased the allowed tolerance a bit to fix the mac arm build. However, that increase is not sufficient for ix86 and the tolerance must be increased further to not fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12390
https://github.com/root-project/root/pull/12390:126,deployability,build,build,126,"Rebased due to commit f237213f79718d083fe2ad0ef17de0b114a20e19 which increased the allowed tolerance a bit to fix the mac arm build. However, that increase is not sufficient for ix86 and the tolerance must be increased further to not fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12390
https://github.com/root-project/root/pull/12390:234,deployability,fail,fail,234,"Rebased due to commit f237213f79718d083fe2ad0ef17de0b114a20e19 which increased the allowed tolerance a bit to fix the mac arm build. However, that increase is not sufficient for ix86 and the tolerance must be increased further to not fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12390
https://github.com/root-project/root/pull/12390:91,reliability,toleran,tolerance,91,"Rebased due to commit f237213f79718d083fe2ad0ef17de0b114a20e19 which increased the allowed tolerance a bit to fix the mac arm build. However, that increase is not sufficient for ix86 and the tolerance must be increased further to not fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12390
https://github.com/root-project/root/pull/12390:191,reliability,toleran,tolerance,191,"Rebased due to commit f237213f79718d083fe2ad0ef17de0b114a20e19 which increased the allowed tolerance a bit to fix the mac arm build. However, that increase is not sufficient for ix86 and the tolerance must be increased further to not fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12390
https://github.com/root-project/root/pull/12390:234,reliability,fail,fail,234,"Rebased due to commit f237213f79718d083fe2ad0ef17de0b114a20e19 which increased the allowed tolerance a bit to fix the mac arm build. However, that increase is not sufficient for ix86 and the tolerance must be increased further to not fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12390
https://github.com/root-project/root/issues/12394:494,deployability,Scale,Scale,494,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:514,deployability,Scale,Scale,514,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:494,energy efficiency,Scale,Scale,494,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:514,energy efficiency,Scale,Scale,514,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:577,energy efficiency,Draw,Draw,577,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:597,energy efficiency,Draw,Draw,597,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:494,modifiability,Scal,Scale,494,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:514,modifiability,Scal,Scale,514,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:494,performance,Scale,Scale,494,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:514,performance,Scale,Scale,514,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:150,safety,test,test,150,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:208,safety,test,test,208,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:150,testability,test,test,150,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:208,testability,test,test,208,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:728,usability,user,user-images,728,"To debug I will use:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. // make two histograms with different xmax. auto h15 = new TH1F(""h15"",""test histogram"", 152, 0, 15);. auto h25 = new TH1F(""h25"",""test histogram"", 252, 0, 25);. TF1 *gaus = (TF1*)gROOT->GetFunction(""gaus"");. gaus->SetParameters(1, 0, 15); // Constant, Mean, Sigma. h15->FillRandom(""gaus"", 10000);. gaus->SetParameters(1, 0, 25); // Constant, Mean, Sigma. h25->FillRandom(""gaus"", 10000);. h25->SetLineColor(2);. h15->Scale(.0005);. h25->Scale(.02);. h25->SetMaximum(10);. h25->SetMinimum(.01);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. }. ```. it gives me:. <img width=""632"" alt=""Screenshot 2023-03-01 at 17 37 38"" src=""https://user-images.githubusercontent.com/4697738/222203726-4dfd1c6c-5cb1-4eca-964e-7a56ea07e6f5.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:10,energy efficiency,Draw,Draw,10,"```. h15->Draw(""hist same ]["");. ```. improves the plot.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:464,energy efficiency,Draw,Draw,464,"Simpler reproducer:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. auto C = new TCanvas();. C->Divide(2,1);. auto h15 = new TH1F(""h15"",""h15"", 3, 10, 15);. auto h25 = new TH1F(""h25"",""h25"", 5, 0, 25);. h15->Fill(11,.5);. h15->Fill(12,1.);. h15->Fill(14,.5);. h15->SetLineWidth(3);. h25->Fill(1,1);. h25->Fill(6,2);. h25->Fill(11,3);. h25->Fill(16,2);. h25->Fill(23,1);. h25->SetLineColor(2);. h25->SetLineWidth(3);. h25->SetMinimum(.05);. C->cd(1);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. gPad->SetGridx(1);. gPad->SetGridy(1);. C->cd(2);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetGridx(1);. gPad->SetGridy(1);. }. ```. <img width=""673"" alt=""Screenshot 2023-03-07 at 16 52 02"" src=""https://user-images.githubusercontent.com/4697738/223475015-4d72384f-e7d0-4d1c-8428-c3addbcd7973.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:484,energy efficiency,Draw,Draw,484,"Simpler reproducer:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. auto C = new TCanvas();. C->Divide(2,1);. auto h15 = new TH1F(""h15"",""h15"", 3, 10, 15);. auto h25 = new TH1F(""h25"",""h25"", 5, 0, 25);. h15->Fill(11,.5);. h15->Fill(12,1.);. h15->Fill(14,.5);. h15->SetLineWidth(3);. h25->Fill(1,1);. h25->Fill(6,2);. h25->Fill(11,3);. h25->Fill(16,2);. h25->Fill(23,1);. h25->SetLineColor(2);. h25->SetLineWidth(3);. h25->SetMinimum(.05);. C->cd(1);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. gPad->SetGridx(1);. gPad->SetGridy(1);. C->cd(2);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetGridx(1);. gPad->SetGridy(1);. }. ```. <img width=""673"" alt=""Screenshot 2023-03-07 at 16 52 02"" src=""https://user-images.githubusercontent.com/4697738/223475015-4d72384f-e7d0-4d1c-8428-c3addbcd7973.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:579,energy efficiency,Draw,Draw,579,"Simpler reproducer:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. auto C = new TCanvas();. C->Divide(2,1);. auto h15 = new TH1F(""h15"",""h15"", 3, 10, 15);. auto h25 = new TH1F(""h25"",""h25"", 5, 0, 25);. h15->Fill(11,.5);. h15->Fill(12,1.);. h15->Fill(14,.5);. h15->SetLineWidth(3);. h25->Fill(1,1);. h25->Fill(6,2);. h25->Fill(11,3);. h25->Fill(16,2);. h25->Fill(23,1);. h25->SetLineColor(2);. h25->SetLineWidth(3);. h25->SetMinimum(.05);. C->cd(1);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. gPad->SetGridx(1);. gPad->SetGridy(1);. C->cd(2);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetGridx(1);. gPad->SetGridy(1);. }. ```. <img width=""673"" alt=""Screenshot 2023-03-07 at 16 52 02"" src=""https://user-images.githubusercontent.com/4697738/223475015-4d72384f-e7d0-4d1c-8428-c3addbcd7973.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:599,energy efficiency,Draw,Draw,599,"Simpler reproducer:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. auto C = new TCanvas();. C->Divide(2,1);. auto h15 = new TH1F(""h15"",""h15"", 3, 10, 15);. auto h25 = new TH1F(""h25"",""h25"", 5, 0, 25);. h15->Fill(11,.5);. h15->Fill(12,1.);. h15->Fill(14,.5);. h15->SetLineWidth(3);. h25->Fill(1,1);. h25->Fill(6,2);. h25->Fill(11,3);. h25->Fill(16,2);. h25->Fill(23,1);. h25->SetLineColor(2);. h25->SetLineWidth(3);. h25->SetMinimum(.05);. C->cd(1);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. gPad->SetGridx(1);. gPad->SetGridy(1);. C->cd(2);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetGridx(1);. gPad->SetGridy(1);. }. ```. <img width=""673"" alt=""Screenshot 2023-03-07 at 16 52 02"" src=""https://user-images.githubusercontent.com/4697738/223475015-4d72384f-e7d0-4d1c-8428-c3addbcd7973.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:0,testability,Simpl,Simpler,0,"Simpler reproducer:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. auto C = new TCanvas();. C->Divide(2,1);. auto h15 = new TH1F(""h15"",""h15"", 3, 10, 15);. auto h25 = new TH1F(""h25"",""h25"", 5, 0, 25);. h15->Fill(11,.5);. h15->Fill(12,1.);. h15->Fill(14,.5);. h15->SetLineWidth(3);. h25->Fill(1,1);. h25->Fill(6,2);. h25->Fill(11,3);. h25->Fill(16,2);. h25->Fill(23,1);. h25->SetLineColor(2);. h25->SetLineWidth(3);. h25->SetMinimum(.05);. C->cd(1);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. gPad->SetGridx(1);. gPad->SetGridy(1);. C->cd(2);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetGridx(1);. gPad->SetGridy(1);. }. ```. <img width=""673"" alt=""Screenshot 2023-03-07 at 16 52 02"" src=""https://user-images.githubusercontent.com/4697738/223475015-4d72384f-e7d0-4d1c-8428-c3addbcd7973.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:0,usability,Simpl,Simpler,0,"Simpler reproducer:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. auto C = new TCanvas();. C->Divide(2,1);. auto h15 = new TH1F(""h15"",""h15"", 3, 10, 15);. auto h25 = new TH1F(""h25"",""h25"", 5, 0, 25);. h15->Fill(11,.5);. h15->Fill(12,1.);. h15->Fill(14,.5);. h15->SetLineWidth(3);. h25->Fill(1,1);. h25->Fill(6,2);. h25->Fill(11,3);. h25->Fill(16,2);. h25->Fill(23,1);. h25->SetLineColor(2);. h25->SetLineWidth(3);. h25->SetMinimum(.05);. C->cd(1);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. gPad->SetGridx(1);. gPad->SetGridy(1);. C->cd(2);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetGridx(1);. gPad->SetGridy(1);. }. ```. <img width=""673"" alt=""Screenshot 2023-03-07 at 16 52 02"" src=""https://user-images.githubusercontent.com/4697738/223475015-4d72384f-e7d0-4d1c-8428-c3addbcd7973.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/issues/12394:737,usability,user,user-images,737,"Simpler reproducer:. ```. {. gStyle->SetOptStat(0);. gStyle->SetOptTitle(0);. auto C = new TCanvas();. C->Divide(2,1);. auto h15 = new TH1F(""h15"",""h15"", 3, 10, 15);. auto h25 = new TH1F(""h25"",""h25"", 5, 0, 25);. h15->Fill(11,.5);. h15->Fill(12,1.);. h15->Fill(14,.5);. h15->SetLineWidth(3);. h25->Fill(1,1);. h25->Fill(6,2);. h25->Fill(11,3);. h25->Fill(16,2);. h25->Fill(23,1);. h25->SetLineColor(2);. h25->SetLineWidth(3);. h25->SetMinimum(.05);. C->cd(1);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetLogy(1);. gPad->SetGridx(1);. gPad->SetGridy(1);. C->cd(2);. h25->Draw(""hist"");. h15->Draw(""hist same"");. gPad->SetGridx(1);. gPad->SetGridy(1);. }. ```. <img width=""673"" alt=""Screenshot 2023-03-07 at 16 52 02"" src=""https://user-images.githubusercontent.com/4697738/223475015-4d72384f-e7d0-4d1c-8428-c3addbcd7973.png"">.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12394
https://github.com/root-project/root/pull/12396:34,availability,error,error,34,"Hello, I think there was a little error when rebasing. 🙂. A lot of people got requested as reviewers, as there's quite some commits unrelated to ntuple. 🙂",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12396
https://github.com/root-project/root/pull/12396:34,performance,error,error,34,"Hello, I think there was a little error when rebasing. 🙂. A lot of people got requested as reviewers, as there's quite some commits unrelated to ntuple. 🙂",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12396
https://github.com/root-project/root/pull/12396:34,safety,error,error,34,"Hello, I think there was a little error when rebasing. 🙂. A lot of people got requested as reviewers, as there's quite some commits unrelated to ntuple. 🙂",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12396
https://github.com/root-project/root/pull/12396:91,safety,review,reviewers,91,"Hello, I think there was a little error when rebasing. 🙂. A lot of people got requested as reviewers, as there's quite some commits unrelated to ntuple. 🙂",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12396
https://github.com/root-project/root/pull/12396:91,testability,review,reviewers,91,"Hello, I think there was a little error when rebasing. 🙂. A lot of people got requested as reviewers, as there's quite some commits unrelated to ntuple. 🙂",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12396
https://github.com/root-project/root/pull/12396:34,usability,error,error,34,"Hello, I think there was a little error when rebasing. 🙂. A lot of people got requested as reviewers, as there's quite some commits unrelated to ntuple. 🙂",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12396
https://github.com/root-project/root/pull/12397:76,modifiability,inherit,inherited,76,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:153,modifiability,inherit,inherit,153,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:208,modifiability,inherit,inherit,208,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:303,reliability,doe,doesn,303,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:261,safety,compl,complications,261,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:571,safety,risk,risk,571,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:618,safety,accid,accidentally,618,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:261,security,compl,complications,261,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:571,security,risk,risk,571,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:199,usability,user,users,199,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12397:525,usability,clear,clear,525,"Hi! I'm not sure if this is a good idea. The ROOT Fitter is not meant to be inherited from in C++, right? It has no virtual functions, and nowhere do we inherit from it. I'm worried that encouraging users to inherit from the Fitter like this will cause further complications, so maybe it's good that it doesn't work? What is the benefit of this? If you think this is really necessary, maybe better add a comment to the destructor explaining why it needs to be `virtual` for PyROOT, because when reading the C++ code it's not clear why it should be there and there is the risk that future developers interpret it as an accidentally added keyword and remove it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12397
https://github.com/root-project/root/pull/12399:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12399
https://github.com/root-project/root/pull/12399:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12399
https://github.com/root-project/root/pull/12400:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12400
https://github.com/root-project/root/pull/12400:0,availability,Failur,Failures,0,"Failures on windows look unrelated, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12400
https://github.com/root-project/root/pull/12400:0,deployability,Fail,Failures,0,"Failures on windows look unrelated, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12400
https://github.com/root-project/root/pull/12400:0,performance,Failur,Failures,0,"Failures on windows look unrelated, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12400
https://github.com/root-project/root/pull/12400:0,reliability,Fail,Failures,0,"Failures on windows look unrelated, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12400
https://github.com/root-project/root/pull/12401:754,safety,test,testProblem,754,"Let me report the printouts I did and what I got. ### Printout in THistpainter at line 7102. ```. printf("">>> FindFixBin is called from THisPainter line 7102 - Hparam.xmin = %g\n"",Hparam.xmin);. Hparam.xfirst= fXaxis->FindFixBin(Hparam.xmin);. ```. ### Printout in TAxis at line 428. ```. printf("">>> bin is calculated in FindFixBin at line 428\n"");. bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin));. printf(""fNbins = %d\n"", fNbins);. printf(""x = %g\n"", x);. printf(""fXmin = %g\n"", fXmin);. printf(""fXmax = %g\n"", fXmax);. printf(""int(fNbins*(x-fXmin)/(fXmax-fXmin) = %d\n"", int (fNbins*(x-fXmin)/(fXmax-fXmin)));. printf("">>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin))\n"");. printf(""bin = %d\n"", bin);. printf(""\n"");. ```. ### Execution of the macro testProblem.C given earlier. ```. >>> FindFixBin is called from THisPainter line 7102 - Hparam.xmin = 0.00125. >>> bin is calculated in FindFixBin at line 428. fNbins = 4. x = 0.00125. fXmin = 0. fXmax = 0.005. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 1. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 2. >>> FindFixBin is called from THisPainter line 7102 - Hparam.xmin = 0.00125. >>> bin is calculated in FindFixBin at line 428. fNbins = 4. x = 0.00125. fXmin = 0. fXmax = 0.005. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 0. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 1. ```. As you can see with the same value we do not get the same bin number. 2 is the correct answer. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12401
https://github.com/root-project/root/pull/12401:754,testability,test,testProblem,754,"Let me report the printouts I did and what I got. ### Printout in THistpainter at line 7102. ```. printf("">>> FindFixBin is called from THisPainter line 7102 - Hparam.xmin = %g\n"",Hparam.xmin);. Hparam.xfirst= fXaxis->FindFixBin(Hparam.xmin);. ```. ### Printout in TAxis at line 428. ```. printf("">>> bin is calculated in FindFixBin at line 428\n"");. bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin));. printf(""fNbins = %d\n"", fNbins);. printf(""x = %g\n"", x);. printf(""fXmin = %g\n"", fXmin);. printf(""fXmax = %g\n"", fXmax);. printf(""int(fNbins*(x-fXmin)/(fXmax-fXmin) = %d\n"", int (fNbins*(x-fXmin)/(fXmax-fXmin)));. printf("">>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin))\n"");. printf(""bin = %d\n"", bin);. printf(""\n"");. ```. ### Execution of the macro testProblem.C given earlier. ```. >>> FindFixBin is called from THisPainter line 7102 - Hparam.xmin = 0.00125. >>> bin is calculated in FindFixBin at line 428. fNbins = 4. x = 0.00125. fXmin = 0. fXmax = 0.005. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 1. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 2. >>> FindFixBin is called from THisPainter line 7102 - Hparam.xmin = 0.00125. >>> bin is calculated in FindFixBin at line 428. fNbins = 4. x = 0.00125. fXmin = 0. fXmax = 0.005. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 0. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 1. ```. As you can see with the same value we do not get the same bin number. 2 is the correct answer. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12401
https://github.com/root-project/root/pull/12401:144,availability,error,error,144,"It is not the same values. If you print all digits (and using `double` in the macro for `x1` and `x2`, you should never use `float`, this is an error in the code provided):. ```. >>> bin is calculated in FindFixBin at line 428 - parent is h1. fNbins = 4. x = 0.00125000000000000003. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 1. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 2. >>> bin is calculated in FindFixBin at line 428 - parent is h2. fNbins = 4. x = 0.00124999999999999959. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 0. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 1. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12401
https://github.com/root-project/root/pull/12401:144,performance,error,error,144,"It is not the same values. If you print all digits (and using `double` in the macro for `x1` and `x2`, you should never use `float`, this is an error in the code provided):. ```. >>> bin is calculated in FindFixBin at line 428 - parent is h1. fNbins = 4. x = 0.00125000000000000003. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 1. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 2. >>> bin is calculated in FindFixBin at line 428 - parent is h2. fNbins = 4. x = 0.00124999999999999959. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 0. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 1. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12401
https://github.com/root-project/root/pull/12401:144,safety,error,error,144,"It is not the same values. If you print all digits (and using `double` in the macro for `x1` and `x2`, you should never use `float`, this is an error in the code provided):. ```. >>> bin is calculated in FindFixBin at line 428 - parent is h1. fNbins = 4. x = 0.00125000000000000003. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 1. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 2. >>> bin is calculated in FindFixBin at line 428 - parent is h2. fNbins = 4. x = 0.00124999999999999959. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 0. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 1. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12401
https://github.com/root-project/root/pull/12401:144,usability,error,error,144,"It is not the same values. If you print all digits (and using `double` in the macro for `x1` and `x2`, you should never use `float`, this is an error in the code provided):. ```. >>> bin is calculated in FindFixBin at line 428 - parent is h1. fNbins = 4. x = 0.00125000000000000003. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 1. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 2. >>> bin is calculated in FindFixBin at line 428 - parent is h2. fNbins = 4. x = 0.00124999999999999959. fXmin = 0.00000000000000000000. fXmax = 0.00500000000000000010. int(fNbins*(x-fXmin)/(fXmax-fXmin) = 0. >>> bin = 1 + int (fNbins*(x-fXmin)/(fXmax-fXmin)). bin = 1. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12401
https://github.com/root-project/root/issues/12406:35,deployability,updat,update,35,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:111,deployability,version,version,111,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:125,deployability,Version,Version,125,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:614,deployability,version,version,614,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:628,deployability,Version,Version,628,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1079,deployability,version,version,1079,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1093,deployability,Version,Version,1093,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:555,energy efficiency,load,load,555,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1020,energy efficiency,load,load,1020,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1485,energy efficiency,load,load,1485,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:111,integrability,version,version,111,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:125,integrability,Version,Version,125,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:614,integrability,version,version,614,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:628,integrability,Version,Version,628,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1079,integrability,version,version,1079,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1093,integrability,Version,Version,1093,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:578,interoperability,share,shared,578,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1043,interoperability,share,shared,1043,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1508,interoperability,share,shared,1508,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:111,modifiability,version,version,111,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:125,modifiability,Version,Version,125,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:614,modifiability,version,version,614,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:628,modifiability,Version,Version,628,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1079,modifiability,version,version,1079,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1093,modifiability,Version,Version,1093,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:555,performance,load,load,555,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1020,performance,load,load,1020,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1485,performance,load,load,1485,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:35,safety,updat,update,35,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:248,safety,test,test,248,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:471,safety,Test,Test,471,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:484,safety,Test,Test,484,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:497,safety,Test,Test,497,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:510,safety,Test,Test,510,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:523,safety,Test,Test,523,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:714,safety,test,test,714,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:936,safety,Test,Test,936,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:949,safety,Test,Test,949,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:962,safety,Test,Test,962,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:975,safety,Test,Test,975,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:988,safety,Test,Test,988,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1179,safety,test,test,1179,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1401,safety,Test,Test,1401,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1414,safety,Test,Test,1414,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1427,safety,Test,Test,1427,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1440,safety,Test,Test,1440,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1453,safety,Test,Test,1453,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:35,security,updat,update,35,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:248,testability,test,test,248,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:471,testability,Test,Test,471,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:484,testability,Test,Test,484,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:497,testability,Test,Test,497,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:510,testability,Test,Test,510,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:523,testability,Test,Test,523,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:714,testability,test,test,714,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:936,testability,Test,Test,936,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:949,testability,Test,Test,949,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:962,testability,Test,Test,962,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:975,testability,Test,Test,975,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:988,testability,Test,Test,988,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1179,testability,test,test,1179,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1401,testability,Test,Test,1401,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1414,testability,Test,Test,1414,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1427,testability,Test,Test,1427,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1440,testability,Test,Test,1440,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1453,testability,Test,Test,1453,"Hi, thanks for the report. A small update, this seems to be an issue since at least ROOT 6.24:. ```. $: root --version. ROOT Version: 6.29/01. Built for linuxx8664gcc on Feb 26 2023, 17:20:00. From heads/master@v6-25-02-4093-g23b30e03c3. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.26/10. Built for linuxx8664gcc on Nov 17 2022, 16:21:00. From @. $: python test.py. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_10'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```. ```. $: root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on May 02 2022, 19:26:00. From @. $: python test.py . IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK4TestS4_EEbT_S5_T0_' unresolved while linking symbol '__cf_9'! You are probably missing the definition of bool std::__equal<false>::equal<Test const*, Test const*>(Test const*, Test const*, Test const*). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:80,deployability,fail,fails,80,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:237,deployability,version,version,237,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:20,energy efficiency,reduc,reduced,20,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:237,integrability,version,version,237,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:237,modifiability,version,version,237,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:80,reliability,fail,fails,80,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:199,reliability,doe,does,199,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:262,reliability,doe,does,262,"Hm, yes --- maybe i reduced things too much. As you said, the example here also fails with 6.26.08, which is what's used in the ATLAS development branch; however the full example that i started with does in fact work correctly with this version. So, while there does seem to be an issue here, there seems to be something else going on as well...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:73,availability,failur,failure,73,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:83,availability,error,error,83,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:73,deployability,fail,failure,73,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:89,integrability,messag,message,89,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:89,interoperability,messag,message,89,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:73,performance,failur,failure,73,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:83,performance,error,error,83,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:73,reliability,fail,failure,73,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:83,safety,error,error,83,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:17,usability,help,help,17,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:83,usability,error,error,83,How much will it help ATLAS if I fix this reproducer? What is the actual failure's error message?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:274,availability,error,error,274,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:915,availability,error,error,915,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1511,availability,error,error,1511,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1663,availability,error,error,1663,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:173,deployability,integr,integration,173,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:922,deployability,Fail,Failed,922,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1518,deployability,Fail,Failed,1518,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1670,deployability,Fail,Failed,1670,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:858,energy efficiency,load,load,858,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1454,energy efficiency,load,load,1454,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:173,integrability,integration test,integration tests,173,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:280,integrability,messag,message,280,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:88,interoperability,specif,specific,88,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:173,interoperability,integr,integration,173,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:280,interoperability,messag,message,280,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:881,interoperability,share,shared,881,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1477,interoperability,share,shared,1477,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:173,modifiability,integr,integration,173,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:274,performance,error,error,274,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:858,performance,load,load,858,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:915,performance,error,error,915,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1454,performance,load,load,1454,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1511,performance,error,error,1511,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1663,performance,error,error,1663,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:173,reliability,integr,integration,173,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:922,reliability,Fail,Failed,922,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1518,reliability,Fail,Failed,1518,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1670,reliability,Fail,Failed,1670,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:185,safety,test,tests,185,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:274,safety,error,error,274,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:915,safety,error,error,915,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1511,safety,error,error,1511,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1663,safety,error,error,1663,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:173,security,integr,integration,173,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:907,security,session,session,907,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1503,security,session,session,1503,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1655,security,session,session,1655,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:173,testability,integr,integration,173,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:185,testability,test,tests,185,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:274,usability,error,error,274,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:915,usability,error,error,915,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1511,usability,error,error,1511,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1663,usability,error,error,1663,"This problem is blocking ATLAS in adopting ROOT 6.28.x in production. . We use an ATLAS specific pyROOT script 'diff-root' that compares AODs branch-by-branch in our CI and integration tests that is not working in ROOT 6.28.x with the symptoms described above. The original error message of this script is:. ```. [..]. Py:diff-root INFO comparing [2932] leaves over entries... IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPKN4xAOD28CaloClusterBadChannelData_v1ES5_EEbT_S6_T0_' unresolved while linking symbol '__cf_295'! You are probably missing the definition of bool std::__equal<false>::equal<xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*>(xAOD::CaloClusterBadChannelData_v1. const*, xAOD::CaloClusterBadChannelData_v1 const*, xAOD::CaloClusterBadChannelData_v1 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZSteqISt6vectorIN4xAOD28CaloClusterBadChannelData_v1ESaIS2_EESaIS4_EEbRKS0_IT_T0_ESA_ }) }. IncrementalExecutor::executeFunction: symbol '_ZNSt7__equalILb0EE5equalIPK20TrigRoiDescriptor_p3S4_EEbT_S5_T0_' unresolved while linking symbol '__cf_452'! You are probably missing the definition of bool std::__equal<false>::equal<TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*>(TrigRoiDescriptor_p3 const*, TrigRoiDescriptor_p3 const*, Trig. RoiDescriptor_p3 const*). Maybe you need to load the corresponding shared library? cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN16__cppyy_internal8is_equalI30TrigRoiDescriptorCollection_p3S1_EEbRKT_RKT0_ }) }. [..] . ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:34,energy efficiency,current,current,34,"I've looked at this again, and in current dev4, anyway, the blocking issue is somewhat different, and it looks like we can avoid the issue on the ATLAS side. Further details to follow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:123,safety,avoid,avoid,123,"I've looked at this again, and in current dev4, anyway, the blocking issue is somewhat different, and it looks like we can avoid the issue on the ATLAS side. Further details to follow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1793,availability,slo,slowly,1793,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1839,availability,error,errors,1839,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1448,integrability,interfac,interface,1448,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1805,integrability,event,eventually,1805,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1064,interoperability,format,format,1064,"s. Turns out we have problems with RootUtils::objetIsA:. ```. TClass* objectIsA (PyObject* obj). {. PyObject* repr = PyObject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change ge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1448,interoperability,interfac,interface,1448,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1448,modifiability,interfac,interface,1448,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1349,performance,time,time,1349,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1832,performance,memor,memory,1832,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1839,performance,error,errors,1839,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1991,performance,time,time,1991,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:817,reliability,doe,does,817,"Further information from ATEAM-885:. Ok, i took another look at this. Turns out we have problems with RootUtils::objetIsA:. ```. TClass* objectIsA (PyObject* obj). {. PyObject* repr = PyObject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1111,reliability,doe,doesn,1111,"bjetIsA:. ```. TClass* objectIsA (PyObject* obj). {. PyObject* repr = PyObject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1458,reliability,doe,doesn,1458,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1793,reliability,slo,slowly,1793,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1901,reliability,doe,does,1901,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1839,safety,error,errors,1839,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:2088,safety,test,tests,2088,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:683,security,ident,identify,683,"Further information from ATEAM-885:. Ok, i took another look at this. Turns out we have problems with RootUtils::objetIsA:. ```. TClass* objectIsA (PyObject* obj). {. PyObject* repr = PyObject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1627,testability,regress,regression,1627,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:2032,testability,verif,verify,2032,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:2083,testability,unit,unit,2083,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:2088,testability,test,tests,2088,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1832,usability,memor,memory,1832,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:1839,usability,error,errors,1839,"bject_Repr (obj);. if (!repr) return nullptr;. const char* s = PyROOT_PyUnicode_AsString (repr);. if (*s == '<') ++s;. if (strncmp (s, ""ROOT."", 5) == 0). s += 5;. if (strncmp (s, ""cppyy.gbl."", 10) == 0). s += 10;. const char* p = strstr (s, "" object "");. if (!p) return nullptr;. std::string name;. name.reserve (p-s + 10);. while (s < p) {. if (*s == '.'). name += ""::"";. else. name += *s;. ++s;. }. TClass* cls = TClass::GetClass (name.c_str());. Py_DECREF (repr);. return cls;. }. ```. We can identify at least three distinct problems here. 1. First, this code is stupid. It's trying to get the TClass for a pyroot. object. It does this by calling repr on the object (which could result. in something very large) and then trying to extract the class name. and looking it up with TClass. In fact, it looks like this hasn't. actually been working for a while now, because the format of the repr. string changed --- and now doesn't include the 'object' string. If i change this to instead use Py_TYPE(obj)->tp_name, then everything. works (and much faster too!). 2. I originally added this code here, but from the comments, it was copied. from the pyroot of the time. The reason why we're doing this in this. roundabout way to begin with is because the TPython interface doesn't. supply any way to get the TClass from a pyroot object. If it would. add a call for that, than this could be streamlined. 3. Finally, there seems to have been a regression with finding the repr. string for a pyroot object between 6.26.10 and dev4. If i have a loop. just calling repr for a vector<float> instance, it runs very slowly. and eventually starts printing memory errors from cling. But with 6.26.10,. it runs much faster and does not start crashing. It sounds sort of like. code is now being repeatedly jitted each time with dev4, but i have. not tried to verify that. Anyway, this change gets at least the unit tests working. Will try to get. that merged soon, and will try to report the repr issue separately.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:135,availability,failur,failure,135,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:135,deployability,fail,failure,135,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:74,performance,time,time,74,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:135,performance,failur,failure,135,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:135,reliability,fail,failure,135,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:130,safety,test,test,130,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:130,testability,test,test,130,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:196,usability,progress,progress,196,"> will try to report the repr issue separately. Thanks for investing your time here, much appreciated! I still want to debug this test failure here, so please leave this open independently of the progress you're making on the ATLAS side.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:661,deployability,fail,fail,661,"I can't imagine why you'd want to write a function like the above, certainly adding such a function to TPython would only be possible as a ROOT add-on (cppyy 4.0.0 will be free from `TClass` and already since 1.0.0, the CPython portion of cppyy is agnostic to it). However, if you must, then `Py_TYPE(obj)->tp_name` isn't the ticket, but the `__cpp_name__` attribute is. The latter exists for the benefit of template instantiations and is the only place to guarantee you the correct (and valid) C++ name. In case of enums, Python-side derived classes, public typedefs of private nested classes, and probably some more corner cases, `Py_TYPE(obj)->tp_name` will fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:552,integrability,pub,public,552,"I can't imagine why you'd want to write a function like the above, certainly adding such a function to TPython would only be possible as a ROOT add-on (cppyy 4.0.0 will be free from `TClass` and already since 1.0.0, the CPython portion of cppyy is agnostic to it). However, if you must, then `Py_TYPE(obj)->tp_name` isn't the ticket, but the `__cpp_name__` attribute is. The latter exists for the benefit of template instantiations and is the only place to guarantee you the correct (and valid) C++ name. In case of enums, Python-side derived classes, public typedefs of private nested classes, and probably some more corner cases, `Py_TYPE(obj)->tp_name` will fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:661,reliability,fail,fail,661,"I can't imagine why you'd want to write a function like the above, certainly adding such a function to TPython would only be possible as a ROOT add-on (cppyy 4.0.0 will be free from `TClass` and already since 1.0.0, the CPython portion of cppyy is agnostic to it). However, if you must, then `Py_TYPE(obj)->tp_name` isn't the ticket, but the `__cpp_name__` attribute is. The latter exists for the benefit of template instantiations and is the only place to guarantee you the correct (and valid) C++ name. In case of enums, Python-side derived classes, public typedefs of private nested classes, and probably some more corner cases, `Py_TYPE(obj)->tp_name` will fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:488,safety,valid,valid,488,"I can't imagine why you'd want to write a function like the above, certainly adding such a function to TPython would only be possible as a ROOT add-on (cppyy 4.0.0 will be free from `TClass` and already since 1.0.0, the CPython portion of cppyy is agnostic to it). However, if you must, then `Py_TYPE(obj)->tp_name` isn't the ticket, but the `__cpp_name__` attribute is. The latter exists for the benefit of template instantiations and is the only place to guarantee you the correct (and valid) C++ name. In case of enums, Python-side derived classes, public typedefs of private nested classes, and probably some more corner cases, `Py_TYPE(obj)->tp_name` will fail.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/issues/12406:54,usability,close,closed,54,"Thanks to the explanation of @wlav, this issue can be closed. If you have further issues with PyROOT, feel free to open new issues @scott-snyder!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12406
https://github.com/root-project/root/pull/12407:106,deployability,instal,install,106,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:150,deployability,instal,installs,150,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:199,deployability,instal,install,199,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:268,deployability,instal,installation,268,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:15,modifiability,pac,packaged,15,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:55,modifiability,pac,packages,55,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:170,modifiability,pac,package,170,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:224,modifiability,pac,package,224,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:178,reliability,doe,does,178,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:96,usability,user,users,96,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/pull/12407:263,usability,user,user,263,"This is an RPM packaged root. It is split into several packages in order to be flexible so that users can install the parts they need. So someone who installs the pyroot package does not necessarily install also the distrdf package, so it can be missing in their user installation. They should still be able to use the non-distrdf part of ROOT.RDF namespace.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12407
https://github.com/root-project/root/issues/12409:0,deployability,Updat,Update,0,Update: I can reproduce this with the (for our tests nicer) case. ```bash. mkdir cling. chmod a-xr cling. root. ```. which gives the same diagnostics as above.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:138,reliability,diagno,diagnostics,138,Update: I can reproduce this with the (for our tests nicer) case. ```bash. mkdir cling. chmod a-xr cling. root. ```. which gives the same diagnostics as above.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:0,safety,Updat,Update,0,Update: I can reproduce this with the (for our tests nicer) case. ```bash. mkdir cling. chmod a-xr cling. root. ```. which gives the same diagnostics as above.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:47,safety,test,tests,47,Update: I can reproduce this with the (for our tests nicer) case. ```bash. mkdir cling. chmod a-xr cling. root. ```. which gives the same diagnostics as above.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:0,security,Updat,Update,0,Update: I can reproduce this with the (for our tests nicer) case. ```bash. mkdir cling. chmod a-xr cling. root. ```. which gives the same diagnostics as above.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:47,testability,test,tests,47,Update: I can reproduce this with the (for our tests nicer) case. ```bash. mkdir cling. chmod a-xr cling. root. ```. which gives the same diagnostics as above.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:138,testability,diagno,diagnostics,138,Update: I can reproduce this with the (for our tests nicer) case. ```bash. mkdir cling. chmod a-xr cling. root. ```. which gives the same diagnostics as above.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:124,availability,echo,echo,124,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:245,availability,error,error,245,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:360,availability,error,error,360,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:684,availability,error,errors,684,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:630,integrability,sub,subsequent,630,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:245,performance,error,error,245,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:360,performance,error,error,360,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:684,performance,error,errors,684,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:6,reliability,doe,does,6,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:245,safety,error,error,245,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:299,safety,Permiss,Permission,299,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:360,safety,error,error,360,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:684,safety,error,errors,684,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:43,security,access,accessible,43,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:245,usability,error,error,245,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:360,usability,error,error,360,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/issues/12409:684,usability,error,errors,684,"clang does not work when launched from non-accessible folder, either:. ```. $ mkdir noread. $ cd noread/. $ chmod a-rwx . $ echo '#include ""ROOT/config/RVersion.hxx""' | clang++ -I. -I$ROOTSYS/include/ -fsyntax-only -x c++ -. <stdin>:1:10: fatal error: cannot open file './ROOT/config/RVersion.hxx': Permission denied. #include ""ROOT/config/RVersion.hxx"". ^. 1 error generated. ```. I.e. clang tries to argue ""don't do that"". But I would argue ""clang, please."" because it even just goes on and finds the header! This was introduced [here](https://github.com/llvm/llvm-project/commit/babdfdec90bb978799bcccf1ee0c856678b0ef7b), with subsequent refinements to not have so many irrelevant errors. https://github.com/root-project/root/pull/12418 now adds another case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12409
https://github.com/root-project/root/pull/12410:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:31,availability,failur,failure,31,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:49,availability,failur,failure,49,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:31,deployability,fail,failure,31,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:49,deployability,fail,failure,49,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:24,interoperability,format,format,24,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:31,performance,failur,failure,31,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:49,performance,failur,failure,49,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:31,reliability,fail,failure,31,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:49,reliability,fail,failure,49,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:7,testability,understand,understand,7,DO not understand clang-format failure. ubuntu20 failure seems unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:12,deployability,build,build,12,did the mac build fail because of the warnings?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:18,deployability,fail,fail,18,did the mac build fail because of the warnings?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:18,reliability,fail,fail,18,did the mac build fail because of the warnings?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:33,availability,failur,failure,33,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:33,deployability,fail,failure,33,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:26,interoperability,format,format,26,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:61,interoperability,format,format,61,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:33,performance,failur,failure,33,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:33,reliability,fail,failure,33,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:230,safety,review,reviewing,230,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:9,testability,understand,understand,9,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12410:230,testability,review,reviewing,230,"> DO not understand clang-format failure. My 2 cents: `clang-format` is unhappy about some old code, but I think it's not a good idea to fix it in the same commit that also introduces functional changes. On the contrary, it makes reviewing the diff quite difficult...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12410
https://github.com/root-project/root/pull/12413:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12413
https://github.com/root-project/root/pull/12413:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12413
https://github.com/root-project/root/pull/12413:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12413
https://github.com/root-project/root/pull/12413:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12413
https://github.com/root-project/root/pull/12415:47,interoperability,coordinat,coordinates,47,I have added all the possible classes defining coordinates.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12415
https://github.com/root-project/root/pull/12417:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12417
https://github.com/root-project/root/pull/12418:54,safety,review,reviews,54,"See my [comment on the original differential](https://reviews.llvm.org/D65956#4167101); I think we need something else, actually.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:54,testability,review,reviews,54,"See my [comment on the original differential](https://reviews.llvm.org/D65956#4167101); I think we need something else, actually.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:12,availability,failur,failure,12,The windows failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:12,deployability,fail,failure,12,The windows failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:12,performance,failur,failure,12,The windows failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:12,reliability,fail,failure,12,The windows failure is unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:42,deployability,patch,patch,42,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:146,deployability,patch,patches,146,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:42,safety,patch,patch,42,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:72,safety,review,review,72,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:146,safety,patch,patches,146,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:42,security,patch,patch,42,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:146,security,patch,patches,146,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12418:72,testability,review,review,72,> Looks like we will have to propose this patch to llvm. Can you open a review for it? ... and we should definitely add this change to our set of patches in https://github.com/root-project/llvm-project/! The `llvm-diff` job is getting less and less hapy...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12418
https://github.com/root-project/root/pull/12421:87,testability,simpl,simplify,87,"Ok, so, despite being a native speaker, I'll admit writing is not my forte. I tried to simplify what you wrote a bit, but please lmk what to change.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12421
https://github.com/root-project/root/pull/12421:87,usability,simpl,simplify,87,"Ok, so, despite being a native speaker, I'll admit writing is not my forte. I tried to simplify what you wrote a bit, but please lmk what to change.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12421
https://github.com/root-project/root/pull/12422:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:325,performance,content,contents,325,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:66,safety,test,test,66,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:125,safety,test,tests,125,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:151,safety,test,test,151,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:208,safety,TEST,TEST,208,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:74,security,control,control,74,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:66,testability,test,test,66,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:74,testability,control,control,74,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:125,testability,test,tests,125,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:151,testability,test,test,151,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:208,testability,TEST,TEST,208,"Hi @edfink234 ,. Thanks a lot for this PR! Could you also add one test to control the functionality of the new overload? The tests are in `math/vecops/test/vecops_rvec.cxx`, for example one could be. ```cpp. TEST(VecOps, TakeN). {. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. CheckEqual(res, {1,2,3,4,1}) // Check the contents of the output vector are correct. }. ```. And similarly for the other use cases of your new function",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:414,deployability,build,build,414,"It seems like it doesn't like the usage of `CheckEqual` (the function is defined at the beginning of the file). You could try to help it by fixing the expected vector type, e.g. ```cpp. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. RVec<int> expected = {1,2,3,4,1};. CheckEqual(res, expected); // Check the contents of the output vector are correct. ```. and so on. If you feel like it, you could also try to build ROOT and test things locally yourself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:312,performance,content,contents,312,"It seems like it doesn't like the usage of `CheckEqual` (the function is defined at the beginning of the file). You could try to help it by fixing the expected vector type, e.g. ```cpp. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. RVec<int> expected = {1,2,3,4,1};. CheckEqual(res, expected); // Check the contents of the output vector are correct. ```. and so on. If you feel like it, you could also try to build ROOT and test things locally yourself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:17,reliability,doe,doesn,17,"It seems like it doesn't like the usage of `CheckEqual` (the function is defined at the beginning of the file). You could try to help it by fixing the expected vector type, e.g. ```cpp. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. RVec<int> expected = {1,2,3,4,1};. CheckEqual(res, expected); // Check the contents of the output vector are correct. ```. and so on. If you feel like it, you could also try to build ROOT and test things locally yourself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:429,safety,test,test,429,"It seems like it doesn't like the usage of `CheckEqual` (the function is defined at the beginning of the file). You could try to help it by fixing the expected vector type, e.g. ```cpp. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. RVec<int> expected = {1,2,3,4,1};. CheckEqual(res, expected); // Check the contents of the output vector are correct. ```. and so on. If you feel like it, you could also try to build ROOT and test things locally yourself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:429,testability,test,test,429,"It seems like it doesn't like the usage of `CheckEqual` (the function is defined at the beginning of the file). You could try to help it by fixing the expected vector type, e.g. ```cpp. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. RVec<int> expected = {1,2,3,4,1};. CheckEqual(res, expected); // Check the contents of the output vector are correct. ```. and so on. If you feel like it, you could also try to build ROOT and test things locally yourself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:129,usability,help,help,129,"It seems like it doesn't like the usage of `CheckEqual` (the function is defined at the beginning of the file). You could try to help it by fixing the expected vector type, e.g. ```cpp. RVec<int> x = {1,2,3,4};. auto res = Take(x,5,1);. RVec<int> expected = {1,2,3,4,1};. CheckEqual(res, expected); // Check the contents of the output vector are correct. ```. and so on. If you feel like it, you could also try to build ROOT and test things locally yourself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:38,deployability,patch,patch,38,It is good practice to check that the patch compiles and the new tests run correctly before pushing,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:11,reliability,pra,practice,11,It is good practice to check that the patch compiles and the new tests run correctly before pushing,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:38,safety,patch,patch,38,It is good practice to check that the patch compiles and the new tests run correctly before pushing,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:65,safety,test,tests,65,It is good practice to check that the patch compiles and the new tests run correctly before pushing,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:38,security,patch,patch,38,It is good practice to check that the patch compiles and the new tests run correctly before pushing,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:65,testability,test,tests,65,It is good practice to check that the patch compiles and the new tests run correctly before pushing,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:44,performance,time,time,44,"Ok, uh I don't get it, what went wrong this time?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:6,deployability,updat,updated,6,"Ok, I updated it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:6,safety,updat,updated,6,"Ok, I updated it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:6,security,updat,updated,6,"Ok, I updated it...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/pull/12422:11,deployability,build,build,11,@phsft-bot build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12422
https://github.com/root-project/root/issues/12426:157,security,access,access,157,"That's super interesting! Many thanks for the report. I think some, but probably not all of it we can fix ""blindly"". Would it be possible to get interactive access to your big endian machine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:145,usability,interact,interactive,145,"That's super interesting! Many thanks for the report. I think some, but probably not all of it we can fix ""blindly"". Would it be possible to get interactive access to your big endian machine?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:10,availability,error,errors,10,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:321,availability,avail,available,321,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:473,availability,avail,available,473,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:38,deployability,build,build,38,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:128,deployability,build,build,128,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:381,deployability,log,log,381,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:415,deployability,build,builds,415,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:792,deployability,patch,patches,792,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:441,energy efficiency,current,currently,441,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:753,interoperability,share,share,753,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:191,modifiability,pac,packager,191,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:361,modifiability,pac,packager,361,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:10,performance,error,errors,10,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:608,performance,disk,disk,608,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:321,reliability,availab,available,321,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:473,reliability,availab,available,473,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:10,safety,error,errors,10,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:321,safety,avail,available,321,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:381,safety,log,log,381,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:460,safety,test,test,460,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:473,safety,avail,available,473,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:657,safety,test,test,657,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:792,safety,patch,patches,792,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:810,safety,test,tests,810,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:321,security,availab,available,321,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:381,security,log,log,381,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:473,security,availab,available,473,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:726,security,access,access,726,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:792,security,patch,patches,792,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:381,testability,log,log,381,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:396,testability,mock,mock,396,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:460,testability,test,test,460,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:657,testability,test,test,657,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:810,testability,test,tests,810,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:10,usability,error,errors,10,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:84,usability,interact,interactive,84,"I collect errors from the Fedora/EPEL build system (a.k.a. koji), which is not very interactive. You can upload a source RPM to build and collect the results. You need to be a member of the ""packager"" group in the Fedora project to use it though, it is not open to everyone. Fedora also has a set of development machines available where, again, members of the ""packager"" group can log in and run mock (i.e. chroot) builds. However, there is currently no s390x test machine available: https://fedoraproject.org/wiki/Test_Machine_Resources_For_Package_Maintainers. [Edit: my previous comment about the lack of disk space was actually referring to the ppc64le test machine, not s390x.]. So, to answer your question, I don't have access to any system I can share. If you have proposed changes or patches I can run tests.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:122,testability,simpl,simpler,122,"Thank you for the additional information! We are setting up a big endian node here, which will make working on this issue simpler.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12426:122,usability,simpl,simpler,122,"Thank you for the additional information! We are setting up a big endian node here, which will make working on this issue simpler.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12426
https://github.com/root-project/root/issues/12427:46,energy efficiency,current,currently,46,"Thank you for the bug report! Our 32bit CI is currently not running on the experimental namespace (including RNTuple). Let us fix that first, which will make it simpler to fix this issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12427
https://github.com/root-project/root/issues/12427:161,testability,simpl,simpler,161,"Thank you for the bug report! Our 32bit CI is currently not running on the experimental namespace (including RNTuple). Let us fix that first, which will make it simpler to fix this issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12427
https://github.com/root-project/root/issues/12427:161,usability,simpl,simpler,161,"Thank you for the bug report! Our 32bit CI is currently not running on the experimental namespace (including RNTuple). Let us fix that first, which will make it simpler to fix this issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12427
https://github.com/root-project/root/pull/12435:90,deployability,fail,failing,90,"> Right, but why was it working before February 21? (that's the first day I could find it failing) Is this related to a compiler update? I'll investigate, but for now I want the nightlies green (at least on Windows) 😉",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12435
https://github.com/root-project/root/pull/12435:129,deployability,updat,update,129,"> Right, but why was it working before February 21? (that's the first day I could find it failing) Is this related to a compiler update? I'll investigate, but for now I want the nightlies green (at least on Windows) 😉",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12435
https://github.com/root-project/root/pull/12435:188,energy efficiency,green,green,188,"> Right, but why was it working before February 21? (that's the first day I could find it failing) Is this related to a compiler update? I'll investigate, but for now I want the nightlies green (at least on Windows) 😉",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12435
https://github.com/root-project/root/pull/12435:90,reliability,fail,failing,90,"> Right, but why was it working before February 21? (that's the first day I could find it failing) Is this related to a compiler update? I'll investigate, but for now I want the nightlies green (at least on Windows) 😉",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12435
https://github.com/root-project/root/pull/12435:129,safety,updat,update,129,"> Right, but why was it working before February 21? (that's the first day I could find it failing) Is this related to a compiler update? I'll investigate, but for now I want the nightlies green (at least on Windows) 😉",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12435
https://github.com/root-project/root/pull/12435:129,security,updat,update,129,"> Right, but why was it working before February 21? (that's the first day I could find it failing) Is this related to a compiler update? I'll investigate, but for now I want the nightlies green (at least on Windows) 😉",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12435
https://github.com/root-project/root/issues/12438:198,availability,operat,operator,198,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:106,deployability,stack,stack,106,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:175,energy efficiency,alloc,allocated,175,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:164,performance,memor,memory,164,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:53,safety,detect,detection,53,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:148,safety,detect,detect,148,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:53,security,detect,detection,53,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:148,security,detect,detect,148,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/issues/12438:164,usability,memor,memory,164,The problem is actually due to an instability of the detection of the `kIsOnHeap` bit where sometimes the stack has the bit pattern that is used to detect that the memory was allocated by `TObject::operator new`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12438
https://github.com/root-project/root/pull/12439:11,deployability,build,build,11,@phsft-bot build with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:55,deployability,patch,patch,55,It's curious that small files grow in size due to this patch - is that understood?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:55,safety,patch,patch,55,It's curious that small files grow in size due to this patch - is that understood?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:55,security,patch,patch,55,It's curious that small files grow in size due to this patch - is that understood?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:57,deployability,patch,patch,57,> It's curious that small files grow in size due to this patch - is that understood? Which file grew?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:57,safety,patch,patch,57,> It's curious that small files grow in size due to this patch - is that understood? Which file grew?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:57,security,patch,patch,57,> It's curious that small files grow in size due to this patch - is that understood? Which file grew?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:151,availability,servic,services,151,"Note: some of the reference files were updated with 'best guesses' and over-shot the correction. . The only case I found of increase is https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169840/testReport/projectroot.roottest.root.io/treeForeign/roottest_root_io_treeForeign_testForeignDraw/. where the actual increase is:. ```. --- a/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. +++ b/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. @@ -4,7 +4,7 @@ Warning in <TClass::Init>: no dictionary for class Wrapper is available. Warning in <TClass::Init>: no dictionary for class MyClass is available. ******************************************************************************. *Tree :T : T *. -*Entries : 2 : Total = 4215 bytes File Size = 1465 *. +*Entries : 2 : Total = 4215 bytes File Size = 1470 *. * : : Tree compression factor = 1.08 *. ******************************************************************************. ```. I am not sure whether it is worth trying to investigate (since it is small, it is the only case and it is the (older?) buitin zlib)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:555,availability,avail,available,555,"Note: some of the reference files were updated with 'best guesses' and over-shot the correction. . The only case I found of increase is https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169840/testReport/projectroot.roottest.root.io/treeForeign/roottest_root_io_treeForeign_testForeignDraw/. where the actual increase is:. ```. --- a/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. +++ b/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. @@ -4,7 +4,7 @@ Warning in <TClass::Init>: no dictionary for class Wrapper is available. Warning in <TClass::Init>: no dictionary for class MyClass is available. ******************************************************************************. *Tree :T : T *. -*Entries : 2 : Total = 4215 bytes File Size = 1465 *. +*Entries : 2 : Total = 4215 bytes File Size = 1470 *. * : : Tree compression factor = 1.08 *. ******************************************************************************. ```. I am not sure whether it is worth trying to investigate (since it is small, it is the only case and it is the (older?) buitin zlib)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:628,availability,avail,available,628,"Note: some of the reference files were updated with 'best guesses' and over-shot the correction. . The only case I found of increase is https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169840/testReport/projectroot.roottest.root.io/treeForeign/roottest_root_io_treeForeign_testForeignDraw/. where the actual increase is:. ```. --- a/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. +++ b/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. @@ -4,7 +4,7 @@ Warning in <TClass::Init>: no dictionary for class Wrapper is available. Warning in <TClass::Init>: no dictionary for class MyClass is available. ******************************************************************************. *Tree :T : T *. -*Entries : 2 : Total = 4215 bytes File Size = 1465 *. +*Entries : 2 : Total = 4215 bytes File Size = 1470 *. * : : Tree compression factor = 1.08 *. ******************************************************************************. ```. I am not sure whether it is worth trying to investigate (since it is small, it is the only case and it is the (older?) buitin zlib)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
https://github.com/root-project/root/pull/12439:39,deployability,updat,updated,39,"Note: some of the reference files were updated with 'best guesses' and over-shot the correction. . The only case I found of increase is https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/169840/testReport/projectroot.roottest.root.io/treeForeign/roottest_root_io_treeForeign_testForeignDraw/. where the actual increase is:. ```. --- a/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. +++ b/root/io/treeForeign/testForeignDrawZLIB_builtinzlib.ref. @@ -4,7 +4,7 @@ Warning in <TClass::Init>: no dictionary for class Wrapper is available. Warning in <TClass::Init>: no dictionary for class MyClass is available. ******************************************************************************. *Tree :T : T *. -*Entries : 2 : Total = 4215 bytes File Size = 1465 *. +*Entries : 2 : Total = 4215 bytes File Size = 1470 *. * : : Tree compression factor = 1.08 *. ******************************************************************************. ```. I am not sure whether it is worth trying to investigate (since it is small, it is the only case and it is the (older?) buitin zlib)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12439
