id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/355:9282,testability,Trace,Traceback,9282,"lotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:775,usability,Visual,Visualization,775,"`pip3 install scanpy` -> 'TypeError: Can't convert 'list' object to str implicitly'; This is in an Ubuntu 16..04 Docker container:. ```. docker run --rm -it ubuntu:16.04. ```. Then I ran:. ```. apt-get update && apt-get install -y \. python3-pip \. python3-setuptools. python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1264,usability,command,command,1264," python3-wheel. pip3 install scanpy. ```. I get the following output (after all of the dependencies are downloaded):. ```. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1395,usability,command,command,1395," manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1560,usability,command,command,1560,"'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1797,usability,command,command,1797,"r/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Runnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:1911,usability,command,command,1911,"st.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db310782588",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2078,usability,command,command,2078,"dist-packages/wheel/bdist_wheel.py"", line 179, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2215,usability,command,command,2215,"n run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2379,usability,command,command,2379,"5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, deco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:2534,usability,command,command,2534,"tribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""impor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3352,usability,learn,learn,3352,"ist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3473,usability,error,error,3473,"src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3501,usability,command,command,3501,"on3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Running setup.py bdist_wheel for anndata ... done. Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:3868,usability,User,UserWarning,3868,"cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367. Running setup.py bdist_wheel for networkx ... done. Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91. Successfully built anndata networkx. Failed to build scanpy. Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy. Running setup.py install for scanpy ... error. Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:. /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'. warnings.warn(msg). running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:4999,usability,simpl,simple,4999,ating build. creating build/lib. creating build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/highly_variable_genes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/magic.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/dca.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5809,usability,tool,tools,5809,cessing. copying scanpy/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5831,usability,tool,tools,5831,y/preprocessing/mnn_correct.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5864,usability,tool,tools,5864, build/lib/scanpy/preprocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5886,usability,tool,tools,5886,rocessing. copying scanpy/preprocessing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5921,usability,tool,tools,5921,sing/qc.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5943,usability,tool,tools,5943,b/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:5980,usability,tool,tools,5980,y/preprocessing/simple.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copyin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6002,usability,tool,tools,6002,.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_co,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6043,usability,tool,tools,6043,eating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. crea,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6065,usability,tool,tools,6065,y/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6101,usability,tool,tools,6101,__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_model,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6123,usability,tool,tools,6123,ib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6161,usability,tool,tools,6161,asets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6183,usability,tool,tools,6183,sets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6217,usability,tool,tools,6217,ts. creating build/lib/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py ->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6239,usability,tool,tools,6239,/scanpy/queries. copying scanpy/queries/__init__.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6286,usability,tool,tools,6286,_.py -> build/lib/scanpy/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> bu,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6308,usability,tool,tools,6308,py/queries. creating build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plottin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6341,usability,tool,tools,6341,anpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6363,usability,tool,tools,6363,py/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6397,usability,tool,tools,6397,anpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6419,usability,tool,tools,6419,py/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6456,usability,tool,tools,6456,y/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6478,usability,tool,tools,6478,api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visu,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6512,usability,tool,tools,6512,py/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6534,usability,tool,tools,6534,/api/tl.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plott,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6571,usability,tool,tools,6571,opying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6593,usability,tool,tools,6593,y -> build/lib/scanpy/api. copying scanpy/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6632,usability,tool,tools,6632,py/api/queries.py -> build/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6654,usability,tool,tools,6654,uild/lib/scanpy/api. copying scanpy/api/logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copyin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6694,usability,tool,tools,6694,logging.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/sca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6716,usability,tool,tools,6716,b/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6749,usability,tool,tools,6749,pp.py -> build/lib/scanpy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> bui,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6771,usability,tool,tools,6771,npy/api. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6813,usability,tool,tools,6813,copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. cop,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6835,usability,tool,tools,6835,pt.py -> build/lib/scanpy/tools. copying scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:6874,usability,tool,tools,6874,g scanpy/tools/phate.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/pypairs.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/rna_velocity.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/rtools. copying scanpy/rtools/__init__.py -> build/lib/scanpy/rtools. copying scanpy/rtools/mnn_correct.py -> build/lib/scanpy/rtools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/plotting. copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8182,usability,tool,tools,8182, copying scanpy/plotting/docs.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8213,usability,tool,tools,8213,y -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'M,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8264,usability,tool,tools,8264,ting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8295,usability,tool,tools,8295,canpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8342,usability,tool,tools,8342,"y -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8373,usability,tool,tools,8373," copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:8416,usability,tool,tools,8416,"ld/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. copying scanpy/plotting/qc.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/highly_variable_genes.py -> build/lib/scanpy/preprocessing/_deprecated. copying scanpy/preprocessing/_deprecated/__init__.py -> build/lib/scanpy/preprocessing/_deprecated. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/scatterplots.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <mo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9462,usability,Visual,Visualization,9462,"ing scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9794,usability,command,command,9794,"umap/utils.py -> build/lib/scanpy/neighbors/umap. running egg_info. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:9898,usability,command,command,9898,"gg-info/dependency_links.txt. writing scanpy.egg-info/PKG-INFO. writing top-level names to scanpy.egg-info/top_level.txt. writing requirements to scanpy.egg-info/requires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10064,usability,command,command,10064,"ires.txt. warning: manifest_maker: standard file '-c' not found. . reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10195,usability,command,command,10195,"ifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10360,usability,command,command,10360,"mp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10597,usability,command,command,10597,"ist.py"", line 955, in run_commands. self.run_command(cmd). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10711,usability,command,command,10711,"in run_command. cmd_obj.run(). File ""/usr/lib/python3/dist-packages/setuptools/command/install.py"", line 61, in run. return orig.install.run(self). File ""/usr/lib/python3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:10878,usability,command,command,10878,"on3.5/distutils/command/install.py"", line 583, in run. self.run_command('build'). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11015,usability,command,command,11015,"n run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11179,usability,command,command,11179,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11334,usability,command,command,11334,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11526,usability,Command,Command,11526,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:11863,usability,error,error,11863,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12046,usability,command,command,12046,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/355:12065,usability,error,error,12065,"ist.py"", line 974, in run_command. cmd_obj.run(). File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run. _build_py.run(self). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run. self.build_package_data(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data. for package, src_dir, build_dir, filenames in self.data_files:. File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__. self.data_files = self._get_data_files(). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files. return list(map(self._get_pkg_data_files, self.packages or ())). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files. for file in self.find_data_files(package, src_dir). File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files. + self.package_data.get(package, [])). TypeError: Can't convert 'list' object to str implicitly. . ----------------------------------------. Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/. You are using pip version 8.1.1, however version 18.1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355
https://github.com/scverse/scanpy/issues/356:1,availability,cluster,clustermap,1,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:47,availability,error,error,47,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:86,availability,cluster,cluster,86,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:117,availability,error,error,117,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:246,availability,cluster,clustermap,246,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:300,availability,error,error,300,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:313,availability,cluster,clustermap,313,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:614,availability,cluster,clustermap,614,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:687,availability,cluster,clustermap,687,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:757,availability,cluster,clustermap,757,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:831,availability,cluster,clustermap,831,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:995,availability,cluster,clustermap,995,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:1159,availability,mask,mask,1159,"from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4559,availability,cluster,clustermap,4559,"/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4782,availability,error,error,4782,"/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:1,deployability,cluster,clustermap,1,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:86,deployability,cluster,cluster,86,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:150,deployability,api,api,150,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:246,deployability,cluster,clustermap,246,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:313,deployability,cluster,clustermap,313,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:591,deployability,modul,module,591,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:614,deployability,cluster,clustermap,614,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:687,deployability,cluster,clustermap,687,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:757,deployability,cluster,clustermap,757,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:831,deployability,cluster,clustermap,831,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:995,deployability,cluster,clustermap,995,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4559,deployability,cluster,clustermap,4559,"/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4215,energy efficiency,core,core,4215,"ethod, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:150,integrability,api,api,150,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3371,integrability,sub,subok,3371,"). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3655,integrability,wrap,wrapper,3655,"ge. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:150,interoperability,api,api,150,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3655,interoperability,wrapper,wrapper,3655,"ge. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:591,modifiability,modul,module,591,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:965,modifiability,pac,packages,965,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:1337,modifiability,pac,packages,1337,".rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:1751,modifiability,pac,packages,1751,"s.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2139,modifiability,pac,packages,2139,"rs, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2447,modifiability,pac,packages,2447,"linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2693,modifiability,pac,packages,2693,"gram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2947,modifiability,pac,packages,2947,"d=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3178,modifiability,pac,packages,3178,"ta, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3438,modifiability,pac,packages,3438,"site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -----------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3694,modifiability,pac,packages,3694,"ges/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3987,modifiability,pac,packages,3987,"kage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4200,modifiability,pac,packages,4200," linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:47,performance,error,error,47,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:117,performance,error,error,117,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:300,performance,error,error,300,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4782,performance,error,error,4782,"/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4489,reliability,doe,doesn,4489,"/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:47,safety,error,error,47,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:117,safety,error,error,117,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:300,safety,error,error,300,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:564,safety,input,input-,564,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:591,safety,modul,module,591,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2852,safety,except,except,2852,"ge, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3866,safety,valid,validate,3866,":. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3940,safety,valid,validate,3940,"te-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4782,safety,error,error,4782,"/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2018,security,rotat,rotate,2018,", method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2224,security,rotat,rotate,2224,"er,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, met",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2361,security,rotat,rotate,2361,"in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, orde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2368,security,rotat,rotate,2368,"(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:2536,security,rotat,rotate,2536,"self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage). 1022 else:. 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in dendrogram(data, linkage, axis, label, metric, method, rotate, ax). 745 plotter = _DendrogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3866,security,validat,validate,3866,":. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3940,security,validat,validate,3940,"te-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:398,testability,Trace,Traceback,398,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:520,testability,Trace,Traceback,520,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:3253,testability,assert,assert,3253,"rogramPlotter(data, linkage=linkage, axis=axis,. 746 metric=metric, method=method,. --> 747 label=label, rotate=rotate). 748 if ax is None:. 749 ax = plt.gca(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in __init__(self, data, linkage, metric, method, axis, label, rotate). 562 . 563 if linkage is None:. --> 564 self.linkage = self.calculated_linkage. 565 else:. 566 self.linkage = linkage. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in calculated_linkage(self). 624 def calculated_linkage(self):. 625 try:. --> 626 return self._calculate_linkage_fastcluster(). 627 except ImportError:. 628 return self._calculate_linkage_scipy(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in _calculate_linkage_fastcluster(self). 618 else:. 619 linkage = fastcluster.linkage(self.array, method=self.method,. --> 620 metric=self.metric). 621 return linkage. 622 . /usr/local/lib/python3.6/site-packages/fastcluster.py in linkage(X, method, metric, preserve_input). 241 assert X.ndim==2. 242 N = len(X). --> 243 X = pdist(X, metric). 244 X = array(X, dtype=double, copy=False, order='C', subok=True). 245 Z = empty((N-1,4)). /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:47,usability,error,error,47,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:117,usability,error,error,117,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:300,usability,error,error,300,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:564,usability,input,input-,564,"`clustermap` with sparse matrix throwing value error; Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python. import scanpy.api as sc. from scipy import sparse. A = sparse.rand(100, 100, 0.1, ""csr""). # This works. sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error. sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))). ```. <details>. <summary> Traceback: </summary>. ```python. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-13-f65606c38b22> in <module>. ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 750 g = sns.clustermap(df, row_colors=row_colors, **kwds). 751 else:. --> 752 g = sns.clustermap(df, **kwds). 753 show = settings.autoshow if show is None else show. 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs). 1299 row_cluster=row_cluster, col_cluster=col_cluster,. 1300 row_linkage=row_linkage, col_linkage=col_linkage,. -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws). 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws. 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,. -> 1128 row_linkage=row_linkage, col_linkage=col_linkage). 1129 try:. 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage). 1019 self.dendrogram_row = dendrogram(. 1020 self.data2d, metric=metric, method=method, label=False, axis=0,. -> 1021 ax=self.a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/issues/356:4782,usability,error,error,4782,"/site-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs). 1932 if metric_name is not None:. 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,. -> 1934 metric_name, **kwargs). 1935 . 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs). 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]. 288 # validate data. --> 289 X = _convert_to_type(X, out_type=typ). 290 . 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type). 182 . 183 def _convert_to_type(X, out_type):. --> 184 return np.ascontiguousarray(X, dtype=out_type). 185 . 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype). 588 . 589 """""". --> 590 return array(a, dtype, copy=False, order='C', ndmin=1). 591 . 592 . ValueError: setting an array element with a sequence. ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python. import pandas as pd. adata = sc.AnnData(A) # from above. pd.DataFrame(A) # Throws error. pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe. 0 ... 99. 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356
https://github.com/scverse/scanpy/pull/357:4,availability,cluster,clustermap,4,"Fix clustermap for sparse X; Fixes #356 for me. It's a pretty simple change. It's a little hard for me to add a test at the moment, but I'm pretty sure this works.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/357
https://github.com/scverse/scanpy/pull/357:4,deployability,cluster,clustermap,4,"Fix clustermap for sparse X; Fixes #356 for me. It's a pretty simple change. It's a little hard for me to add a test at the moment, but I'm pretty sure this works.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/357
https://github.com/scverse/scanpy/pull/357:112,safety,test,test,112,"Fix clustermap for sparse X; Fixes #356 for me. It's a pretty simple change. It's a little hard for me to add a test at the moment, but I'm pretty sure this works.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/357
https://github.com/scverse/scanpy/pull/357:62,testability,simpl,simple,62,"Fix clustermap for sparse X; Fixes #356 for me. It's a pretty simple change. It's a little hard for me to add a test at the moment, but I'm pretty sure this works.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/357
https://github.com/scverse/scanpy/pull/357:112,testability,test,test,112,"Fix clustermap for sparse X; Fixes #356 for me. It's a pretty simple change. It's a little hard for me to add a test at the moment, but I'm pretty sure this works.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/357
https://github.com/scverse/scanpy/pull/357:62,usability,simpl,simple,62,"Fix clustermap for sparse X; Fixes #356 for me. It's a pretty simple change. It's a little hard for me to add a test at the moment, but I'm pretty sure this works.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/357
https://github.com/scverse/scanpy/pull/358:11,deployability,updat,update,11,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:120,energy efficiency,optim,optimized,120,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:205,energy efficiency,current,current,205,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:922,modifiability,variab,variables,922,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:120,performance,optimiz,optimized,120,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:140,performance,memor,memory,140,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:11,safety,updat,update,11,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:11,security,updat,update,11,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:964,security,control,control,964,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:998,security,control,controlled,998,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:964,testability,control,control,964,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:998,testability,control,controlled,998,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/358:140,usability,memor,memory,140,"qc_metrics update; Following on discussion from #316, I've renamed a number of arguments and metrics. Additionally I've optimized a bit for memory usage. Changes to naming can be summarized as follows:. | current | proposed |. | ------- | -------- |. |`total_features_by_{expr_values}` | `n_{var_type}_by_{expr_type}`|. |`total_{expr_values}` | `total_{expr_type}`|. |`pct_{expr_values}_in_top_{n}_features` | `pct_{expr_type}_in_top_{n}_{var_type}`|. |`total_{expr_values}_{feature_control}` | `total_{expr_type}_{qc_var}`|. |`pct_{expr_values}_{feature_control}` | `pct_{expr_type}_{qc_var}`|. | | |. |`total_{expr_values}` | `total_{expr_type}`|. |`mean_{expr_values}` | `mean_{expr_type}`|. |`n_cells_by_{expr_values}` | `n_cells_by_{expr_type}`|. |`pct_dropout_by_{expr_values}` | `pct_dropout_by_{expr_type}`|. I went with `qc_vars` over `control_vars` on the recommendation of a lab mate, since they are presumably variables which are important for quality control, but were not necessarily controlled.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/358
https://github.com/scverse/scanpy/pull/360:0,testability,simpl,simplify,0,simplify travis;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360
https://github.com/scverse/scanpy/pull/360:0,usability,simpl,simplify,0,simplify travis;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/360
https://github.com/scverse/scanpy/pull/361:130,deployability,api,api,130,bbknn and leiden functions; - created `bbknn.py` and `leiden.py`. - added Park18 and Traag18 references. - added bbknn import to `api/pp.py` and leiden import to `api/tl.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361
https://github.com/scverse/scanpy/pull/361:163,deployability,api,api,163,bbknn and leiden functions; - created `bbknn.py` and `leiden.py`. - added Park18 and Traag18 references. - added bbknn import to `api/pp.py` and leiden import to `api/tl.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361
https://github.com/scverse/scanpy/pull/361:130,integrability,api,api,130,bbknn and leiden functions; - created `bbknn.py` and `leiden.py`. - added Park18 and Traag18 references. - added bbknn import to `api/pp.py` and leiden import to `api/tl.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361
https://github.com/scverse/scanpy/pull/361:163,integrability,api,api,163,bbknn and leiden functions; - created `bbknn.py` and `leiden.py`. - added Park18 and Traag18 references. - added bbknn import to `api/pp.py` and leiden import to `api/tl.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361
https://github.com/scverse/scanpy/pull/361:130,interoperability,api,api,130,bbknn and leiden functions; - created `bbknn.py` and `leiden.py`. - added Park18 and Traag18 references. - added bbknn import to `api/pp.py` and leiden import to `api/tl.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361
https://github.com/scverse/scanpy/pull/361:163,interoperability,api,api,163,bbknn and leiden functions; - created `bbknn.py` and `leiden.py`. - added Park18 and Traag18 references. - added bbknn import to `api/pp.py` and leiden import to `api/tl.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361
https://github.com/scverse/scanpy/issues/362:165,availability,cluster,clusters,165,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:212,availability,cluster,clusters,212,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:298,availability,cluster,cluster,298,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:165,deployability,cluster,clusters,165,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:212,deployability,cluster,clusters,212,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:298,deployability,cluster,cluster,298,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:441,deployability,contain,contains,441,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:115,energy efficiency,heat,heatmap,115,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:137,energy efficiency,heat,heatmap,137,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:0,usability,Visual,Visualizing,0,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/362:77,usability,visual,visualize,77,"Visualizing Standalone Dendrogram and Merging Similar Nodes; I would like to visualize a dendrogram from scanpy.pl.heatmap() without the heatmap, grouped by louvain clusters. It would be nice to have the louvain clusters as the x-axis and the y-axis representative of OOBE or some other metric for cluster scores (similar to Seurat). . Is there some obvious method for doing this that I have not seen? I realize that adata.uns['dendrogram'] contains dendrogram information; however, I am unsure of how to use the information to generate a dendrogram within scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362
https://github.com/scverse/scanpy/issues/363:538,availability,sli,sliced,538,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:31,deployability,updat,updating,31,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:331,deployability,modul,module,331,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:0,integrability,sub,subsetting,0,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:48,integrability,sub,subsetting,48,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:331,modifiability,modul,module,331,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:430,modifiability,pac,packages,430,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:687,modifiability,pac,packages,687,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:999,modifiability,pac,packages,999,"setting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axis 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:1072,modifiability,layer,layers,1072,"'ve this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axis 1 with size 7. ```. even though it's part of the set:. ```py. >>> set(tis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:1346,modifiability,pac,packages,1346,"--> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axis 1 with size 7. ```. even though it's part of the set:. ```py. >>> set(tiss.obs['cell_ontology_class']). {'B cell',. 'NA',. 'T cell',. 'dendritic cell',. 'macrophage',. 'natural killer cell'}. ```. it does work for louvain though:. ```python. >>> tiss[tiss.obs['louvain']=='0']`. ```. View of AnnData object with n_obs × n_vars = 5862 × 19860`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:1677,modifiability,pac,packages,1677,"--> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axis 1 with size 7. ```. even though it's part of the set:. ```py. >>> set(tiss.obs['cell_ontology_class']). {'B cell',. 'NA',. 'T cell',. 'dendritic cell',. 'macrophage',. 'natural killer cell'}. ```. it does work for louvain though:. ```python. >>> tiss[tiss.obs['louvain']=='0']`. ```. View of AnnData object with n_obs × n_vars = 5862 × 19860`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:59,reliability,doe,doesn,59,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:538,reliability,sli,sliced,538,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:2202,reliability,doe,does,2202,"--> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axis 1 with size 7. ```. even though it's part of the set:. ```py. >>> set(tiss.obs['cell_ontology_class']). {'B cell',. 'NA',. 'T cell',. 'dendritic cell',. 'macrophage',. 'natural killer cell'}. ```. it does work for louvain though:. ```python. >>> tiss[tiss.obs['louvain']=='0']`. ```. View of AnnData object with n_obs × n_vars = 5862 × 19860`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:31,safety,updat,updating,31,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:303,safety,input,input-,303,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:331,safety,modul,module,331,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:31,security,updat,updating,31,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:259,testability,Trace,Traceback,259,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/issues/363:303,usability,input,input-,303,"subsetting isn't working after updating scanpy; subsetting doesn't work:. I've this object. ```python. >>> tiss. ```. AnnData object with n_obs × n_vars = 29322 × 19860. ```python. >>> tiss[tiss.obs['cell_ontology_class']=='B cell']. ```. ```pytb. IndexError Traceback (most recent call last). <ipython-input-269-28b4524131cb> in <module>(). ----> 1 tiss[tiss.obs['cell_ontology_class']=='B cell']. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index). 1299 def __getitem__(self, index):. 1300 """"""Returns a sliced view of the object."""""". -> 1301 return self._getitem_view(index). 1302 . 1303 def _getitem_view(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index). 1303 def _getitem_view(self, index):. 1304 oidx, vidx = self._normalize_indices(index). -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1306 . 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx). 713 raise KeyError('Unknown Index type'). 714 # fix categories. --> 715 self._remove_unused_categories(adata_ref.obs, obs_sub, uns_new). 716 self._remove_unused_categories(adata_ref.var, var_sub, uns_new). 717 # set attributes. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _remove_unused_categories(self, df_full, df_sub, uns). 1318 uns[k + '_colors'] = np.array(uns[k + '_colors'])[. 1319 np.where(np.in1d(. -> 1320 all_categories, df_sub[k].cat.categories))[0]]. 1321 . 1322 def rename_categories(self, key, categories):. IndexError: index 7 is out of bounds for axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363
https://github.com/scverse/scanpy/pull/364:6,energy efficiency,Current,Currently,6,"kBET; Currently it’s almost a MVP. What do you people think (especially @mbuttner)? Possible improvements:. - [x] **Heuristic for neighborhood size**. - [x] Expose more data: E.g. a column in `.obs` with the corrected p values. - [ ] **Better docs**. - [ ] **groupby**. - [ ] Mean of multiple samples instead of whole data. - [ ] Adapt to cells that appear in no neighborhoods. - [ ] Speedups? I guess at least the heuristic and the docs have to go in! I also don’t know if relying on the previous `neighbors` call is a good idea. Its default is 15 Neighbors, and even for a small (200 cells) dataset, the number the heuristic determined was 75.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364
https://github.com/scverse/scanpy/pull/364:330,energy efficiency,Adapt,Adapt,330,"kBET; Currently it’s almost a MVP. What do you people think (especially @mbuttner)? Possible improvements:. - [x] **Heuristic for neighborhood size**. - [x] Expose more data: E.g. a column in `.obs` with the corrected p values. - [ ] **Better docs**. - [ ] **groupby**. - [ ] Mean of multiple samples instead of whole data. - [ ] Adapt to cells that appear in no neighborhoods. - [ ] Speedups? I guess at least the heuristic and the docs have to go in! I also don’t know if relying on the previous `neighbors` call is a good idea. Its default is 15 Neighbors, and even for a small (200 cells) dataset, the number the heuristic determined was 75.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364
https://github.com/scverse/scanpy/pull/364:330,integrability,Adapt,Adapt,330,"kBET; Currently it’s almost a MVP. What do you people think (especially @mbuttner)? Possible improvements:. - [x] **Heuristic for neighborhood size**. - [x] Expose more data: E.g. a column in `.obs` with the corrected p values. - [ ] **Better docs**. - [ ] **groupby**. - [ ] Mean of multiple samples instead of whole data. - [ ] Adapt to cells that appear in no neighborhoods. - [ ] Speedups? I guess at least the heuristic and the docs have to go in! I also don’t know if relying on the previous `neighbors` call is a good idea. Its default is 15 Neighbors, and even for a small (200 cells) dataset, the number the heuristic determined was 75.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364
https://github.com/scverse/scanpy/pull/364:330,interoperability,Adapt,Adapt,330,"kBET; Currently it’s almost a MVP. What do you people think (especially @mbuttner)? Possible improvements:. - [x] **Heuristic for neighborhood size**. - [x] Expose more data: E.g. a column in `.obs` with the corrected p values. - [ ] **Better docs**. - [ ] **groupby**. - [ ] Mean of multiple samples instead of whole data. - [ ] Adapt to cells that appear in no neighborhoods. - [ ] Speedups? I guess at least the heuristic and the docs have to go in! I also don’t know if relying on the previous `neighbors` call is a good idea. Its default is 15 Neighbors, and even for a small (200 cells) dataset, the number the heuristic determined was 75.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364
https://github.com/scverse/scanpy/pull/364:330,modifiability,Adapt,Adapt,330,"kBET; Currently it’s almost a MVP. What do you people think (especially @mbuttner)? Possible improvements:. - [x] **Heuristic for neighborhood size**. - [x] Expose more data: E.g. a column in `.obs` with the corrected p values. - [ ] **Better docs**. - [ ] **groupby**. - [ ] Mean of multiple samples instead of whole data. - [ ] Adapt to cells that appear in no neighborhoods. - [ ] Speedups? I guess at least the heuristic and the docs have to go in! I also don’t know if relying on the previous `neighbors` call is a good idea. Its default is 15 Neighbors, and even for a small (200 cells) dataset, the number the heuristic determined was 75.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364
https://github.com/scverse/scanpy/pull/364:157,security,Expos,Expose,157,"kBET; Currently it’s almost a MVP. What do you people think (especially @mbuttner)? Possible improvements:. - [x] **Heuristic for neighborhood size**. - [x] Expose more data: E.g. a column in `.obs` with the corrected p values. - [ ] **Better docs**. - [ ] **groupby**. - [ ] Mean of multiple samples instead of whole data. - [ ] Adapt to cells that appear in no neighborhoods. - [ ] Speedups? I guess at least the heuristic and the docs have to go in! I also don’t know if relying on the previous `neighbors` call is a good idea. Its default is 15 Neighbors, and even for a small (200 cells) dataset, the number the heuristic determined was 75.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/364
https://github.com/scverse/scanpy/issues/365:0,availability,Error,Error,0,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:353,availability,error,error,353,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:1196,availability,error,error,1196,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:840,energy efficiency,core,core,840,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:895,interoperability,format,formats,895,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:395,modifiability,pac,packages,395,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:825,modifiability,pac,packages,825,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:0,performance,Error,Error,0,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:67,performance,time,time,67,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:353,performance,error,error,353,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:1196,performance,error,error,1196,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:0,safety,Error,Error,0,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:353,safety,error,error,353,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:751,safety,test,test,751,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:1196,safety,error,error,1196,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:751,testability,test,test,751,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:0,usability,Error,Error,0,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:353,usability,error,error,353,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:411,usability,tool,tools,411,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/365:1196,usability,error,error,1196,"Error using rank_genes_groups; Hi,. I have been Scanpy for a short time and I find it really great! However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types. When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```. ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 374 adata.uns[key_added]['names'] = np.rec.fromarrays(. 375 [n for n in rankings_gene_names],. --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]). 377. 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 632 # populate the record array (makes a copy). 633 for i in range(len(arrayList)):. --> 634 _array[_names[i]] = arrayList[i]. 635. 636 return _array. ValueError: setting an array element with a sequence. ```. Do you have any idea of what could cause this error? Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365
https://github.com/scverse/scanpy/issues/366:100,deployability,automat,automated,100,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:110,deployability,version,version,110,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:157,deployability,pipelin,pipeline,157,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:18,energy efficiency,load,loading,18,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:256,energy efficiency,load,load,256,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:110,integrability,version,version,110,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:157,integrability,pipelin,pipeline,157,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:110,modifiability,version,version,110,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:18,performance,load,loading,18,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:256,performance,load,load,256,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/366:100,testability,automat,automated,100,Nadia single cell loading in scanpy; Hi . We have purchased the Nadia dolomite machine which is the automated version of dropseq. I am using the dropseqpipe pipeline for demultiplexing and generate count matrix. Analysis with Seurat is fine but how do you load a count matrix in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/366
https://github.com/scverse/scanpy/issues/367:509,availability,mask,mask,509,"sc.tl.paga_expression_entropies(adata); I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes! ```. from scipy.stats import entropy. groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']). entropies = []. for mask in groups_masks:. X_mask = tiss.X[mask].todense(). x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True). x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)). entropies.append(entropy(x_probs)). entropies. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367
https://github.com/scverse/scanpy/issues/367:548,availability,mask,mask,548,"sc.tl.paga_expression_entropies(adata); I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes! ```. from scipy.stats import entropy. groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']). entropies = []. for mask in groups_masks:. X_mask = tiss.X[mask].todense(). x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True). x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)). entropies.append(entropy(x_probs)). entropies. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367
https://github.com/scverse/scanpy/issues/367:266,deployability,updat,update,266,"sc.tl.paga_expression_entropies(adata); I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes! ```. from scipy.stats import entropy. groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']). entropies = []. for mask in groups_masks:. X_mask = tiss.X[mask].todense(). x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True). x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)). entropies.append(entropy(x_probs)). entropies. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367
https://github.com/scverse/scanpy/issues/367:304,reliability,doe,doesn,304,"sc.tl.paga_expression_entropies(adata); I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes! ```. from scipy.stats import entropy. groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']). entropies = []. for mask in groups_masks:. X_mask = tiss.X[mask].todense(). x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True). x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)). entropies.append(entropy(x_probs)). entropies. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367
https://github.com/scverse/scanpy/issues/367:266,safety,updat,update,266,"sc.tl.paga_expression_entropies(adata); I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes! ```. from scipy.stats import entropy. groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']). entropies = []. for mask in groups_masks:. X_mask = tiss.X[mask].todense(). x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True). x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)). entropies.append(entropy(x_probs)). entropies. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367
https://github.com/scverse/scanpy/issues/367:186,security,modif,modified,186,"sc.tl.paga_expression_entropies(adata); I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes! ```. from scipy.stats import entropy. groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']). entropies = []. for mask in groups_masks:. X_mask = tiss.X[mask].todense(). x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True). x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)). entropies.append(entropy(x_probs)). entropies. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367
https://github.com/scverse/scanpy/issues/367:266,security,updat,update,266,"sc.tl.paga_expression_entropies(adata); I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes! ```. from scipy.stats import entropy. groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']). entropies = []. for mask in groups_masks:. X_mask = tiss.X[mask].todense(). x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True). x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)). entropies.append(entropy(x_probs)). entropies. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367
https://github.com/scverse/scanpy/issues/368:10,integrability,sub,subfigures,10,"legend of subfigures overlapping; I've got some problems with overlapping legends:. ```python3. sc.pl.umap(adata_pp, color=[""treatment"", ""mixture_assignment""]). ```. ![grafik](https://user-images.githubusercontent.com/1200058/48719273-60f9f200-ec1d-11e8-8cab-08434ad02411.png). Is there something I can do about this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/368
https://github.com/scverse/scanpy/issues/368:184,usability,user,user-images,184,"legend of subfigures overlapping; I've got some problems with overlapping legends:. ```python3. sc.pl.umap(adata_pp, color=[""treatment"", ""mixture_assignment""]). ```. ![grafik](https://user-images.githubusercontent.com/1200058/48719273-60f9f200-ec1d-11e8-8cab-08434ad02411.png). Is there something I can do about this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/368
https://github.com/scverse/scanpy/pull/369:166,deployability,contain,contains,166,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:196,deployability,contain,contains,196,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1079,deployability,contain,contain,1079,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1567,deployability,contain,contains,1567,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:122,energy efficiency,heat,heatmap,122,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:254,energy efficiency,heat,heatmap,254,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:292,energy efficiency,heat,heatmaps,292,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:378,energy efficiency,heat,heatmap,378,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:423,energy efficiency,heat,heatmap,423,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:781,energy efficiency,reduc,reduced,781,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1213,energy efficiency,heat,heatmap,1213,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:555,interoperability,specif,specify,555,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:538,modifiability,layer,layer,538,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:569,modifiability,layer,layer,569,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:667,modifiability,variab,variable,667,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:694,modifiability,variab,variable,694,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:770,safety,test,testing,770,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:796,safety,test,test,796,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:770,testability,test,testing,770,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:796,testability,test,test,796,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:612,usability,visual,visualization,612,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1092,usability,visual,visual,1092,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1288,usability,user,user-images,1288,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1438,usability,user,user-images,1438,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1670,usability,user,user-images,1670,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/pull/369:1845,usability,user,user-images,1845,"Figure improvements; This PR introduces the following changes:. * `swap_axes` option was added to `pl.matrixplot` and `pl.heatmap`. When `swap_axes=True`, the x axis contains cells and the y axis contains genes (#349). * added `show_genes_labels` to `pl.heatmap`. This allows to have compact heatmaps without overlapping gene labels. * added lines to separate categories in `pl.heatmap`. * changed categories colors in `pl.heatmap` by the colors found in `adata.uns`. * removed empty space that was present in different plots. * added a `layer` option to specify which layer to use for plotting. . * added a new visualization called `pl.tracksplot`. . * changed `if <variable> is True` by `if <variable>` after @flying-sheep remarks. . * added `setup()` from matplotlib.testing. * reduced dpi of test images to 40. * added var_groups plot for stacked_violin when `swap_axes=True` . * improved layout of stacked_violin (default width and linewidth of violin plots). As an example, here is how some of the changes look like. I am using the `rank_genes_groups_*` plots because they contain more visual elements. Further examples can be seen here: https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c. **heatmap** with `swap_axes=True, show_gene_labels=False`:. ![image](https://user-images.githubusercontent.com/4964309/48777204-46358500-ecd2-11e8-8ced-e772e0987f95.png). **matrixplot** with `swap_axes=True`:. ![image](https://user-images.githubusercontent.com/4964309/48777447-dffd3200-ecd2-11e8-9720-31e084eec0f4.png). **new *tracksplot***: Each *track* contains the var (genes) values sorted and colored according to the categories used:. ![image](https://user-images.githubusercontent.com/4964309/48777284-7c730480-ecd2-11e8-8e3b-ab4a02969311.png). **tracksplot** using the results of `sc.tl.rank_genes_groups`:. ![image](https://user-images.githubusercontent.com/4964309/48777641-6fa2e080-ecd3-11e8-90be-e3742058eb99.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/369
https://github.com/scverse/scanpy/issues/373:1100,deployability,automat,automatically,1100,"’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1421,deployability,automat,automatically,1421," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1727,deployability,stage,stage,1727," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1750,deployability,continu,continue,1750," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:2241,integrability,coupl,couple,2241," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:860,modifiability,pac,packages,860,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1788,modifiability,pac,packages,1788," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:2241,modifiability,coupl,couple,2241," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:889,performance,time,time,889,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:2120,performance,time,time,2120," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:790,reliability,doe,doesn,790,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:438,safety,compl,complicated,438,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1484,safety,compl,complicated,1484," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:438,security,compl,complicated,438,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1484,security,compl,complicated,1484," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:420,testability,simpl,simply,420,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:894,testability,simpl,simply,894,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1100,testability,automat,automatically,1100,"’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1421,testability,automat,automatically,1421," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1743,testability,simpl,simply,1743," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:2241,testability,coupl,couple,2241," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:130,usability,document,documentation,130,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:420,usability,simpl,simply,420,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:555,usability,help,help,555,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:824,usability,user,user,824,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:894,usability,simpl,simply,894,"Type annotation considerations; @falexwolf wrote:. > > Wow, this looks great! One remark for future PRs: We’re migrating to a new documentation style using type annotations. > . > I'm still not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1180,usability,user,user-images,1180,"ill not convinced that we should use type annotations for Scanpy toplevel functions. People use Scanpy in Jupyter Lab and notebooks and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one mark",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1311,usability,user,user-images,1311," and not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1408,usability,Clear,Clearly,1408," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/373:1743,usability,simpl,simply,1743," not in Pycharm. Hence, there is no gain in the annotations, by contrast, the function annotations simply look super complicated and it's no longer feasible to grasp at first sight what's going on. This also regards the output of the help in Jupyter Lab and Notebooks. > . > So, while I think that for AnnData and everything in the background, type annotations may make sense for a few developers (not for me, as I'm doing everything on remote servers using emacs), it doesn't make sense for the Scanpy user. > . > Also, all the other big packages I work with all the time simply don't have it (numpy, seaborn, pandas, tensorflow) and it makes it harder and lengthier for contributors to contribute if they need to go through it. > . > Finally, I'm still not happy about how the automatically generated docs from the type annotation look:. > ![image](https://user-images.githubusercontent.com/16916678/48796750-6ebb8000-ecce-11e8-9cdc-33b6056d8957.png). > which is from. > ![image](https://user-images.githubusercontent.com/16916678/48796824-a0344b80-ecce-11e8-8570-e4754f4ccd96.png). > Clearly, the automatically generated line with `Union[...]` is just way too complicated for a human to make sense of. The mix of auto-generated types in the docs and the manual annotations also looks inhomogeneous. > . > So, please let's stay away from having more type annotations and corresponding docstrings at this stage and let's simply continue imitating what all the major packages are doing. > . > Also: regarding your comment about the use of '``' vs. '`' in the docs: again, I think it leads to an inhomogeneous appearance to have *two* types of markup for code-related things. I agree that the read-the-docs italicized default style for '`' might be supoptimal, and I'll work on that if there is some time. But in general, I think there should be essentially one markup for code, as it's done in the tensorflow docs and a couple of other examples. > . > Happy to also discuss offline, @flying-sheep ;).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373
https://github.com/scverse/scanpy/issues/374:149,deployability,api,api,149,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/374:307,deployability,contain,contained,307,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/374:149,integrability,api,api,149,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/374:149,interoperability,api,api,149,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/374:338,interoperability,specif,specifying,338,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/374:74,usability,minim,minimal,74,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/374:465,usability,user,user-images,465,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/374:837,usability,user,user-images,837,"umap legends overlap with axis when decreasing legend fontsize; Here is a minimal example to recreate the issue I am describing:. ```. import scanpy.api as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.umap(adata). ```. when you plot the umap of the bulk labels contained in adata.obs without specifying any further settings (i.e. `sc.pl.umap(adata, color = ['bulk_labels'])` ) everything looks fine. . ![image](https://user-images.githubusercontent.com/15019107/48847064-efe34780-eda0-11e8-8d51-b503d7912d1e.png). But as soon as you try and adjust the legend font size (`sc.pl.umap(adata, color = ['bulk_labels'], legend_fontsize = 4)`) to a value that is smaller than the default font size it selects for your legend, the legend overlaps with the right edge of the plot. . ![image](https://user-images.githubusercontent.com/15019107/48847096-04274480-eda1-11e8-9bac-dceb31aba155.png). For me this sometimes leads to issues that I can no longer export figures with my desired fontsize for presentations, etc. without it overlapping the plot in an ugly way.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/374
https://github.com/scverse/scanpy/issues/375:189,availability,error,error,189,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:478,availability,error,error,478,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:1134,availability,sli,sliced,1134,"umns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observatio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:1801,availability,sli,slice,1801,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:649,deployability,modul,module,649,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:789,deployability,log,log,789,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:828,deployability,scale,scale,828,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2127,deployability,observ,observation,2127,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2265,deployability,observ,observation,2265,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:828,energy efficiency,scale,scale,828,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:195,integrability,messag,message,195,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:195,interoperability,messag,message,195,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2171,interoperability,format,format,2171,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:649,modifiability,modul,module,649,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:828,modifiability,scal,scale,828,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2139,modifiability,variab,variable,2139,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2277,modifiability,variab,variable,2277,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:189,performance,error,error,189,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:478,performance,error,error,478,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:828,performance,scale,scale,828,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:1134,reliability,sli,sliced,1134,"umns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observatio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:1801,reliability,sli,slice,1801,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:189,safety,error,error,189,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:478,safety,error,error,478,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:623,safety,input,input-,623,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:649,safety,modul,module,649,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:789,safety,log,log,789,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2121,safety,valid,valid,2121,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2259,safety,valid,valid,2259,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:789,security,log,log,789,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:869,security,rotat,rotation,869,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:579,testability,Trace,Traceback,579,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:789,testability,log,log,789,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2127,testability,observ,observation,2127,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2265,testability,observ,observation,2265,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:8,usability,document,documentation,8,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:189,usability,error,error,189,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:478,usability,error,error,478,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:623,usability,input,input-,623,"Improve documentation for violin plot to illustrate per-gene usage – violin(adata.T, 'gene_property'); Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:. ```. adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0). adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'). ```. and I get this error:. ```. ---------------------------------------------------------------------------. IndexError Traceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implement",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:1814,usability,stop,stop,1814,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/issues/375:2456,usability,clear,clearly,2456,"raceback (most recent call last). <ipython-input-8-463060c90a0b> in <module>(). ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds). 630 X_col = adata.raw[:, key].X. 631 else:. --> 632 X_col = adata[:, key].X. 633 obs_df[key] = X_col. 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index). 1303 def __getitem__(self, index):. 1304 """"""Returns a sliced view of the object."""""". -> 1305 return self._getitem_view(index). 1306 . 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index). 1306 . 1307 def _getitem_view(self, index):. -> 1308 oidx, vidx = self._normalize_indices(index). 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index). 1283 obs, var = super(AnnData, self)._unpack_index(index). 1284 obs = _normalize_index(obs, self.obs_names). -> 1285 var = _normalize_index(var, self.var_names). 1286 return obs, var. 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names). 261 return slice(start, stop, step). 262 elif isinstance(index, (int, str)):. --> 263 return name_idx(index). 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):. 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i). 248 raise IndexError(. 249 'Key ""{}"" is not valid observation/variable name/index.'. --> 250 .format(i)). 251 i = i_found[0]. 252 return i. IndexError: Key ""dropout_per_gene"" is not valid observation/variable name/index. ```. The whole thing works for:. ```. sc.pl.violin(adata_counts.T, keys='dropout_per_gene'). sc.pl.violin(adata_counts, keys='dropout_per_cell). ```. So it's clearly just not taking `.var` columns for `sc.pl.violing()`. . I've also reproduced this with `adata = sc.datasets.blob()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375
https://github.com/scverse/scanpy/pull/376:103,interoperability,specif,specify,103,Add 'annot_col' parameter to highest_expr_genes plotting function; The `annot_col` parameter allows to specify a column that will be shown on the y axis of the `highest_expr_genes` plot instead of `var_names`. . This is useful when working with ENSG identifiers as `var_names` and you have stored gene names in a separate column.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376
https://github.com/scverse/scanpy/pull/376:16,modifiability,paramet,parameter,16,Add 'annot_col' parameter to highest_expr_genes plotting function; The `annot_col` parameter allows to specify a column that will be shown on the y axis of the `highest_expr_genes` plot instead of `var_names`. . This is useful when working with ENSG identifiers as `var_names` and you have stored gene names in a separate column.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376
https://github.com/scverse/scanpy/pull/376:83,modifiability,paramet,parameter,83,Add 'annot_col' parameter to highest_expr_genes plotting function; The `annot_col` parameter allows to specify a column that will be shown on the y axis of the `highest_expr_genes` plot instead of `var_names`. . This is useful when working with ENSG identifiers as `var_names` and you have stored gene names in a separate column.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376
https://github.com/scverse/scanpy/pull/376:250,security,ident,identifiers,250,Add 'annot_col' parameter to highest_expr_genes plotting function; The `annot_col` parameter allows to specify a column that will be shown on the y axis of the `highest_expr_genes` plot instead of `var_names`. . This is useful when working with ENSG identifiers as `var_names` and you have stored gene names in a separate column.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376
https://github.com/scverse/scanpy/issues/377:9,deployability,scale,scale,9,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:102,deployability,scale,scale,102,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:9,energy efficiency,scale,scale,9,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:102,energy efficiency,scale,scale,102,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:9,modifiability,scal,scale,9,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:102,modifiability,scal,scale,102,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:9,performance,scale,scale,9,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:102,performance,scale,scale,102,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:71,usability,custom,customise,71,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/377:242,usability,help,help,242,"Changing scale for plotting functions; Hello there,. Is it possible to customise the expression range scale when using for example ```pl.umap```? I thought I could try ```use_raw=True```, but got the same issue as in #370. Thank you for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377
https://github.com/scverse/scanpy/issues/378:583,availability,cluster,clustering,583,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:629,availability,cluster,clusters,629,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:663,availability,cluster,cluster,663,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:725,availability,cluster,clustering,725,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:771,availability,cluster,clusters,771,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:805,availability,cluster,cluster,805,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:867,availability,cluster,clustering,867,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:913,availability,cluster,clusters,913,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:947,availability,cluster,cluster,947,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1009,availability,cluster,clustering,1009,"re on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1055,availability,cluster,clusters,1055,"m using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1089,availability,cluster,cluster,1089," In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1151,availability,cluster,clustering,1151,"cuting the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1198,availability,cluster,clusters,1198,"lso using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1232,availability,cluster,cluster,1232,"from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1293,availability,cluster,clustering,1293,"05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1340,availability,cluster,clusters,1340,"ray = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1374,availability,cluster,cluster,1374,"ray]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1435,availability,cluster,clustering,1435,"n=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1482,availability,cluster,clusters,1482,"ighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1516,availability,cluster,cluster,1516," adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1578,availability,cluster,clustering,1578,"clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1625,availability,cluster,clusters,1625,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1659,availability,cluster,cluster,1659,"cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1720,availability,cluster,clustering,1720,"clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1767,availability,cluster,clusters,1767,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1801,availability,cluster,cluster,1801,"cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1862,availability,cluster,clustering,1862,"clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1909,availability,cluster,clusters,1909,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1943,availability,cluster,cluster,1943,"cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2004,availability,cluster,clustering,2004,"clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2051,availability,cluster,clusters,2051,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette scor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2085,availability,cluster,cluster,2085,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2146,availability,cluster,clustering,2146,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2193,availability,cluster,clusters,2193,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2227,availability,cluster,cluster,2227,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2288,availability,cluster,clustering,2288,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2335,availability,cluster,clusters,2335,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2369,availability,cluster,cluster,2369,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2430,availability,cluster,clustering,2430,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2477,availability,cluster,clusters,2477,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2511,availability,cluster,cluster,2511,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2572,availability,cluster,clustering,2572,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2619,availability,cluster,clusters,2619,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2653,availability,cluster,cluster,2653,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2714,availability,cluster,clustering,2714,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2761,availability,cluster,clusters,2761,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2795,availability,cluster,cluster,2795,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2856,availability,cluster,clustering,2856,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2903,availability,cluster,clusters,2903,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2937,availability,cluster,cluster,2937,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:3025,availability,cluster,clustering,3025,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:583,deployability,cluster,clustering,583,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:629,deployability,cluster,clusters,629,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:663,deployability,cluster,cluster,663,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:725,deployability,cluster,clustering,725,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:771,deployability,cluster,clusters,771,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:805,deployability,cluster,cluster,805,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:867,deployability,cluster,clustering,867,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:913,deployability,cluster,clusters,913,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:947,deployability,cluster,cluster,947,"Silhouette score on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1009,deployability,cluster,clustering,1009,"re on leiden/louvain returning -1 or NaN; I am using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1055,deployability,cluster,clusters,1055,"m using a similar code as in #222. In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1089,deployability,cluster,cluster,1089," In particular I want to compute the silhouette score after executing the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1151,deployability,cluster,clustering,1151,"cuting the leiden algorithm (similar results also using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1198,deployability,cluster,clusters,1198,"lso using louvain):. ```python. > from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1232,deployability,cluster,cluster,1232,"from sklearn.metrics import silhouette_score. > res_array = [.05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1293,deployability,cluster,clustering,1293,"05] + list(np.linspace(.1, 1.6, 16)). > res_array = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1340,deployability,cluster,clusters,1340,"ray = [round(r, 2) for r in res_array]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1374,deployability,cluster,cluster,1374,"ray]. > for res in res_array:. > sc.tl.leiden(adata, resolution=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1435,deployability,cluster,clustering,1435,"n=res). > print(silhouette_score(adata.uns['neighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1482,deployability,cluster,clusters,1482,"ighbors']['distances'].todense(),. adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1516,deployability,cluster,cluster,1516," adata.obs[f'leiden'],. metric='precomputed')). running Leiden clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1578,deployability,cluster,clustering,1578,"clustering. finished (0:00:00.59) --> found 6 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1625,deployability,cluster,clusters,1625,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1659,deployability,cluster,cluster,1659,"cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1720,deployability,cluster,clustering,1720,"clustering. finished (0:00:00.57) --> found 7 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1767,deployability,cluster,clusters,1767,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1801,deployability,cluster,cluster,1801,"cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1862,deployability,cluster,clustering,1862,"clustering. finished (0:00:00.38) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1909,deployability,cluster,clusters,1909,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:1943,deployability,cluster,cluster,1943,"cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2004,deployability,cluster,clustering,2004,"clustering. finished (0:00:00.48) --> found 8 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2051,deployability,cluster,clusters,2051,"clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette scor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2085,deployability,cluster,cluster,2085,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2146,deployability,cluster,clustering,2146,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2193,deployability,cluster,clusters,2193,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2227,deployability,cluster,cluster,2227,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2288,deployability,cluster,clustering,2288,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2335,deployability,cluster,clusters,2335,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2369,deployability,cluster,cluster,2369,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2430,deployability,cluster,clustering,2430,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2477,deployability,cluster,clusters,2477,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2511,deployability,cluster,cluster,2511,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2572,deployability,cluster,clustering,2572,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2619,deployability,cluster,clusters,2619,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2653,deployability,cluster,cluster,2653,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2714,deployability,cluster,clustering,2714,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2761,deployability,cluster,clusters,2761,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2795,deployability,cluster,cluster,2795,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2856,deployability,cluster,clustering,2856,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2903,deployability,cluster,clusters,2903,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:2937,deployability,cluster,cluster,2937,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/378:3025,deployability,cluster,clustering,3025,"usters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.95) --> found 12 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.67) --> found 14 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.97) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). -1.0. running Leiden clustering. finished (0:00:00.67) --> found 16 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 18 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.05) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.77) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.89) --> found 19 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:00.85) --> found 21 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.46) --> found 22 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. running Leiden clustering. finished (0:00:01.28) --> found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical). nan. ```. Is this expected with Leiden/Louvain clustering and Silhouette score?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/378
https://github.com/scverse/scanpy/issues/381:17,availability,error,error,17,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:97,availability,cluster,clusters,97,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:168,availability,cluster,cluster,168,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:191,availability,error,error,191,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:97,deployability,cluster,clusters,97,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:168,deployability,cluster,cluster,168,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:674,deployability,modul,module,674,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2187,deployability,stack,stacklevel,2187,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2671,deployability,fail,failed,2671,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2572,interoperability,format,format,2572,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2660,interoperability,convers,conversion,2660,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:288,modifiability,pac,packages,288,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:674,modifiability,modul,module,674,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:771,modifiability,pac,packages,771,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:1396,modifiability,pac,packages,1396,", verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2035,modifiability,pac,packages,2035,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2338,modifiability,pac,packages,2338,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2854,modifiability,paramet,parameter,2854,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:17,performance,error,error,17,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:191,performance,error,error,191,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:2671,reliability,fail,failed,2671,"ze_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4232 ""acceptable for use with 'x' with size {xs}, "". 4233 ""'y' with size {ys}."". -> 4234 .format(nc=n_elem, xs=x.size, ys=y.size). 4235 ). 4236 # Both the mapping *and* the RGBA conversion failed: pretty. ValueError: 'c' argument has 14 elements, which is not acceptable for use with 'x' with size 4, 'y' with size 4. It seems that there are something wrong with the cmap parameter of matplotlib's plt.scatter() function. please refer to this issue:. https://github.com/matplotlib/matplotlib/issues/11919",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:17,safety,error,error,17,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:191,safety,error,error,191,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:489,safety,except,except,489,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:552,safety,except,exception,552,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:571,safety,except,exception,571,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:647,safety,input,input-,647,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:674,safety,modul,module,674,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:217,testability,Trace,Traceback,217,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:603,testability,Trace,Traceback,603,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:17,usability,error,error,17,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:191,usability,error,error,191,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:647,usability,input,input-,647,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:796,usability,tool,tools,796,"sc.pl.paga value error; Dear, . When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last). ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/issues/381:1421,usability,tool,tools,1421,"wargs). 4226 valid_shape = False. -> 4227 raise ValueError. 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-29-c0e8bf06937e> in <module>(). ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax). 396 single_component=single_component,. 397 arrowsize=arrowsize,. --> 398 pos=pos). 399 if colorbars[icolor]:. 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state). 746 sct = ax.scatter(. 747 pos_array[:, 0], pos_array[:, 1],. --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap). 749 if fontsize is None:. 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1804 RuntimeWarning, stacklevel=2). -> 1805 return func(ax, *args, **kwargs). 1806 . 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381
https://github.com/scverse/scanpy/pull/382:155,availability,cluster,cluster,155,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:155,deployability,cluster,cluster,155,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:471,deployability,depend,dependencies,471,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:506,deployability,instal,install,506,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:441,energy efficiency,current,currently,441,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:471,integrability,depend,dependencies,471,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:209,interoperability,convers,conversion,209,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:244,modifiability,pac,package,244,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:421,modifiability,pac,package,421,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:471,modifiability,depend,dependencies,471,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:454,reliability,doe,doesn,454,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:471,safety,depend,dependencies,471,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/pull/382:471,testability,depend,dependencies,471,"Cellbrowser exporter for Scanpy; This is inspired by the Spring exporter. It also fills a directory with output files, but in addition to the matrix, adds cluster markers, meta data and embeddings. I keep the conversion code in the cellbrowser package, so I can change it easily in the future. We could also copy the whole function over, but I don't know if this makes a lot of sense, as people will need the cellbrowser package anyways and currently it doesn't have any dependencies, so should be easy to install. This function can optionally convert to html files, start a webserver and serve the result.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382
https://github.com/scverse/scanpy/issues/383:97,deployability,observ,observations,97,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:340,deployability,contain,contains,340,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:975,deployability,observ,observation,975,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:1061,deployability,observ,observation,1061,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:1125,deployability,observ,observation,1125,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:154,energy efficiency,draw,draw,154,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:1197,energy efficiency,draw,drawn,1197,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:1340,energy efficiency,draw,draw,1340,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:133,modifiability,variab,variables,133,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:817,modifiability,paramet,parameter,817,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:969,safety,valid,valid,969,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:299,security,ident,identifier,299,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:349,security,ident,identifiers,349,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:97,testability,observ,observations,97,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:975,testability,observ,observation,975,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:1061,testability,observ,observation,1061,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:1125,testability,observ,observation,1125,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:569,usability,user,user-images,569,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:680,usability,visual,visualize,680,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/issues/383:1235,usability,user,user-images,1235,"Not able to color groups on pca plot; I have an adata object and multiple CD4+ and CD8+ cells as observations and gene expression as variables. I want to draw a PCA with each dot corresponding to one cell and colored by cell type (e.g. all CD4 cells in blue, CD8 in orange). Each cell have a unique identifier, and I have a list cd4, which contains identifiers of only CD4 cells, and the same for CD8. I tried the following:. `scn.pl.pca(adata_needed, groups={""cd4"":cd4, ""cd8"":cd8}, palette = [""red"", ""blue""])`. But the result is the PCA plot in grey. ![image](https://user-images.githubusercontent.com/45490688/49294731-db036400-f4c4-11e8-9b8f-00b3d20e5c41.png). I also tried to visualize only one sample:. `scn.pl.pca(adata_needed, groups=[""SRR1551000""])`. But got exactly the same result. I decided to use ""color"" parameter in pca plot:. `scn.pl.pca(adata_needed, color=""SRR1551000"")`. But got the following mistake:. > ValueError: key 'SRR1551000' is invalid! pass valid observation annotation, one of [] or a gene name Index(['ENSG....', 'ENSG...', ). The observation names are there (adata_needed.obs_names outputs the observation I try to give to the function). Here's the plot I need, but drawn with pandas. . ![image](https://user-images.githubusercontent.com/45490688/49296023-3be06b80-f4c8-11e8-8a21-f1aa9e9b4a46.png). How can I draw a PCA plot like this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/383
https://github.com/scverse/scanpy/pull/384:0,deployability,Updat,Update,0,Update paga.py;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/384
https://github.com/scverse/scanpy/pull/384:0,safety,Updat,Update,0,Update paga.py;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/384
https://github.com/scverse/scanpy/pull/384:0,security,Updat,Update,0,Update paga.py;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/384
https://github.com/scverse/scanpy/issues/385:0,deployability,Automat,Automatic,0,Automatic gene symbols lookup in plotting; In plotting functions: Why not automatically lookup gene symbols from `.var['gene_symbols']` if it's present? Then we don't have to add and check for a `gene_symbols` parameter everywhere...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/385
https://github.com/scverse/scanpy/issues/385:74,deployability,automat,automatically,74,Automatic gene symbols lookup in plotting; In plotting functions: Why not automatically lookup gene symbols from `.var['gene_symbols']` if it's present? Then we don't have to add and check for a `gene_symbols` parameter everywhere...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/385
https://github.com/scverse/scanpy/issues/385:210,modifiability,paramet,parameter,210,Automatic gene symbols lookup in plotting; In plotting functions: Why not automatically lookup gene symbols from `.var['gene_symbols']` if it's present? Then we don't have to add and check for a `gene_symbols` parameter everywhere...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/385
https://github.com/scverse/scanpy/issues/385:0,testability,Automat,Automatic,0,Automatic gene symbols lookup in plotting; In plotting functions: Why not automatically lookup gene symbols from `.var['gene_symbols']` if it's present? Then we don't have to add and check for a `gene_symbols` parameter everywhere...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/385
https://github.com/scverse/scanpy/issues/385:74,testability,automat,automatically,74,Automatic gene symbols lookup in plotting; In plotting functions: Why not automatically lookup gene symbols from `.var['gene_symbols']` if it's present? Then we don't have to add and check for a `gene_symbols` parameter everywhere...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/385
https://github.com/scverse/scanpy/issues/386:480,deployability,api,api,480,"How to use stacked_violin with variable y-axis limits between rows?; I would like to use stacked_violin plot with variable y-axis limits, particularly when swap_axes=True. Examples [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c), particularly code in line 7, show this. How do I do this? When I use it now with my code, it always chooses a uniform y-axis limit for all genes. Which option do I use for variable y-axis limits? Maybe this aspect of scanpy.api.pl.stacked_violin() should be better documented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386
https://github.com/scverse/scanpy/issues/386:480,integrability,api,api,480,"How to use stacked_violin with variable y-axis limits between rows?; I would like to use stacked_violin plot with variable y-axis limits, particularly when swap_axes=True. Examples [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c), particularly code in line 7, show this. How do I do this? When I use it now with my code, it always chooses a uniform y-axis limit for all genes. Which option do I use for variable y-axis limits? Maybe this aspect of scanpy.api.pl.stacked_violin() should be better documented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386
https://github.com/scverse/scanpy/issues/386:480,interoperability,api,api,480,"How to use stacked_violin with variable y-axis limits between rows?; I would like to use stacked_violin plot with variable y-axis limits, particularly when swap_axes=True. Examples [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c), particularly code in line 7, show this. How do I do this? When I use it now with my code, it always chooses a uniform y-axis limit for all genes. Which option do I use for variable y-axis limits? Maybe this aspect of scanpy.api.pl.stacked_violin() should be better documented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386
https://github.com/scverse/scanpy/issues/386:31,modifiability,variab,variable,31,"How to use stacked_violin with variable y-axis limits between rows?; I would like to use stacked_violin plot with variable y-axis limits, particularly when swap_axes=True. Examples [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c), particularly code in line 7, show this. How do I do this? When I use it now with my code, it always chooses a uniform y-axis limit for all genes. Which option do I use for variable y-axis limits? Maybe this aspect of scanpy.api.pl.stacked_violin() should be better documented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386
https://github.com/scverse/scanpy/issues/386:114,modifiability,variab,variable,114,"How to use stacked_violin with variable y-axis limits between rows?; I would like to use stacked_violin plot with variable y-axis limits, particularly when swap_axes=True. Examples [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c), particularly code in line 7, show this. How do I do this? When I use it now with my code, it always chooses a uniform y-axis limit for all genes. Which option do I use for variable y-axis limits? Maybe this aspect of scanpy.api.pl.stacked_violin() should be better documented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386
https://github.com/scverse/scanpy/issues/386:428,modifiability,variab,variable,428,"How to use stacked_violin with variable y-axis limits between rows?; I would like to use stacked_violin plot with variable y-axis limits, particularly when swap_axes=True. Examples [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c), particularly code in line 7, show this. How do I do this? When I use it now with my code, it always chooses a uniform y-axis limit for all genes. Which option do I use for variable y-axis limits? Maybe this aspect of scanpy.api.pl.stacked_violin() should be better documented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386
https://github.com/scverse/scanpy/issues/386:521,usability,document,documented,521,"How to use stacked_violin with variable y-axis limits between rows?; I would like to use stacked_violin plot with variable y-axis limits, particularly when swap_axes=True. Examples [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c), particularly code in line 7, show this. How do I do this? When I use it now with my code, it always chooses a uniform y-axis limit for all genes. Which option do I use for variable y-axis limits? Maybe this aspect of scanpy.api.pl.stacked_violin() should be better documented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386
https://github.com/scverse/scanpy/issues/387:189,availability,cluster,clusters,189,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:477,availability,cluster,clusters,477,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:615,availability,avail,available,615,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:189,deployability,cluster,clusters,189,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:477,deployability,cluster,clusters,477,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:405,energy efficiency,green,green,405,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:429,energy efficiency,current,current,429,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:615,reliability,availab,available,615,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:615,safety,avail,available,615,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:615,security,availab,available,615,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:513,usability,tool,tool,513,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:570,usability,help,help,570,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/387:587,usability,custom,custom,587,"Adopt colorblind-friendly default color cycle; Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387
https://github.com/scverse/scanpy/issues/388:309,availability,state,states,309,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:875,deployability,scale,scale,875,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:1005,deployability,scale,scale,1005,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:875,energy efficiency,scale,scale,875,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:1005,energy efficiency,scale,scale,1005,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:1025,energy efficiency,Current,Currently,1025,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:309,integrability,state,states,309,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:79,modifiability,pac,package,79,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:776,modifiability,variab,variable,776,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:815,modifiability,paramet,parameters,815,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:875,modifiability,scal,scale,875,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:1005,modifiability,scal,scale,1005,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:875,performance,scale,scale,875,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:1005,performance,scale,scale,1005,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:387,reliability,doe,does,387,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:295,usability,document,documentation,295,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:952,usability,user,user,952,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:979,usability,user,user,979,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/388:1084,usability,document,documentation,1084,"vmin, vmax kwargs are ignored by sc.pl.dotplot(); First, very nice job on this package! It is a welcome replacement to seurat for python programmers! Yay! I have a suggestion to improve sc.pl.dotplot(). I would like to be able to adjust the limits of the color_map used for sc.pl.dotplot(). The documentation states that kwargs get passed to matplotlib.pyplot.scatter(). But the dotplot does not change when vmin and vmax are included as kwargs. In the source code for anndata.dotplot includes the following lines:. import matplotlib.colors. normalize = matplotlib.colors.Normalize(vmin=min(mean_flat), vmax=max(mean_flat)). colors = [cmap(normalize(value)) for value in mean_flat]. I believe these lines are the issue. Because vmin and vmax are calculated from the mean_flat variable the vmin and vmax provided as parameters are ignored. Perhaps rather than determining the scale using mean_flat, the vmin and vmax should be used when provided by the user. This would allow the user to set the color_bar scale as they need. Currently, there is no way to change the color_bar and the documentation is misleading, since it suggests that it can be done.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388
https://github.com/scverse/scanpy/issues/389:222,integrability,sub,subplots,222,"Plot of ranking genes does not accept 'ncols' graphical option; Hej,. I have a minor plotting issue. when using the following command `sc.pl.rank_genes_groups(all_data, n_genes=20, sharey=True, ncols=5)`, I cannot get the subplots in groups of five panels on each row, even though this option is present in the documentation :). It might be that it needs a fix. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389
https://github.com/scverse/scanpy/issues/389:181,interoperability,share,sharey,181,"Plot of ranking genes does not accept 'ncols' graphical option; Hej,. I have a minor plotting issue. when using the following command `sc.pl.rank_genes_groups(all_data, n_genes=20, sharey=True, ncols=5)`, I cannot get the subplots in groups of five panels on each row, even though this option is present in the documentation :). It might be that it needs a fix. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389
https://github.com/scverse/scanpy/issues/389:22,reliability,doe,does,22,"Plot of ranking genes does not accept 'ncols' graphical option; Hej,. I have a minor plotting issue. when using the following command `sc.pl.rank_genes_groups(all_data, n_genes=20, sharey=True, ncols=5)`, I cannot get the subplots in groups of five panels on each row, even though this option is present in the documentation :). It might be that it needs a fix. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389
https://github.com/scverse/scanpy/issues/389:126,usability,command,command,126,"Plot of ranking genes does not accept 'ncols' graphical option; Hej,. I have a minor plotting issue. when using the following command `sc.pl.rank_genes_groups(all_data, n_genes=20, sharey=True, ncols=5)`, I cannot get the subplots in groups of five panels on each row, even though this option is present in the documentation :). It might be that it needs a fix. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389
https://github.com/scverse/scanpy/issues/389:311,usability,document,documentation,311,"Plot of ranking genes does not accept 'ncols' graphical option; Hej,. I have a minor plotting issue. when using the following command `sc.pl.rank_genes_groups(all_data, n_genes=20, sharey=True, ncols=5)`, I cannot get the subplots in groups of five panels on each row, even though this option is present in the documentation :). It might be that it needs a fix. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389
https://github.com/scverse/scanpy/pull/390:366,modifiability,variab,variable,366,"dotplot can take vmin vmax arguments from user; Hi Fidel, . Here is the pull request for vmin vmax in dotplot... I am guessing that there could be similar issues with other plotting functions and other plotting keywords. In general, it would be best to check plotting methods for plotting keywords and use what is provided in kwds by default rather than setting the variable without checking whether it was provided. . Thanks for your groups great work! Tim.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390
https://github.com/scverse/scanpy/pull/390:42,usability,user,user,42,"dotplot can take vmin vmax arguments from user; Hi Fidel, . Here is the pull request for vmin vmax in dotplot... I am guessing that there could be similar issues with other plotting functions and other plotting keywords. In general, it would be best to check plotting methods for plotting keywords and use what is provided in kwds by default rather than setting the variable without checking whether it was provided. . Thanks for your groups great work! Tim.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390
https://github.com/scverse/scanpy/issues/391:119,availability,error,error,119,"highly_variable_genes - issue; Hi there,. While running ```sc.pp.highly_variable_genes(adata.X)``` I got the following error:. ```AttributeError: X not found```. I then ran ```sc.pp.highly_variable_genes(adata)``` and got the following:. ```ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]). You can drop duplicate edges by setting the duplicates kwarg ```. The older ```sc.pp.filter_genes_dispersion(adata.X)``` works fine. Do you know how to fix this? Thank you! **Info**: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391
https://github.com/scverse/scanpy/issues/391:119,performance,error,error,119,"highly_variable_genes - issue; Hi there,. While running ```sc.pp.highly_variable_genes(adata.X)``` I got the following error:. ```AttributeError: X not found```. I then ran ```sc.pp.highly_variable_genes(adata)``` and got the following:. ```ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]). You can drop duplicate edges by setting the duplicates kwarg ```. The older ```sc.pp.filter_genes_dispersion(adata.X)``` works fine. Do you know how to fix this? Thank you! **Info**: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391
https://github.com/scverse/scanpy/issues/391:119,safety,error,error,119,"highly_variable_genes - issue; Hi there,. While running ```sc.pp.highly_variable_genes(adata.X)``` I got the following error:. ```AttributeError: X not found```. I then ran ```sc.pp.highly_variable_genes(adata)``` and got the following:. ```ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]). You can drop duplicate edges by setting the duplicates kwarg ```. The older ```sc.pp.filter_genes_dispersion(adata.X)``` works fine. Do you know how to fix this? Thank you! **Info**: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391
https://github.com/scverse/scanpy/issues/391:119,usability,error,error,119,"highly_variable_genes - issue; Hi there,. While running ```sc.pp.highly_variable_genes(adata.X)``` I got the following error:. ```AttributeError: X not found```. I then ran ```sc.pp.highly_variable_genes(adata)``` and got the following:. ```ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]). You can drop duplicate edges by setting the duplicates kwarg ```. The older ```sc.pp.filter_genes_dispersion(adata.X)``` works fine. Do you know how to fix this? Thank you! **Info**: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391
https://github.com/scverse/scanpy/issues/391:654,usability,learn,learn,654,"highly_variable_genes - issue; Hi there,. While running ```sc.pp.highly_variable_genes(adata.X)``` I got the following error:. ```AttributeError: X not found```. I then ran ```sc.pp.highly_variable_genes(adata)``` and got the following:. ```ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]). You can drop duplicate edges by setting the duplicates kwarg ```. The older ```sc.pp.filter_genes_dispersion(adata.X)``` works fine. Do you know how to fix this? Thank you! **Info**: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391
https://github.com/scverse/scanpy/issues/392:160,usability,tool,tools,160,"`rank_genes_groups_gene_names` is no longer here.; correlation_matrix:. https://github.com/theislab/scanpy/blob/21adc0c9a31fb1eebb16579aa4f41700bc939aa2/scanpy/tools/top_genes.py#L58. exploratory_rank_analysis:. https://github.com/theislab/scanpy/blob/02e78bb025f9cd8d02cf6d39256fea008ec51d7f/scanpy/plotting/top_genes_visual.py#L109. also correlation_matrix is not included in the docs, and the recommendations alex made on 573519e524815fd2c227c876da26e283939a3012 aren’t implemented. generally, please don’t just commit low quality and unfinished code to master @tcallies. that’s what PRs are for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/392
https://github.com/scverse/scanpy/issues/393:984,deployability,manag,manageable,984,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1210,deployability,depend,depend,1210,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:280,energy efficiency,current,currently,280,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:984,energy efficiency,manag,manageable,984,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:447,integrability,compon,components,447,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:511,integrability,sub,subsequent,511,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1210,integrability,depend,depend,1210,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:447,interoperability,compon,components,447,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:447,modifiability,compon,components,447,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1210,modifiability,depend,depend,1210,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1202,reliability,doe,doesn,1202,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:984,safety,manag,manageable,984,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1210,safety,depend,depend,1210,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1084,testability,simpl,simple,1084,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1105,testability,understand,understand,1105,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1210,testability,depend,depend,1210,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/393:1084,usability,simpl,simple,1084,"PCA with sparse data; Right now we get different PCs when using sparse data (applying TruncatedSVD) compared to using dense data (applying PCA). . `TruncatedSVD(X-X.mean(0))` would be equivalent to `PCA(X)`. `X-X.mean(0)` would obviously not be sparse anymore, which is why it is currently implemented as `TruncatedSVD(X)`. The first PC will be mainly representing the vector of means, thus be very different from zero-centered PCA. The following components would approximately resemble PCA. However, since all subsequent PCs are orthogonal to the first PC, we will never get to the exact solution. Hence, the PCs are questionable, in particular when the very first ones are quite misleading. That's not desirable. I think we should obtain the same PCA representation regardless of the data type. Don't we have to densify `X` at some point anyways, as we would have to compute `X.dot(X.T)`. Thus it might be worth thinking of some EM approach? Whatsoever, I think as long the data is manageable and fits into the RAM, we should just use the densified `X`. . Line 486 in preprocessing/simple I don't quite understand:. ```. if zero_center is not None:. zero_center = not issparse(adata_comp.X). ```. It doesn't depend on the actual value of the attribute `zero_center` anymore. Is that a bug, or what is the rationale behind this? For now, we can change that into something like. ```. zero_center = zero_center if zero_center is not None else False if issparse(adata.X) and adata.X.shape[0] > 1e4 else True. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393
https://github.com/scverse/scanpy/issues/394:105,availability,recov,recover,105,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:354,availability,error,error,354,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:16,deployability,modul,module,16,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:105,deployability,recov,recover,105,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:117,deployability,observ,observation,117,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:241,deployability,api,api,241,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:538,deployability,modul,module,538,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:923,deployability,modul,module,923,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:241,integrability,api,api,241,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:767,integrability,filter,filter,767,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:241,interoperability,api,api,241,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:873,interoperability,format,format,873,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:16,modifiability,modul,module,16,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:538,modifiability,modul,module,538,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:608,modifiability,pac,packages,608,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:923,modifiability,modul,module,923,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:354,performance,error,error,354,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:105,reliability,recov,recover,105,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:16,safety,modul,module,16,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:105,safety,recov,recover,105,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:354,safety,error,error,354,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:511,safety,input,input-,511,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:538,safety,modul,module,538,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:923,safety,modul,module,923,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:105,security,recov,recover,105,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:117,testability,observ,observation,117,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:467,testability,Trace,Traceback,467,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:713,testability,simpl,simplefilter,713,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:192,usability,command,commands,192,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:354,usability,error,error,354,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:511,usability,input,input-,511,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/394:713,usability,simpl,simplefilter,713,"AttributeError: module 'warnings' has no attribute 'warning'; Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```. import scanpy.api as sc. data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data). ```. Then this error happens:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-14-1f44700b9ea5> in <module>(). ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs). 104 def new_func(*args, **kwargs):. 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter. --> 106 warnings.warning(. 107 'Use {0} instead of {1}, {1} will be removed in the future.'. 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394
https://github.com/scverse/scanpy/issues/395:5,interoperability,coordinat,coordinates,5,"Paga coordinates from phate plot; Is there a way to plot a paga plot based off the coordinates from a phate plot? No issue in doing it from an fa plot, just wondering if its possible from a phate plot as well?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/395
https://github.com/scverse/scanpy/issues/395:83,interoperability,coordinat,coordinates,83,"Paga coordinates from phate plot; Is there a way to plot a paga plot based off the coordinates from a phate plot? No issue in doing it from an fa plot, just wondering if its possible from a phate plot as well?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/395
https://github.com/scverse/scanpy/issues/396:85,deployability,scale,scale,85,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:391,deployability,automat,automatically,391,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:75,energy efficiency,frequenc,frequency,75,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:85,energy efficiency,scale,scale,85,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:265,integrability,sub,subpopulations,265,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:9,modifiability,scal,scaling,9,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:85,modifiability,scal,scale,85,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:383,modifiability,scal,scaling,383,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:85,performance,scale,scale,85,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:373,reliability,doe,does,373,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:391,testability,automat,automatically,391,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/396:214,usability,visual,visualize,214,"Dot plot scaling issue/request; It would be great to be able to adjust the frequency scale of the dot size to the min-max values of the data set, instead of 0-100% of total cells. This is particularly important to visualize expression of genes that is rare in some subpopulations, that are otherwise impossible to see because the dots are too small. As a side note, Seurat does this scaling automatically and it works well. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396
https://github.com/scverse/scanpy/issues/397:65,availability,cluster,clusters,65,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:230,availability,cluster,clusters,230,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:299,availability,cluster,clusters,299,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:341,availability,cluster,clusters,341,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:65,deployability,cluster,clusters,65,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:230,deployability,cluster,clusters,230,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:299,deployability,cluster,clusters,299,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:341,deployability,cluster,clusters,341,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:42,usability,user,user,42,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/issues/397:408,usability,help,help,408,"Calculate differential expression between user defined groups of clusters; Hello,. I want to be able to use sc.tl.rank_genes_groups() to calculate differential expression between two groups of my choice. For example, if I have 16 clusters in my UMAP plot and I want to compare group 1 (all cells in clusters 1 to 8) to group 2 (all cells in clusters 9 to 16) how can I do this ? Thank you in advance for any help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397
https://github.com/scverse/scanpy/pull/398:182,availability,sli,slightly,182,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:498,deployability,version,version,498,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:868,energy efficiency,model,models,868,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:910,energy efficiency,power,power,910,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:934,energy efficiency,estimat,estimate,934,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:20,integrability,Batch,Batch,20,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:109,integrability,batch,batch,109,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:498,integrability,version,version,498,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:597,integrability,batch,batch,597,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:751,integrability,batch,batch,751,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:351,modifiability,pac,package,351,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:468,modifiability,Variab,Variable,468,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:489,modifiability,pac,package,489,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:498,modifiability,version,version,498,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:20,performance,Batch,Batch,20,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:109,performance,batch,batch,109,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:597,performance,batch,batch,597,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:751,performance,batch,batch,751,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:182,reliability,sli,slightly,182,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:248,safety,permiss,permission,248,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:191,security,modif,modified,191,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:868,security,model,models,868,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/pull/398:976,testability,understand,understand,976,"Combat Function for Batch Effects; Hi all,. this is a re-implementation of the ComBat function in python for batch effect removal by Brent Pedersen at the University of Utah which I slightly modified to work with AnnData objects. I asked Brent for permission and he would be happy with us using this. Originally, the code was written in R for the SVA package:. Jeffrey T. Leek, W. Evan Johnson, Hilary S. Parker, Andrew E. Jaffe. and John D. Storey (). sva: Surrogate Variable Analysis. R package. version 3.4.0. The idea is taken from this paper:. Johnson WE, Rabinovic A, Li C (2007). Adjusting batch effects in microarray. expression data using Empirical Bayes methods. Biostatistics 8:118-127. . Originally, the method was developed to adjust for batch effects in microarray data, however, it is commonly applied to scRNA-seq data nowadays. The method fits linear models to the genes and pools statistical power by means of EB to estimate per gene correction factors. . I understand that @mbuttner also has an implementation of this - maybe we can combine and get the best of both approaches?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398
https://github.com/scverse/scanpy/issues/399:31,availability,cluster,clusters,31,"annotating anndata object with clusters and tnse info from .csv file; Dear,. Thanks for this fantastic package. I saved one of my analysis to get .csv files output using the cmd adata.write_csv('./ouput'). I modified some of these files (the obs.csv and obsm) for pecific purposes related to a collaborative project while respecting the dimensions and the order of the cells. How can I reload back these files into an anndata object? . adata = sc.read_csv('./ouput/*') ??",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399
https://github.com/scverse/scanpy/issues/399:31,deployability,cluster,clusters,31,"annotating anndata object with clusters and tnse info from .csv file; Dear,. Thanks for this fantastic package. I saved one of my analysis to get .csv files output using the cmd adata.write_csv('./ouput'). I modified some of these files (the obs.csv and obsm) for pecific purposes related to a collaborative project while respecting the dimensions and the order of the cells. How can I reload back these files into an anndata object? . adata = sc.read_csv('./ouput/*') ??",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399
https://github.com/scverse/scanpy/issues/399:103,modifiability,pac,package,103,"annotating anndata object with clusters and tnse info from .csv file; Dear,. Thanks for this fantastic package. I saved one of my analysis to get .csv files output using the cmd adata.write_csv('./ouput'). I modified some of these files (the obs.csv and obsm) for pecific purposes related to a collaborative project while respecting the dimensions and the order of the cells. How can I reload back these files into an anndata object? . adata = sc.read_csv('./ouput/*') ??",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399
https://github.com/scverse/scanpy/issues/399:208,security,modif,modified,208,"annotating anndata object with clusters and tnse info from .csv file; Dear,. Thanks for this fantastic package. I saved one of my analysis to get .csv files output using the cmd adata.write_csv('./ouput'). I modified some of these files (the obs.csv and obsm) for pecific purposes related to a collaborative project while respecting the dimensions and the order of the cells. How can I reload back these files into an anndata object? . adata = sc.read_csv('./ouput/*') ??",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399
https://github.com/scverse/scanpy/issues/400:22,deployability,api,api,22,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:87,deployability,api,api,87,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:193,deployability,API,API,193,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:22,integrability,api,api,22,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:87,integrability,api,api,87,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:186,integrability,pub,public,186,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:193,integrability,API,API,193,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:22,interoperability,api,api,22,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:87,interoperability,api,api,87,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:193,interoperability,API,API,193,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/issues/400:152,usability,hint,hints,152,"Getting rid of scanpy.api; Hi, as we discussed, @falexwolf wants to get rid of `scanpy.api` and make `scanpy` what is was before. For this, we can take hints from trio, which has a nice public API here: https://github.com/python-trio/trio/blob/master/trio/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/400
https://github.com/scverse/scanpy/pull/401:81,usability,user,user-images,81,Add `dot_min` and `dot_max` to dotplot; This PR addresses #396. ![image](https://user-images.githubusercontent.com/4964309/50230025-04b8f800-03ac-11e9-8dcd-b1e66901c4ff.png).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/401
https://github.com/scverse/scanpy/issues/405:608,availability,error,error,608,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:645,availability,Error,Error,645,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:77,deployability,instal,installed,77,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:566,deployability,stack,stacked,566,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:919,deployability,updat,update,919,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:614,integrability,messag,message,614,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:626,integrability,sub,subsequent,626,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:651,integrability,messag,message,651,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:614,interoperability,messag,message,614,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:651,interoperability,messag,message,651,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:608,performance,error,error,608,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:645,performance,Error,Error,645,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:524,reliability,doe,does,524,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:608,safety,error,error,608,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:645,safety,Error,Error,645,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:822,safety,test,tested,822,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:919,safety,updat,update,919,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:275,security,rotat,rotation,275,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:919,security,updat,update,919,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:822,testability,test,tested,822,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:608,usability,error,error,608,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/issues/405:645,usability,Error,Error,645,"sc.pl.stacked_violin: IndexError, list index out of range; Scanpy vs. 1.3.6. installed using pip3. OSX 10.10.5. Jupyter lab. code:. `list_of_list_of_marker_genes = [mg1, mg2, mg3]. for mg in list_of_list_of_marker_genes:. sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90). print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run. sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then. 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405
https://github.com/scverse/scanpy/pull/406:22,deployability,api,api,22,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:69,deployability,api,api,69,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:82,deployability,modul,modules,82,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:267,deployability,api,api,267,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:422,deployability,api,api,422,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:480,deployability,api,api,480,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:95,energy efficiency,core,core,95,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:22,integrability,api,api,22,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:69,integrability,api,api,69,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:267,integrability,api,api,267,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:422,integrability,api,api,422,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:480,integrability,api,api,480,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:22,interoperability,api,api,22,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:32,interoperability,distribut,distributes,32,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:69,interoperability,api,api,69,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:267,interoperability,api,api,267,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:422,interoperability,api,api,422,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:447,interoperability,compatib,compatibility,447,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:480,interoperability,api,api,480,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:82,modifiability,modul,modules,82,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:494,modifiability,maintain,maintained,494,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:82,safety,modul,modules,82,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:494,safety,maintain,maintained,494,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:286,testability,simpl,simply,286,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:280,usability,user,users,280,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/pull/406:286,usability,simpl,simply,286,"Getting rid of scanpy.api; This distributes the reexports in `scanpy/api/` in two modules: the core functionality goes into the root (`scanpy/__init__.py`) and the external functionality goes into `scanpy/ext/`. The structure of the latter mirrors the one of `scanpy.api` so that users simply need to adjust their imports. ```. import scanpy as sc. import scanpy.ext as sce. ```. instead of previously. ```. import scanpy.api as sc. ```. Backward compatibility for use of `scanpy.api` is fully maintained, but from now on, its use and development are deprecated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406
https://github.com/scverse/scanpy/issues/407:355,deployability,api,api,355,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:434,deployability,api,api,434,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:445,deployability,api,api,445,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:525,deployability,API,API,525,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:594,deployability,api,api,594,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:1380,deployability,contain,contained,1380,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:355,integrability,api,api,355,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:434,integrability,api,api,434,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:445,integrability,api,api,445,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:525,integrability,API,API,525,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:594,integrability,api,api,594,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:355,interoperability,api,api,355,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:434,interoperability,api,api,434,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:445,interoperability,api,api,445,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:525,interoperability,API,API,525,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:594,interoperability,api,api,594,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:42,performance,content,contents,42,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:260,performance,content,contents,260,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:1326,performance,content,contents,1326,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:14,reliability,doe,does,14,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:225,reliability,doe,does,225,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:1200,reliability,pra,practical,1200,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:142,usability,help,helpful,142,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:164,usability,navigat,navigate,164,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:186,usability,document,documentation,186,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:728,usability,clear,clear,728,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:940,usability,user,user-images,940,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:1151,usability,navigat,navigate,1151,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:1272,usability,help,helpful,1272,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:1291,usability,navigat,navigating,1291,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/407:1574,usability,user,user-images,1574,"Read the docs does not show full table of contents of left bar + font improvement; Hello, I have a minor suggestion that I think will be very helpful for people to navigate and read the documentation. Right now Read the Docs does not display the full table of contents on the left (i.e. one link for every page). For example, to go to the page on `scanpy.api.pp.calculate_qc_metrics` (which is https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.calculate_qc_metrics.html) I have two options:. First, I could go to the API page under prepocessing (https://scanpy.readthedocs.io/en/latest/api/index.html#preprocessing-pp) , and click the link to `pp.calculate_qc_metrics` link highlighted in the picture. However, it's not clear from the font used that it's clickable, because it looks like just markdown. I'd suggest making links blue, or underlined, or both, because that's what will convey that they are clickable. ![image](https://user-images.githubusercontent.com/12504176/50525392-065f7b80-0a90-11e9-8731-35dde488a456.png). Second, at the bottom of the page I could click `next`, which will take me to the next page. This only allows me to navigate the pages sequentially, and is not very practical because I don't know what comes next. . It would be extremely helpful for people navigating the doc if the table of contents unfurled into links for the individual pages contained in the section they are at. I made an example below of what I think this could look like, in it each page under `Preprocessing: PP` gets it's own link in the sidebar. ![image](https://user-images.githubusercontent.com/12504176/50525689-f052ba80-0a91-11e9-8ddc-9cdb86a0a7f5.png). Thanks. Eduardo.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407
https://github.com/scverse/scanpy/issues/408:105,deployability,api,api,105,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:130,deployability,modul,module-scanpy,130,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:216,deployability,api,api,216,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:227,deployability,api,api,227,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:236,deployability,modul,module-scanpy,236,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:250,deployability,api,api,250,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:295,deployability,api,api,295,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:320,deployability,modul,module-scanpy,320,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:423,deployability,modul,module,423,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:105,integrability,api,api,105,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:216,integrability,api,api,216,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:227,integrability,api,api,227,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:250,integrability,api,api,250,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:295,integrability,api,api,295,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:105,interoperability,api,api,105,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:216,interoperability,api,api,216,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:227,interoperability,api,api,227,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:250,interoperability,api,api,250,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:295,interoperability,api,api,295,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:130,modifiability,modul,module-scanpy,130,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:236,modifiability,modul,module-scanpy,236,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:320,modifiability,modul,module-scanpy,320,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:423,modifiability,modul,module,423,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:130,safety,modul,module-scanpy,130,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:236,safety,modul,module-scanpy,236,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:320,safety,modul,module-scanpy,320,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:423,safety,modul,module,423,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:56,testability,simpl,simple,56,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/408:56,usability,simpl,simple,56,"automodule docs; I'm probably not seeing something very simple:. https://scanpy.readthedocs.io/en/latest/api/scanpy.external.html#module-scanpy.external. renders fine whereas. https://scanpy.readthedocs.io/en/latest/api/scanpy.api.html#module-scanpy.api. https://scanpy.readthedocs.io/en/latest/api/scanpy.plotting.html#module-scanpy.plotting. both append an auto-generated list of all functions and classes defined in the module. As there is an annotated manual list already, we obviously don't want this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408
https://github.com/scverse/scanpy/issues/409:284,deployability,fail,fails,284,KeyError: 'dpt_order_indices' missing if branching=0; I don't think this is fixed in the previous issue https://github.com/theislab/scanpy/issues/129. If you run `sc.tl.dpt(adata)` it creates the `dpt_pseudotime` property in `obs` as expected. However using dpt in plotting functions fails like `sc.pl.dpt_timeseries(adata)`. This is due to the `dpt_order_indices` property not being created if `branching=0`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409
https://github.com/scverse/scanpy/issues/409:284,reliability,fail,fails,284,KeyError: 'dpt_order_indices' missing if branching=0; I don't think this is fixed in the previous issue https://github.com/theislab/scanpy/issues/129. If you run `sc.tl.dpt(adata)` it creates the `dpt_pseudotime` property in `obs` as expected. However using dpt in plotting functions fails like `sc.pl.dpt_timeseries(adata)`. This is due to the `dpt_order_indices` property not being created if `branching=0`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409
https://github.com/scverse/scanpy/issues/411:0,integrability,Messag,Message,0,"Message from highly_variable_genes; Hi,. when using the command . ```python. sc.preprocessing.highly_variable_genes.highly_variable_genes(all_data,n_top_genes=5000). ```. I get this informative message:. ```. --> added. 'highly_variable', boolean vector (adata.var). 'means', boolean vector (adata.var). 'dispersions', boolean vector (adata.var). 'dispersions_norm', boolean vector (adata.var). ```. Even though not all of them are booleans! I guess it is just a copy-paste residue from implementation :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/411
https://github.com/scverse/scanpy/issues/411:194,integrability,messag,message,194,"Message from highly_variable_genes; Hi,. when using the command . ```python. sc.preprocessing.highly_variable_genes.highly_variable_genes(all_data,n_top_genes=5000). ```. I get this informative message:. ```. --> added. 'highly_variable', boolean vector (adata.var). 'means', boolean vector (adata.var). 'dispersions', boolean vector (adata.var). 'dispersions_norm', boolean vector (adata.var). ```. Even though not all of them are booleans! I guess it is just a copy-paste residue from implementation :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/411
https://github.com/scverse/scanpy/issues/411:0,interoperability,Messag,Message,0,"Message from highly_variable_genes; Hi,. when using the command . ```python. sc.preprocessing.highly_variable_genes.highly_variable_genes(all_data,n_top_genes=5000). ```. I get this informative message:. ```. --> added. 'highly_variable', boolean vector (adata.var). 'means', boolean vector (adata.var). 'dispersions', boolean vector (adata.var). 'dispersions_norm', boolean vector (adata.var). ```. Even though not all of them are booleans! I guess it is just a copy-paste residue from implementation :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/411
https://github.com/scverse/scanpy/issues/411:194,interoperability,messag,message,194,"Message from highly_variable_genes; Hi,. when using the command . ```python. sc.preprocessing.highly_variable_genes.highly_variable_genes(all_data,n_top_genes=5000). ```. I get this informative message:. ```. --> added. 'highly_variable', boolean vector (adata.var). 'means', boolean vector (adata.var). 'dispersions', boolean vector (adata.var). 'dispersions_norm', boolean vector (adata.var). ```. Even though not all of them are booleans! I guess it is just a copy-paste residue from implementation :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/411
https://github.com/scverse/scanpy/issues/411:56,usability,command,command,56,"Message from highly_variable_genes; Hi,. when using the command . ```python. sc.preprocessing.highly_variable_genes.highly_variable_genes(all_data,n_top_genes=5000). ```. I get this informative message:. ```. --> added. 'highly_variable', boolean vector (adata.var). 'means', boolean vector (adata.var). 'dispersions', boolean vector (adata.var). 'dispersions_norm', boolean vector (adata.var). ```. Even though not all of them are booleans! I guess it is just a copy-paste residue from implementation :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/411
https://github.com/scverse/scanpy/pull/412:108,deployability,api,api,108,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:335,deployability,modul,modules,335,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:537,deployability,api,api,537,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:568,deployability,api,api,568,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:38,integrability,sub,submodules,38,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:108,integrability,api,api,108,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:255,integrability,sub,submodules,255,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:471,integrability,sub,submodule,471,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:537,integrability,api,api,537,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:568,integrability,api,api,568,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:108,interoperability,api,api,108,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:355,interoperability,distribut,distributed,355,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:537,interoperability,api,api,537,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:568,interoperability,api,api,568,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:335,modifiability,modul,modules,335,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:335,safety,modul,modules,335,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:244,security,access,access,244,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:5,usability,tool,tool,5,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:176,usability,user,user,176,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:316,usability,user,users,316,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/412:453,usability,user,user,453,"Make tool, preprocessing and plotting submodules private; Now that we changed from the reexports in `scanpy.api` whose sole purpose were to reexport top-level functions to the user in a clean way, we run into two problems;. * one can no longer access the submodules as the names are occupied by the functions. * the users sees private modules such as `pp.distributed` and similar. Therefore, I'd change everything that is not intended to be used by the user to a private submodule. This actually was the very first design before `scanpy.api` (inspired by `statsmodels.api` and `matplotlib.pyplot`) was introduced. Comments are welcome: @flying-sheep and everyone else.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/412
https://github.com/scverse/scanpy/pull/414:11,security,auth,author,11,Centralize author;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/414
https://github.com/scverse/scanpy/issues/415:171,deployability,contain,contains,171,"equal_frequency bins in highly_variable_genes; Hi,. Using Seurat, in their variable gene function I've had some success using the `equal_frequency` option, where each bin contains an equal number of genes. Would it possible to implement this option in scanpy? . If you'd like I could submit a PR to implement this feature. I think it could be as simple as using `pd.qcut` instead of `pd.cut` or you could use a similar style as in the `cell_ranger` flavor with `pd.cut(df['mean'], np.r_[-np.inf,. np.percentile(df['mean'], np.arange(10, 105, 5)), np.inf])`. I don't know how useful it would be, but I could also add the option to have more bins in the `cell_ranger` flavor by replacing `np.arange(10,105,5)` with `np.linspace(10, 100, n_bins - 1)`. Best,. David.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415
https://github.com/scverse/scanpy/issues/415:284,integrability,sub,submit,284,"equal_frequency bins in highly_variable_genes; Hi,. Using Seurat, in their variable gene function I've had some success using the `equal_frequency` option, where each bin contains an equal number of genes. Would it possible to implement this option in scanpy? . If you'd like I could submit a PR to implement this feature. I think it could be as simple as using `pd.qcut` instead of `pd.cut` or you could use a similar style as in the `cell_ranger` flavor with `pd.cut(df['mean'], np.r_[-np.inf,. np.percentile(df['mean'], np.arange(10, 105, 5)), np.inf])`. I don't know how useful it would be, but I could also add the option to have more bins in the `cell_ranger` flavor by replacing `np.arange(10,105,5)` with `np.linspace(10, 100, n_bins - 1)`. Best,. David.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415
https://github.com/scverse/scanpy/issues/415:75,modifiability,variab,variable,75,"equal_frequency bins in highly_variable_genes; Hi,. Using Seurat, in their variable gene function I've had some success using the `equal_frequency` option, where each bin contains an equal number of genes. Would it possible to implement this option in scanpy? . If you'd like I could submit a PR to implement this feature. I think it could be as simple as using `pd.qcut` instead of `pd.cut` or you could use a similar style as in the `cell_ranger` flavor with `pd.cut(df['mean'], np.r_[-np.inf,. np.percentile(df['mean'], np.arange(10, 105, 5)), np.inf])`. I don't know how useful it would be, but I could also add the option to have more bins in the `cell_ranger` flavor by replacing `np.arange(10,105,5)` with `np.linspace(10, 100, n_bins - 1)`. Best,. David.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415
https://github.com/scverse/scanpy/issues/415:346,testability,simpl,simple,346,"equal_frequency bins in highly_variable_genes; Hi,. Using Seurat, in their variable gene function I've had some success using the `equal_frequency` option, where each bin contains an equal number of genes. Would it possible to implement this option in scanpy? . If you'd like I could submit a PR to implement this feature. I think it could be as simple as using `pd.qcut` instead of `pd.cut` or you could use a similar style as in the `cell_ranger` flavor with `pd.cut(df['mean'], np.r_[-np.inf,. np.percentile(df['mean'], np.arange(10, 105, 5)), np.inf])`. I don't know how useful it would be, but I could also add the option to have more bins in the `cell_ranger` flavor by replacing `np.arange(10,105,5)` with `np.linspace(10, 100, n_bins - 1)`. Best,. David.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415
https://github.com/scverse/scanpy/issues/415:346,usability,simpl,simple,346,"equal_frequency bins in highly_variable_genes; Hi,. Using Seurat, in their variable gene function I've had some success using the `equal_frequency` option, where each bin contains an equal number of genes. Would it possible to implement this option in scanpy? . If you'd like I could submit a PR to implement this feature. I think it could be as simple as using `pd.qcut` instead of `pd.cut` or you could use a similar style as in the `cell_ranger` flavor with `pd.cut(df['mean'], np.r_[-np.inf,. np.percentile(df['mean'], np.arange(10, 105, 5)), np.inf])`. I don't know how useful it would be, but I could also add the option to have more bins in the `cell_ranger` flavor by replacing `np.arange(10,105,5)` with `np.linspace(10, 100, n_bins - 1)`. Best,. David.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415
https://github.com/scverse/scanpy/issues/416:7,deployability,instal,install,7,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:44,deployability,instal,install,44,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:228,deployability,modul,module,228,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:284,deployability,modul,module,284,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:392,deployability,modul,module,392,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:490,deployability,modul,module,490,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:610,deployability,modul,module,610,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:719,deployability,modul,module,719,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:767,integrability,batch,batch,767,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:228,modifiability,modul,module,228,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:284,modifiability,modul,module,284,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:392,modifiability,modul,module,392,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:490,modifiability,modul,module,490,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:610,modifiability,modul,module,610,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:719,modifiability,modul,module,719,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:767,performance,batch,batch,767,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:107,safety,Compl,Complete,107,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:228,safety,modul,module,228,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:284,safety,modul,module,284,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:392,safety,modul,module,392,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:490,safety,modul,module,490,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:610,safety,modul,module,610,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:719,safety,modul,module,719,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:107,security,Compl,Complete,107,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:163,testability,Trace,Traceback,163,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:128,usability,command,command,128,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:415,usability,tool,tools,415,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/416:458,usability,tool,tools,458,"latest install AnnData is not defined; `pip install -e .`. gives:. ```. Obtaining file:///apps/gau/scanpy. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/apps/gau/scanpy/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/apps/gau/scanpy/scanpy/__init__.py"", line 31, in <module>. from . import tools as tl. File ""/apps/gau/scanpy/scanpy/tools/__init__.py"", line 1, in <module>. from ..preprocessing._simple import pca. File ""/apps/gau/scanpy/scanpy/preprocessing/__init__.py"", line 7, in <module>. from ._combat import combat. File ""/apps/gau/scanpy/scanpy/preprocessing/_combat.py"", line 111, in <module>. def combat(adata: AnnData, key: str = 'batch', inplace: bool = True):. NameError: name 'AnnData' is not defined. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/416
https://github.com/scverse/scanpy/issues/417:13,reliability,doe,does,13,"to_df method does not appear to be working correctly; I'm trying to export a Pandas DataFrame from the adata object using the example notebook pbmc3k and I'm getting a weird result shown below: . <img width=""1079"" alt=""screen shot 2019-01-09 at 3 52 51 pm"" src=""https://user-images.githubusercontent.com/8352840/50927784-d1a3da80-1426-11e9-9b01-fef15bdf2e2d.png"">. I could not find documentation on the `to_df` method in the documents.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/417
https://github.com/scverse/scanpy/issues/417:270,usability,user,user-images,270,"to_df method does not appear to be working correctly; I'm trying to export a Pandas DataFrame from the adata object using the example notebook pbmc3k and I'm getting a weird result shown below: . <img width=""1079"" alt=""screen shot 2019-01-09 at 3 52 51 pm"" src=""https://user-images.githubusercontent.com/8352840/50927784-d1a3da80-1426-11e9-9b01-fef15bdf2e2d.png"">. I could not find documentation on the `to_df` method in the documents.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/417
https://github.com/scverse/scanpy/issues/417:382,usability,document,documentation,382,"to_df method does not appear to be working correctly; I'm trying to export a Pandas DataFrame from the adata object using the example notebook pbmc3k and I'm getting a weird result shown below: . <img width=""1079"" alt=""screen shot 2019-01-09 at 3 52 51 pm"" src=""https://user-images.githubusercontent.com/8352840/50927784-d1a3da80-1426-11e9-9b01-fef15bdf2e2d.png"">. I could not find documentation on the `to_df` method in the documents.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/417
https://github.com/scverse/scanpy/issues/417:425,usability,document,documents,425,"to_df method does not appear to be working correctly; I'm trying to export a Pandas DataFrame from the adata object using the example notebook pbmc3k and I'm getting a weird result shown below: . <img width=""1079"" alt=""screen shot 2019-01-09 at 3 52 51 pm"" src=""https://user-images.githubusercontent.com/8352840/50927784-d1a3da80-1426-11e9-9b01-fef15bdf2e2d.png"">. I could not find documentation on the `to_df` method in the documents.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/417
https://github.com/scverse/scanpy/issues/418:104,deployability,version,version,104,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:104,integrability,version,version,104,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1283,integrability,translat,translate,1283,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1037,interoperability,specif,specific,1037," fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1283,interoperability,translat,translate,1283,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:104,modifiability,version,version,104,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:896,modifiability,exten,extended,896,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1735,modifiability,exten,extending,1735,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1262,reliability,doe,does,1262,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1445,safety,test,test,1445,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1619,safety,test,test,1619,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:981,testability,simpl,simply,981,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1445,testability,test,test,1445,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1619,testability,test,test,1619,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:79,usability,workflow,workflow,79,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:237,usability,help,help,237,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:696,usability,help,help,696,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:731,usability,behavi,behavior,731,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:981,usability,simpl,simply,981,"Plotting ax and figure manipulation, e.g. fig.tight_layout() and other related workflow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1082,usability,user,users,1082,"ow issues.; scanpy version 1.3.7. NOTE!: During typing this issue out i figured out how to solve it and save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1299,usability,workflow,workflow,1299,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1465,usability,command,command,1465,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1633,usability,user,user-images,1633,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1828,usability,clear,clear,1828,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/418:1964,usability,interact,interactive,1964,"d save figures with all elements showing with the help of . `fig1.savefig(""name.svg"" bbox_inches='tight')`, which solves 90% of the issue I had. I also noticed that these functions have a built in save function where I found the answer. I added a question at the bottom which is still of interest to me. However, feel free to rank this as non essential. --------------------------------------. First of all, the new figure plotting functions looks amazing. I just have a few issues that I hope I can get some help with. I seem to often get the behavior of figures from scanpy after I plot that the elements like xtick labels and other important features are hidden due to figure boarders or that boarders are extended far beyond the plotting are. Due to the way the axes is constructed I can't simply do a fig.tight_layout(). Even with the grid_spec specific tight_layout https://matplotlib.org/users/tight_layout_guide.html#use-with-gridspec I get the same result. I get the sense that the figures looks ok in a notebook, perhaps, where these elements can be seen, but that does unfortunate not translate to my workflow of manually saving figures and plotting with qt or tk backends to be able to get a quick overview. Below is an example of a fig.savefig(""test.png""). for the command. ```. sc.pl.matrixplot(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True). ```. ![test](https://user-images.githubusercontent.com/715716/50937406-77644300-1441-11e9-8713-8bebdf94c26b.png). The over extending bounders can't be seen here due to the white background but the missing x-tics are clear. (Note I realized how to at least save figures with a 'tight' bounding box so that issue is solved.). Q: Is it possible to get an interactive figure (as in plotting with qt or tk) where elements are visible as with fig.tight_layout() for ordinary axes using your plotting functions? @fidelram tagging you here as I assume you might be able to know this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418
https://github.com/scverse/scanpy/issues/419:701,availability,state,state,701,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:69,deployability,version,version,69,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:69,integrability,version,version,69,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:701,integrability,state,state,701,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:143,interoperability,Specif,Specifically,143,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:767,interoperability,specif,specific,767,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:69,modifiability,version,version,69,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:574,modifiability,variab,variable,574,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:753,modifiability,pac,packages,753,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:113,reliability,doe,does,113,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:182,reliability,doe,does,182,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:238,reliability,doe,does,238,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/419:728,usability,behavi,behavior,728,"All plotting functions could return an ax and/or fig handle.; scanpy version 1.3.7,. I noticed that some figures does not return an ax handle. Specifically rank_genes_groups_heatmap does not return an axis becouse _rank_genes_groups_plot does not return an axis from the matrix plot. Only tracksplot and stacked_violin seems to return an axis in [_rank_genes_groups_plot](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L258). Also I'm wondering why not all plotting functions return an axes handle (list) always. It's easy to capture in a variable if not wished to print to screen and easier to keep track of than having to both capture and determine the show=False state, and it would mirror behavior of other figure packages. Any specific reason you do not do this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419
https://github.com/scverse/scanpy/issues/420:32,availability,cluster,clusters,32,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:366,availability,cluster,clusters,366,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:417,availability,cluster,clusters,417,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:32,deployability,cluster,clusters,32,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:366,deployability,cluster,clusters,366,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:417,deployability,cluster,clusters,417,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:0,interoperability,Mismatch,Mismatching,0,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:441,performance,time,time,441,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:70,usability,command,command,70,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:103,usability,tool,tools,103,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:182,usability,tool,tools,182,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/420:456,usability,command,command,456,"Mismatching between colours and clusters in Leiden; Hi,. when I run a command like this. ```python. sc.tools.leiden.leiden(all_data, resolution=0.35, use_weights=True ). sc.plotting.tools.scatterplots.umap(all_data, color=['leiden']). ```. trying out different resolution, the vector `all_data.uns['leiden_colors']` happens to have a number of colors for the Leiden clusters that is not matching the number of Leiden clusters found the last time I ran the command above. Maybe the function that append the color vector to the annData object could be changed so that it checks if the vector of colors already exists, and overwrite it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420
https://github.com/scverse/scanpy/issues/421:359,availability,error,error,359,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/421:138,deployability,Contain,Container,138,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/421:359,performance,error,error,359,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/421:359,safety,error,error,359,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/421:0,usability,Behavi,Behaviour,0,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/421:82,usability,document,documentation,82,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/421:101,usability,document,documentation,101,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/421:359,usability,error,error,359,"Behaviour of `percent_top=None or []` in `calculate_qc_metrics()` inconsistent to documentation; The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)). > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421
https://github.com/scverse/scanpy/issues/422:721,deployability,modul,module,721,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1267,deployability,log,log,1267,"endrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:0,energy efficiency,heat,heatmap,0,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:125,energy efficiency,heat,heatmap,125,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:430,energy efficiency,heat,heatmap,430,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:812,energy efficiency,heat,heatmap,812,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:991,energy efficiency,heat,heatmap,991,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1223,energy efficiency,heat,heatmap,1223," component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(tic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1640,energy efficiency,heat,heatmap,1640,"ErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:228,integrability,compon,component,228,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:295,integrability,compon,component,295,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:228,interoperability,compon,component,228,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:295,interoperability,compon,component,295,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:2625,interoperability,format,format,2625,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:228,modifiability,compon,component,228,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:295,modifiability,compon,component,295,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:721,modifiability,modul,module,721,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1184,modifiability,pac,packages,1184," note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1359,modifiability,layer,layer,1359,"genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1770,modifiability,pac,packages,1770,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:2116,modifiability,pac,packages,2116,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:2576,performance,time,time,2576,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:693,safety,input,input-,693,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:721,safety,modul,module,721,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1267,safety,log,log,1267,"endrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1267,security,log,log,1267,"endrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:2042,security,rotat,rotate,2042,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:2060,security,rotat,rotation,2060,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:2317,security,rotat,rotate,2317,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:2335,security,rotat,rotation,2335,"last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. TypeError: object of type 'int' has no len(). ```. It seems like the function `_plot_categories_as_colorblocks` expects the len function to be applied to each category to be able to place it properly. However my categories are time stamps and therefore I have them in integer format. Changing to str categorical fixes the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:624,testability,trace,traceback,624,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:1267,testability,log,log,1267,"endrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < 3:. 2385 # if the labels are small do not rotate them. 2386 rotation = 0. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in <listcomp>(.0). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:100,usability,visual,visualize,100,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/issues/422:693,usability,input,input-,693,"heatmap plot can't handle groupby integer categoricals; scanpy.__version__ : '1.3.7'. I'm trying to visualize my data with a heatmap and ran in to the following issue (title) and thought I note it,. The code I try to run:. ```. component = [0,1,2,3,4,5,6]. topg = 30. dendrogram=False. for c in component:. sort_idcs = np.argsort(adata.varm['PCs'][:, c])[::-1]. genes_ranked_by_loading_in_PC = adata.var_names[sort_idcs]. . sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). fig = plt.gcf(). ```. and I get the flollowing traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-641-33e0c59aae76> in <module>. 10 cells_ranked_by_loading_in_PC = adata.obs_names[sort_cell]. 11 . ---> 12 sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). 13 fig1 = plt.gcf(). 14 # sc.pl.heatmap(adata, var_names=genes_ranked_by_loading_in_PC[:topg], groupby='louvain', use_raw=None, cmap='RdBu_r', swap_axes=True, dendrogram=dendrogram). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show_gene_labels, show, save, figsize, **kwds). 1274 groupby_ax = fig.add_subplot(axs[2, 0]). 1275 ticks, labels, groupby_cmap = _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors=groupby_colors,. -> 1276 orientation='bottom'). 1277 # add lines to main heatmap. 1278 line_positions = np.cumsum(obs_tidy.index.value_counts(sort=False))[:-1]. ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name). 2382 if len(labels) > 1:. 2383 groupby_ax.set_xticks(ticks). -> 2384 if max([len(x) for x in labels]) < ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422
https://github.com/scverse/scanpy/pull/423:32,deployability,API,API,32,"Add .readwrite.write to the new API; I'm not sure if `sc.write` is forgotten or left out on purpose. Leaving it out make sense as it only offers `sc.write('file.csv', adata)` over `adata.write()`. Alternatively, extending `sc.write` functionality to loom and zarr and keeping it in the new API might make it more useful. I was using it just to make the code more symmetric :) i.e. `sc.read` and `sc.write`, but I don't mind if it's removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423
https://github.com/scverse/scanpy/pull/423:290,deployability,API,API,290,"Add .readwrite.write to the new API; I'm not sure if `sc.write` is forgotten or left out on purpose. Leaving it out make sense as it only offers `sc.write('file.csv', adata)` over `adata.write()`. Alternatively, extending `sc.write` functionality to loom and zarr and keeping it in the new API might make it more useful. I was using it just to make the code more symmetric :) i.e. `sc.read` and `sc.write`, but I don't mind if it's removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423
https://github.com/scverse/scanpy/pull/423:32,integrability,API,API,32,"Add .readwrite.write to the new API; I'm not sure if `sc.write` is forgotten or left out on purpose. Leaving it out make sense as it only offers `sc.write('file.csv', adata)` over `adata.write()`. Alternatively, extending `sc.write` functionality to loom and zarr and keeping it in the new API might make it more useful. I was using it just to make the code more symmetric :) i.e. `sc.read` and `sc.write`, but I don't mind if it's removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423
https://github.com/scverse/scanpy/pull/423:290,integrability,API,API,290,"Add .readwrite.write to the new API; I'm not sure if `sc.write` is forgotten or left out on purpose. Leaving it out make sense as it only offers `sc.write('file.csv', adata)` over `adata.write()`. Alternatively, extending `sc.write` functionality to loom and zarr and keeping it in the new API might make it more useful. I was using it just to make the code more symmetric :) i.e. `sc.read` and `sc.write`, but I don't mind if it's removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423
https://github.com/scverse/scanpy/pull/423:32,interoperability,API,API,32,"Add .readwrite.write to the new API; I'm not sure if `sc.write` is forgotten or left out on purpose. Leaving it out make sense as it only offers `sc.write('file.csv', adata)` over `adata.write()`. Alternatively, extending `sc.write` functionality to loom and zarr and keeping it in the new API might make it more useful. I was using it just to make the code more symmetric :) i.e. `sc.read` and `sc.write`, but I don't mind if it's removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423
https://github.com/scverse/scanpy/pull/423:290,interoperability,API,API,290,"Add .readwrite.write to the new API; I'm not sure if `sc.write` is forgotten or left out on purpose. Leaving it out make sense as it only offers `sc.write('file.csv', adata)` over `adata.write()`. Alternatively, extending `sc.write` functionality to loom and zarr and keeping it in the new API might make it more useful. I was using it just to make the code more symmetric :) i.e. `sc.read` and `sc.write`, but I don't mind if it's removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423
https://github.com/scverse/scanpy/pull/423:212,modifiability,exten,extending,212,"Add .readwrite.write to the new API; I'm not sure if `sc.write` is forgotten or left out on purpose. Leaving it out make sense as it only offers `sc.write('file.csv', adata)` over `adata.write()`. Alternatively, extending `sc.write` functionality to loom and zarr and keeping it in the new API might make it more useful. I was using it just to make the code more symmetric :) i.e. `sc.read` and `sc.write`, but I don't mind if it's removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423
https://github.com/scverse/scanpy/pull/425:120,availability,cluster,clustering,120,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:482,availability,cluster,clustering,482,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:120,deployability,cluster,clustering,120,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:482,deployability,cluster,clustering,482,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:42,integrability,filter,filtering,42,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:830,integrability,filter,filter,830,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:1160,integrability,filter,filtering,1160,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:342,usability,user,user-images,342,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:542,usability,visual,visualization,542,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:709,usability,user,user-images,709,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/pull/425:1028,usability,user,user-images,1028,"dendrograms, correlation and marker genes filtering; This PR makes more transparent the computation of the hierarchical clustering underlying the dendrograms. Now, by default, the dendrograms are computed based on the PCA using `sc.tl.dendrogram`. Also, now is possible to directly plot a dendrogram without any other data:. ![image](https://user-images.githubusercontent.com/4964309/51113629-e3102c80-1802-11e9-918f-8869e88a5e0e.png). Since for the computation of the hierarchical clustering, a correlation matrix is computed I also added a visualization for this (mostly borrowing code from https://github.com/deeptools/deepTools). The new plotting function is called `sc.pl.correlation` . ![image](https://user-images.githubusercontent.com/4964309/51113718-49954a80-1803-11e9-9d6b-ab3261118250.png). Also I added a function to filter the results from `sc.tl.rank_genes_groups` based on fold change and fraction of genes that are expressing the gene within and outside the group by categories. For example, . ![image](https://user-images.githubusercontent.com/4964309/51114075-7e55d180-1804-11e9-8e16-49ce3dc8477e.png). The first image show the case without filtering.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425
https://github.com/scverse/scanpy/issues/426:63,modifiability,pac,package,63,"Save a matrix in an annData object; Hi. I am trying to use the package MAGIC-IMPUTE on the annData object on which I am working with scanpy. I do something of this type. ```python. import magic. magic_op = magic.MAGIC(). all_data.magic = magic_op.fit_transform(all_data, genes='all_genes'). ```. I then save the annData object on my hard drive to reopen it in another python notebook. But when I read the h5ad file, I cannot anymore find all_data.magic. Am I doing something wrong? Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/426
https://github.com/scverse/scanpy/pull/427:85,safety,valid,valid,85,"fix docstring neighbors; the docstring mentioned ``method=='gauss'``, which is not a valid option.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/427
https://github.com/scverse/scanpy/issues/428:785,availability,down,download,785,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:316,deployability,api,api,316,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:316,integrability,api,api,316,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:162,interoperability,standard,standard,162,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:316,interoperability,api,api,316,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:98,reliability,doe,does,98,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:217,safety,test,testing,217,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:217,testability,test,testing,217,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/428:225,usability,visual,visualization,225,"pbmc3k dataset has NaNs for gene_ids; Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python. In [1]: import scanpy.api as sc . ...: sc.datasets.pbmc3k().var.head() . Out[1]: . gene_ids. index . MIR1302-10 NaN. FAM138A NaN. OR4F5 NaN. RP11-34P13.7 NaN. RP11-34P13.8 NaN. In [2]: import h5py . ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: . ...: print(repr(f[""var""][:])) . ...: . array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,. (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],. dtype=[('index', 'S19'), ('gene_ids', 'i1')]). ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz . ... In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz. ... In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() . Out[5]: . gene_ids. MIR1302-10 ENSG00000243485. FAM138A ENSG00000237613. OR4F5 ENSG00000186092. RP11-34P13.7 ENSG00000238009. RP11-34P13.8 ENSG00000239945. ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428
https://github.com/scverse/scanpy/issues/429:349,integrability,filter,filtering,349,"counts_per_cell has no effect on pp.normalize_per_cell(adata); `counts_per_cell` has no effect on `pp.normalize_per_cell(adata)` as it is overwritten here:. https://github.com/theislab/scanpy/blob/e0d2ea60fa2394f1158618bc69dff4fc639b51c4/scanpy/preprocessing/_simple.py#L599. Would be great if one could use, e.g. the initial cell size (from before filtering). Note, that this issue only holds when passing `AnnData`. With `AnnData.X` it works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429
https://github.com/scverse/scanpy/pull/430:358,energy efficiency,Current,Currently,358,"Add `gene_symbols` argument to scatter plots; Added a `gene_symbols` argument to the scatter plot functions so indices can be standardized and unique while plots have interpretable titles. Usage:. ```python. sc.pl.umap(adata, colors=[""Sox2""], gene_symbols=""name""). ```. One question I have: should the user be allowed to pass both gene ids and gene symbols? Currently this is not allowed, but easily could be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/430
https://github.com/scverse/scanpy/pull/430:126,integrability,standardiz,standardized,126,"Add `gene_symbols` argument to scatter plots; Added a `gene_symbols` argument to the scatter plot functions so indices can be standardized and unique while plots have interpretable titles. Usage:. ```python. sc.pl.umap(adata, colors=[""Sox2""], gene_symbols=""name""). ```. One question I have: should the user be allowed to pass both gene ids and gene symbols? Currently this is not allowed, but easily could be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/430
https://github.com/scverse/scanpy/pull/430:126,interoperability,standard,standardized,126,"Add `gene_symbols` argument to scatter plots; Added a `gene_symbols` argument to the scatter plot functions so indices can be standardized and unique while plots have interpretable titles. Usage:. ```python. sc.pl.umap(adata, colors=[""Sox2""], gene_symbols=""name""). ```. One question I have: should the user be allowed to pass both gene ids and gene symbols? Currently this is not allowed, but easily could be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/430
https://github.com/scverse/scanpy/pull/430:302,usability,user,user,302,"Add `gene_symbols` argument to scatter plots; Added a `gene_symbols` argument to the scatter plot functions so indices can be standardized and unique while plots have interpretable titles. Usage:. ```python. sc.pl.umap(adata, colors=[""Sox2""], gene_symbols=""name""). ```. One question I have: should the user be allowed to pass both gene ids and gene symbols? Currently this is not allowed, but easily could be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/430
https://github.com/scverse/scanpy/issues/431:0,availability,Error,Error,0,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:64,availability,error,error,64,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:145,availability,error,error,145,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:27,integrability,compon,components,27,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:87,integrability,compon,components,87,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:27,interoperability,compon,components,27,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:87,interoperability,compon,components,87,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:27,modifiability,compon,components,27,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:87,modifiability,compon,components,87,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:0,performance,Error,Error,0,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:64,performance,error,error,64,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:145,performance,error,error,145,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:0,safety,Error,Error,0,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:64,safety,error,error,64,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:145,safety,error,error,145,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:0,usability,Error,Error,0,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:64,usability,error,error,64,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/431:145,usability,error,error,145,"Error in pca_loadings when components > 5; Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431
https://github.com/scverse/scanpy/issues/432:135,availability,error,error,135,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:7,deployability,api,api,7,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:334,deployability,modul,module,334,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1689,deployability,Integr,Integral,1689,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:7,integrability,api,api,7,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1689,integrability,Integr,Integral,1689,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:7,interoperability,api,api,7,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1689,interoperability,Integr,Integral,1689,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:334,modifiability,modul,module,334,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:409,modifiability,pac,packages,409,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:842,modifiability,pac,packages,842,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:859,modifiability,deco,decomposition,859,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1040,modifiability,pac,packages,1040,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1057,modifiability,deco,decomposition,1057,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1417,modifiability,pac,packages,1417,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1434,modifiability,deco,decomposition,1434,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1689,modifiability,Integr,Integral,1689,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:135,performance,error,error,135,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1689,reliability,Integr,Integral,1689,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:135,safety,error,error,135,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:306,safety,input,input-,306,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:334,safety,modul,module,334,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1689,security,Integr,Integral,1689,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:439,testability,simpl,simple,439,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:1689,testability,Integr,Integral,1689,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:135,usability,error,error,135,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:306,usability,input,input-,306,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/432:439,usability,simpl,simple,439,"scanpy.api.tl.pca compensate for few genes < 50 but not few cells.; Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb. ValueErrorTraceback (most recent call last). <ipython-input-823-4c11b9b62e6d> in <module>. ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 505 X = adata_comp.X. --> 506 X_pca = pca_.fit_transform(X). 507 . 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 357 . 358 """""". --> 359 U, S, V = self._fit(X). 360 U = U[:, :self.n_components_]. 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 404 # Call different fits for either full or truncated SVD. 405 if self._fit_svd_solver == 'full':. --> 406 return self._fit_full(X, n_components). 407 elif self._fit_svd_solver in ['arpack', 'randomized']:. 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components). 423 ""min(n_samples, n_features)=%r with "". 424 ""svd_solver='full'"". --> 425 % (n_components, min(n_samples, n_features))). 426 elif n_components >= 1:. 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432
https://github.com/scverse/scanpy/issues/434:38,energy efficiency,reduc,reduce,38,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:225,energy efficiency,measur,measuring,225,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:412,energy efficiency,current,current,412,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:450,modifiability,pac,package,450,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:45,performance,memor,memory,45,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:196,performance,memor,memory,196,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:235,performance,memor,memory,235,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:263,performance,time,time,263,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:29,reliability,doe,does,29,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:106,safety,test,test,106,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:155,safety,test,test,155,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:106,testability,test,test,106,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:155,testability,test,test,155,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:45,usability,memor,memory,45,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:196,usability,memor,memory,196,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/434:235,usability,memor,memory,235,"Reading h5ad with backed='r' does not reduce memory usage; Whether I read the data as:. `adata = sc.read('test.h5ad', backed='r')`. or:. `adata = sc.read('test.h5ad', backed='r+')`. The amount of memory used is the same (I'm measuring memory usage with `/usr/bin/time -v` and looking at `Maximum resident set size`). In my particular case, I have a very large data set and I'm only interested in `adata.obs`. My current solution is to use the `h5py` package and read only the `obs` group from the `h5ad` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434
https://github.com/scverse/scanpy/issues/435:326,availability,error,error,326,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:603,availability,error,error,603,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:1019,availability,down,download,1019,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:87,modifiability,paramet,parameter,87,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:422,modifiability,paramet,parameter,422,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:326,performance,error,error,326,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:603,performance,error,error,603,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:733,reliability,doe,does,733,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:326,safety,error,error,326,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:603,safety,error,error,603,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:326,usability,error,error,326,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:603,usability,error,error,603,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/435:1079,usability,help,help,1079,"TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'). TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File. x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData. file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'. exec(open(wget.download(file_url)).read()). adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435
https://github.com/scverse/scanpy/issues/436:467,deployability,version,version,467,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/436:467,integrability,version,version,467,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/436:414,interoperability,distribut,distributions,414,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/436:467,modifiability,version,version,467,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/436:157,safety,test,test,157,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/436:482,safety,test,test,482,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/436:157,testability,test,test,157,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/436:482,testability,test,test,482,"Information about scores; Hello, I would like to know how the scores are calculated in the case of the differential expression analysis using the wilcoxon's test. This is what I found in the code of the function _rank_genes_groups.py:. `scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). scores[np.isnan(scores)] = 0. pvals = 2 * stats.distributions.norm.sf(np.abs(scores))` . Is this the version of the test that works with not paired samples? Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/436
https://github.com/scverse/scanpy/issues/437:536,deployability,api,api,536,"Edit on GitHub links are broken; Hi @flying-sheep,. it seems that the links broke in the course of the change to `scanpydoc`. Currently, what should resolve as. ```. https://github.com/theislab/scanpy/blob/master/scanpy/tools/_paga.py#L13-L108. ```. resolves as. ```. https://github.com/theislab/scanpy/tree/master/tools/__init__.py#L13-L108. ```. It's evidently just missing the `scanpy/` subdirectory and the fact that it shouldn't point to `__init__.py`. I'm getting this from the [paga docs](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.paga.html). It would be terrific if you could make this work again: I suspect it's a small change for you...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437
https://github.com/scverse/scanpy/issues/437:126,energy efficiency,Current,Currently,126,"Edit on GitHub links are broken; Hi @flying-sheep,. it seems that the links broke in the course of the change to `scanpydoc`. Currently, what should resolve as. ```. https://github.com/theislab/scanpy/blob/master/scanpy/tools/_paga.py#L13-L108. ```. resolves as. ```. https://github.com/theislab/scanpy/tree/master/tools/__init__.py#L13-L108. ```. It's evidently just missing the `scanpy/` subdirectory and the fact that it shouldn't point to `__init__.py`. I'm getting this from the [paga docs](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.paga.html). It would be terrific if you could make this work again: I suspect it's a small change for you...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437
https://github.com/scverse/scanpy/issues/437:390,integrability,sub,subdirectory,390,"Edit on GitHub links are broken; Hi @flying-sheep,. it seems that the links broke in the course of the change to `scanpydoc`. Currently, what should resolve as. ```. https://github.com/theislab/scanpy/blob/master/scanpy/tools/_paga.py#L13-L108. ```. resolves as. ```. https://github.com/theislab/scanpy/tree/master/tools/__init__.py#L13-L108. ```. It's evidently just missing the `scanpy/` subdirectory and the fact that it shouldn't point to `__init__.py`. I'm getting this from the [paga docs](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.paga.html). It would be terrific if you could make this work again: I suspect it's a small change for you...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437
https://github.com/scverse/scanpy/issues/437:536,integrability,api,api,536,"Edit on GitHub links are broken; Hi @flying-sheep,. it seems that the links broke in the course of the change to `scanpydoc`. Currently, what should resolve as. ```. https://github.com/theislab/scanpy/blob/master/scanpy/tools/_paga.py#L13-L108. ```. resolves as. ```. https://github.com/theislab/scanpy/tree/master/tools/__init__.py#L13-L108. ```. It's evidently just missing the `scanpy/` subdirectory and the fact that it shouldn't point to `__init__.py`. I'm getting this from the [paga docs](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.paga.html). It would be terrific if you could make this work again: I suspect it's a small change for you...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437
https://github.com/scverse/scanpy/issues/437:536,interoperability,api,api,536,"Edit on GitHub links are broken; Hi @flying-sheep,. it seems that the links broke in the course of the change to `scanpydoc`. Currently, what should resolve as. ```. https://github.com/theislab/scanpy/blob/master/scanpy/tools/_paga.py#L13-L108. ```. resolves as. ```. https://github.com/theislab/scanpy/tree/master/tools/__init__.py#L13-L108. ```. It's evidently just missing the `scanpy/` subdirectory and the fact that it shouldn't point to `__init__.py`. I'm getting this from the [paga docs](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.paga.html). It would be terrific if you could make this work again: I suspect it's a small change for you...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437
https://github.com/scverse/scanpy/issues/437:220,usability,tool,tools,220,"Edit on GitHub links are broken; Hi @flying-sheep,. it seems that the links broke in the course of the change to `scanpydoc`. Currently, what should resolve as. ```. https://github.com/theislab/scanpy/blob/master/scanpy/tools/_paga.py#L13-L108. ```. resolves as. ```. https://github.com/theislab/scanpy/tree/master/tools/__init__.py#L13-L108. ```. It's evidently just missing the `scanpy/` subdirectory and the fact that it shouldn't point to `__init__.py`. I'm getting this from the [paga docs](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.paga.html). It would be terrific if you could make this work again: I suspect it's a small change for you...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437
https://github.com/scverse/scanpy/issues/437:315,usability,tool,tools,315,"Edit on GitHub links are broken; Hi @flying-sheep,. it seems that the links broke in the course of the change to `scanpydoc`. Currently, what should resolve as. ```. https://github.com/theislab/scanpy/blob/master/scanpy/tools/_paga.py#L13-L108. ```. resolves as. ```. https://github.com/theislab/scanpy/tree/master/tools/__init__.py#L13-L108. ```. It's evidently just missing the `scanpy/` subdirectory and the fact that it shouldn't point to `__init__.py`. I'm getting this from the [paga docs](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.paga.html). It would be terrific if you could make this work again: I suspect it's a small change for you...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437
https://github.com/scverse/scanpy/issues/438:472,availability,error,error,472,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:608,availability,error,error,608,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1652,availability,error,error,1652,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1422,deployability,contain,contain,1422,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1438,deployability,observ,observation,1438,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:572,energy efficiency,heat,heatmap,572,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:242,integrability,batch,batch,242,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:415,integrability,batch,batch,415,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:49,modifiability,layer,layers,49,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:268,modifiability,layer,layer,268,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1450,modifiability,variab,variables,1450,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:242,performance,batch,batch,242,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:415,performance,batch,batch,415,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:472,performance,error,error,472,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:608,performance,error,error,608,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1652,performance,error,error,1652,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:472,safety,error,error,472,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:608,safety,error,error,608,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1652,safety,error,error,1652,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1438,testability,observ,observation,1438,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:158,usability,tool,tools,158,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:331,usability,tool,tools,331,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:472,usability,error,error,472,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:524,usability,command,commands,524,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:608,usability,error,error,608,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:824,usability,TIP,TIPARP-,824,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/issues/438:1652,usability,error,error,1652,"Plot of ranked genes groups with non-raw data or layers; Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') . ```. or from non-raw data. ```. sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) . ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:. ```. KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'. ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438
https://github.com/scverse/scanpy/pull/439:306,deployability,releas,released,306,"Use np.asarray() rather than Zappy-specific code.; This uses the `__array__` method on ndarray-like classes to convert from. a distributed array to a regular NumPy ndarray when `materialize_as_ndarray` is called. This was prompted by an [improvement in Zappy](https://github.com/lasersonlab/zappy/pull/7) (released in 0.2.0) that makes Zappy arrays implement the `__array__` method. As another benefit, this change should make it easier to use other implementations of the ndarray interface in Scanpy in the future. Note that there is still a Dask-specific call for the case of a sequence of arrays, since Dask can materialize these in one call to `compute`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439
https://github.com/scverse/scanpy/pull/439:481,integrability,interfac,interface,481,"Use np.asarray() rather than Zappy-specific code.; This uses the `__array__` method on ndarray-like classes to convert from. a distributed array to a regular NumPy ndarray when `materialize_as_ndarray` is called. This was prompted by an [improvement in Zappy](https://github.com/lasersonlab/zappy/pull/7) (released in 0.2.0) that makes Zappy arrays implement the `__array__` method. As another benefit, this change should make it easier to use other implementations of the ndarray interface in Scanpy in the future. Note that there is still a Dask-specific call for the case of a sequence of arrays, since Dask can materialize these in one call to `compute`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439
https://github.com/scverse/scanpy/pull/439:35,interoperability,specif,specific,35,"Use np.asarray() rather than Zappy-specific code.; This uses the `__array__` method on ndarray-like classes to convert from. a distributed array to a regular NumPy ndarray when `materialize_as_ndarray` is called. This was prompted by an [improvement in Zappy](https://github.com/lasersonlab/zappy/pull/7) (released in 0.2.0) that makes Zappy arrays implement the `__array__` method. As another benefit, this change should make it easier to use other implementations of the ndarray interface in Scanpy in the future. Note that there is still a Dask-specific call for the case of a sequence of arrays, since Dask can materialize these in one call to `compute`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439
https://github.com/scverse/scanpy/pull/439:127,interoperability,distribut,distributed,127,"Use np.asarray() rather than Zappy-specific code.; This uses the `__array__` method on ndarray-like classes to convert from. a distributed array to a regular NumPy ndarray when `materialize_as_ndarray` is called. This was prompted by an [improvement in Zappy](https://github.com/lasersonlab/zappy/pull/7) (released in 0.2.0) that makes Zappy arrays implement the `__array__` method. As another benefit, this change should make it easier to use other implementations of the ndarray interface in Scanpy in the future. Note that there is still a Dask-specific call for the case of a sequence of arrays, since Dask can materialize these in one call to `compute`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439
https://github.com/scverse/scanpy/pull/439:481,interoperability,interfac,interface,481,"Use np.asarray() rather than Zappy-specific code.; This uses the `__array__` method on ndarray-like classes to convert from. a distributed array to a regular NumPy ndarray when `materialize_as_ndarray` is called. This was prompted by an [improvement in Zappy](https://github.com/lasersonlab/zappy/pull/7) (released in 0.2.0) that makes Zappy arrays implement the `__array__` method. As another benefit, this change should make it easier to use other implementations of the ndarray interface in Scanpy in the future. Note that there is still a Dask-specific call for the case of a sequence of arrays, since Dask can materialize these in one call to `compute`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439
https://github.com/scverse/scanpy/pull/439:548,interoperability,specif,specific,548,"Use np.asarray() rather than Zappy-specific code.; This uses the `__array__` method on ndarray-like classes to convert from. a distributed array to a regular NumPy ndarray when `materialize_as_ndarray` is called. This was prompted by an [improvement in Zappy](https://github.com/lasersonlab/zappy/pull/7) (released in 0.2.0) that makes Zappy arrays implement the `__array__` method. As another benefit, this change should make it easier to use other implementations of the ndarray interface in Scanpy in the future. Note that there is still a Dask-specific call for the case of a sequence of arrays, since Dask can materialize these in one call to `compute`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439
https://github.com/scverse/scanpy/pull/439:481,modifiability,interfac,interface,481,"Use np.asarray() rather than Zappy-specific code.; This uses the `__array__` method on ndarray-like classes to convert from. a distributed array to a regular NumPy ndarray when `materialize_as_ndarray` is called. This was prompted by an [improvement in Zappy](https://github.com/lasersonlab/zappy/pull/7) (released in 0.2.0) that makes Zappy arrays implement the `__array__` method. As another benefit, this change should make it easier to use other implementations of the ndarray interface in Scanpy in the future. Note that there is still a Dask-specific call for the case of a sequence of arrays, since Dask can materialize these in one call to `compute`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439
https://github.com/scverse/scanpy/issues/440:444,availability,error,error,444,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:17,deployability,fail,fails,17,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:692,deployability,modul,module,692,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:450,integrability,messag,message,450,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1363,integrability,compon,components,1363,"map(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1812,integrability,wrap,wrapper,1812,"scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only work",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1868,integrability,wrap,wrapper,1868,"=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:450,interoperability,messag,message,450,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1363,interoperability,compon,components,1363,"map(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1812,interoperability,wrapper,wrapper,1812,"scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only work",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1868,interoperability,wrapper,wrapper,1868,"=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2747,interoperability,incompatib,incompatible,2747,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2913,interoperability,format,format,2913,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:491,modifiability,pac,package,491,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:692,modifiability,modul,module,692,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:945,modifiability,pac,packages,945,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1196,modifiability,pac,packages,1196,"o UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1363,modifiability,compon,components,1363,"map(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1922,modifiability,pac,packages,1922,"lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2169,modifiability,pac,packages,2169,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2382,modifiability,pac,packages,2382,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:255,performance,memor,memory,255,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:444,performance,error,error,444,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1991,performance,Perform,Perform,1991,"umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2449,performance,Perform,Perform,2449,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2985,performance,memor,memory,2985,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:17,reliability,fail,fails,17,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:444,safety,error,error,444,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:666,safety,input,input-,666,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:692,safety,modul,module,692,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:518,testability,trace,trace,518,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:622,testability,Trace,Traceback,622,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:255,usability,memor,memory,255,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:348,usability,tool,tools,348,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:444,usability,error,error,444,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:666,usability,input,input-,666,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:810,usability,tool,tools,810,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:970,usability,tool,tools,970,"UMAP scatterplot fails with backed data; Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1221,usability,tool,tools,1221,"out any problem apart from the memory usage. But now that the data is backed, when running the following:. ```. sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-a78575d924b7> in <module>. 24 if len(markers) > 0:. 25 print(""Expression plots of "", names, "" markers: "", markers). ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5). 27 . 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:1991,usability,Perform,Perform,1991,"umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2449,usability,Perform,Perform,2449,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/issues/440:2985,usability,memor,memory,2985,"(adata, basis='umap', **kwargs). 30 . 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 280 if sort_order is True and value_to_plot is not None and categorical is False:. 281 order = np.argsort(color_vector). --> 282 color_vector = color_vector[order]. 283 _data_points = data_points[component_idx][order, :]. 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args). 474 . 475 # Perform the dataspace selection. --> 476 selection = sel.select(self.shape, args, dsid=self.id). 477 . 478 if selection.nselect == 0:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in select(shape, args, dsid). 70 elif isinstance(arg, np.ndarray):. 71 sel = PointSelection(shape). ---> 72 sel[arg]. 73 return sel. 74 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/selections.py in __getitem__(self, arg). 210 """""" Perform point-wise selection from a NumPy boolean array """""". 211 if not (isinstance(arg, np.ndarray) and arg.dtype.kind == 'b'):. --> 212 raise TypeError(""PointSelection __getitem__ only works with bool arrays""). 213 if not arg.shape == self.shape:. 214 raise TypeError(""Boolean indexing array has incompatible shape""). TypeError: PointSelection __getitem__ only works with bool arrays. <Figure size 1978.56x288 with 0 Axes>. ``` . Is it something implicit in the format of the backed file that cannot be solved? Also, do you think the memory usage is due to something else than the data not being backed? It is only 8000 cells and 15000 genes. Cheers,. Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440
https://github.com/scverse/scanpy/pull/441:0,availability,Consist,Consistent,0,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:148,deployability,log,logg,148,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:447,interoperability,semant,semantics,447,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:352,reliability,Doe,Does,352,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:148,safety,log,logg,148,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:473,safety,compl,completely,473,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:148,security,log,logg,148,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:473,security,compl,completely,473,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:148,testability,log,logg,148,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:0,usability,Consist,Consistent,0,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:11,usability,hint,hint,11,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:153,usability,hint,hint,153,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/441:392,usability,document,documentation,392,"Consistent hint for the distance matrix; Define `.uns['neighbors']['distances']` as the distance matrix instead of the weighted adjacency matrix in logg.hint. By the way, when `knn=True`, distances to non-neighbor data points are stored as zero in this matrix to keep it sparse, right? But technically these are not zeros, but rather ""unknown values"". Does it make sense to add a note in the documentation about that? Because for `knn=False`, the semantics of zeros change completely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441
https://github.com/scverse/scanpy/pull/442:690,availability,error,error,690,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:993,deployability,contain,contain,993,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:306,integrability,filter,filter,306,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:493,integrability,filter,filters,493,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:40,interoperability,specif,specify,40,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:276,interoperability,specif,specifying,276,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:674,interoperability,specif,specify,674,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:521,modifiability,variab,variables,521,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:690,performance,error,error,690,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:354,reliability,doe,doesn,354,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:316,safety,input,input,316,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:690,safety,error,error,690,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:107,usability,person,personal,107,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:316,usability,input,input,316,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:414,usability,behavi,behavior,414,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:465,usability,document,documentation,465,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:661,usability,user,user,661,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:690,usability,error,error,690,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:814,usability,behavi,behavior,814,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:945,usability,Person,Personally,945,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/442:1037,usability,feedback,feedback,1037,"Easier 10x reading; Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default. * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442
https://github.com/scverse/scanpy/pull/444:16,availability,error,errors,16,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:118,availability,error,error,118,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:579,availability,Avail,Available,579,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:16,performance,error,errors,16,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:118,performance,error,error,118,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:100,reliability,doe,doesn,100,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:171,reliability,doe,does,171,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:579,reliability,Availab,Available,579,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:954,reliability,doe,does,954,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:16,safety,error,errors,16,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:118,safety,error,error,118,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:252,safety,test,tests,252,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:518,safety,test,tests,518,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:579,safety,Avail,Available,579,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:712,safety,test,tests,712,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:923,safety,Except,Exception,923,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:579,security,Availab,Available,579,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:252,testability,test,tests,252,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:419,testability,Trace,Traceback,419,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:518,testability,test,tests,518,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:712,testability,test,tests,712,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:884,testability,Trace,Traceback,884,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:16,usability,error,errors,16,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:118,usability,error,error,118,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/pull/444:632,usability,behavi,behavior,632,"Better 10x read errors; An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']. ```. Previous behavior:. ```python. In [1]: import scanpy as sc . ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") . ---------------------------------------------------------------------------. NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444
https://github.com/scverse/scanpy/issues/445:1833,availability,sli,sliced,1833," colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:348,deployability,modul,module,348,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:1658,integrability,sub,subset,1658,"text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:348,modifiability,modul,module,348,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:464,modifiability,pac,packages,464,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:1113,modifiability,pac,packages,1113,"tb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:1725,modifiability,pac,packages,1725,"dge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:1985,modifiability,pac,packages,1985,"ze=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 750 shape = (. 751 get_n_items",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:2300,modifiability,pac,packages,2300,"ht, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 750 shape = (. 751 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 752 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 753 ). 754 if np.isscalar(X):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 148 return 1. 149 else:. --> 150 return len(idx). TypeError: object of type 'numpy.int64' has",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:2373,modifiability,layer,layers,2373," node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 750 shape = (. 751 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 752 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 753 ). 754 if np.isscalar(X):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 148 return 1. 149 else:. --> 150 return len(idx). TypeError: object of type 'numpy.int64' has no len(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:2650,modifiability,pac,packages,2650," node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 750 shape = (. 751 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 752 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 753 ). 754 if np.isscalar(X):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 148 return 1. 149 else:. --> 150 return len(idx). TypeError: object of type 'numpy.int64' has no len(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:2908,modifiability,pac,packages,2908," node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 750 shape = (. 751 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 752 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 753 ). 754 if np.isscalar(X):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 148 return 1. 149 else:. --> 150 return len(idx). TypeError: object of type 'numpy.int64' has no len(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:3157,modifiability,pac,packages,3157," node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self). 750 shape = (. 751 get_n_items_idx(self._oidx, self._adata_ref.n_obs),. --> 752 get_n_items_idx(self._vidx, self._adata_ref.n_vars). 753 ). 754 if np.isscalar(X):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l). 148 return 1. 149 else:. --> 150 return len(idx). TypeError: object of type 'numpy.int64' has no len(). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:1833,reliability,sli,sliced,1833," colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1314 . 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx). 662 if not isinstance(X, AnnData):. 663 raise ValueError('`X` has to be an AnnData object.'). --> 664 self._init_as_view(X, oidx, vidx). 665 else:. 666 self._init_as_actual(. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx). 723 self._X = None. 724 else:. --> 725 self._init_X_as_view(). 726 . 727 self._layers = AnnDataLayers(self, adata_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:100,safety,except,exception,100,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:321,safety,input,input-,321,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:348,safety,modul,module,348,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:277,testability,Trace,Traceback,277,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:321,usability,input,input-,321,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:489,usability,tool,tools,489,"Paul15 example broken; I tried to run the paul15 example notebook, but the following cell raised an exception:. ```pytb. >>> sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/445:1138,usability,tool,tools,1138,", color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-20-e7bc8482aee3> in <module>. ----> 1 sc.pl.paga(adata, color=['louvain', 'Hba-a2', 'Elane', 'Irf8']). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 493 single_component=single_component,. 494 arrowsize=arrowsize,. --> 495 pos=pos). 496 if colorbars[icolor]:. 497 bottom = panel_pos[0][0]. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize). 612 adata_gene = adata.raw[:, colors]. 613 else:. --> 614 adata_gene = adata[:, colors]. 615 x_color.append(np.mean(adata_gene.X[subset])). 616 colors = x_color. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index). 1307 def __getitem__(self, index):. 1308 """"""Returns a sliced view of the object."""""". -> 1309 return self._getitem_view(index). 1310 . 1311 def _getitem_view(self, index):. C:\ProgramData\Anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index). 1311 def _getitem_view(self, index):. 1312 oidx, vidx = self._normalize_indices(index). -> 1313 retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445
https://github.com/scverse/scanpy/issues/446:125,deployability,log,logfoldchange,125,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:198,deployability,log,log,198,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:202,deployability,log,log,202,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:412,deployability,log,logfoldchange,412,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:125,safety,log,logfoldchange,125,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:198,safety,log,log,198,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:202,safety,log,log,202,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:412,safety,log,logfoldchange,412,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:125,security,log,logfoldchange,125,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:198,security,log,log,198,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:202,security,log,log,202,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:412,security,log,logfoldchange,412,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:125,testability,log,logfoldchange,125,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:198,testability,log,log,198,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:202,testability,log,log,202,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:412,testability,log,logfoldchange,412,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:0,usability,Document,Documentation,0,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:65,usability,tool,tools,65,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:289,usability,tool,tools,289,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:380,usability,clear,clear,380,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/446:393,usability,document,documentation,393,"Documentation for rank_genes_groups ; Hi, . Thanks for the great tools included in scanpy. . I was searching to see what the logfoldchange numbers in the `rank_genes_groups` are. i.e. is it natural log/log base 10 or log2? The code in https://github.com/theislab/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py shows that it is log2foldchange. . Perhaps this should be made clear in the documentation? Or `logfoldchange` should be chnaged to `log2foldchange`. . Cheers, . S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446
https://github.com/scverse/scanpy/issues/447:310,availability,cluster,clusters,310,"scATACseq; Hi,. Thanks for this amazing package. I have been playing with scanpy on scATACSeq data generated from 10x. And in comparison to the cellranger analysis, I think analysis scanpy does pretty descent job and adds more possibilities. I would like to displays some peaks that are highly present if some clusters using the genome browser which scanpy seem to be able to do ""I think"" ( as shown below). Is it possible to the same thing but with the peak averaged/concatinated for all cells within the same cluster? import matplotlib.pyplot as plt. genes =['chr15:101708546_101718131','chr11:117961932_117970696',. 'chr19:5821847_5852441','chr15:101422873_101429606',. 'chr17:39842811_39849028','chr13:6108971_6109684']. sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]). ![atacseq](https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447
https://github.com/scverse/scanpy/issues/447:511,availability,cluster,cluster,511,"scATACseq; Hi,. Thanks for this amazing package. I have been playing with scanpy on scATACSeq data generated from 10x. And in comparison to the cellranger analysis, I think analysis scanpy does pretty descent job and adds more possibilities. I would like to displays some peaks that are highly present if some clusters using the genome browser which scanpy seem to be able to do ""I think"" ( as shown below). Is it possible to the same thing but with the peak averaged/concatinated for all cells within the same cluster? import matplotlib.pyplot as plt. genes =['chr15:101708546_101718131','chr11:117961932_117970696',. 'chr19:5821847_5852441','chr15:101422873_101429606',. 'chr17:39842811_39849028','chr13:6108971_6109684']. sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]). ![atacseq](https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447
https://github.com/scverse/scanpy/issues/447:310,deployability,cluster,clusters,310,"scATACseq; Hi,. Thanks for this amazing package. I have been playing with scanpy on scATACSeq data generated from 10x. And in comparison to the cellranger analysis, I think analysis scanpy does pretty descent job and adds more possibilities. I would like to displays some peaks that are highly present if some clusters using the genome browser which scanpy seem to be able to do ""I think"" ( as shown below). Is it possible to the same thing but with the peak averaged/concatinated for all cells within the same cluster? import matplotlib.pyplot as plt. genes =['chr15:101708546_101718131','chr11:117961932_117970696',. 'chr19:5821847_5852441','chr15:101422873_101429606',. 'chr17:39842811_39849028','chr13:6108971_6109684']. sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]). ![atacseq](https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447
https://github.com/scverse/scanpy/issues/447:511,deployability,cluster,cluster,511,"scATACseq; Hi,. Thanks for this amazing package. I have been playing with scanpy on scATACSeq data generated from 10x. And in comparison to the cellranger analysis, I think analysis scanpy does pretty descent job and adds more possibilities. I would like to displays some peaks that are highly present if some clusters using the genome browser which scanpy seem to be able to do ""I think"" ( as shown below). Is it possible to the same thing but with the peak averaged/concatinated for all cells within the same cluster? import matplotlib.pyplot as plt. genes =['chr15:101708546_101718131','chr11:117961932_117970696',. 'chr19:5821847_5852441','chr15:101422873_101429606',. 'chr17:39842811_39849028','chr13:6108971_6109684']. sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]). ![atacseq](https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447
https://github.com/scverse/scanpy/issues/447:40,modifiability,pac,package,40,"scATACseq; Hi,. Thanks for this amazing package. I have been playing with scanpy on scATACSeq data generated from 10x. And in comparison to the cellranger analysis, I think analysis scanpy does pretty descent job and adds more possibilities. I would like to displays some peaks that are highly present if some clusters using the genome browser which scanpy seem to be able to do ""I think"" ( as shown below). Is it possible to the same thing but with the peak averaged/concatinated for all cells within the same cluster? import matplotlib.pyplot as plt. genes =['chr15:101708546_101718131','chr11:117961932_117970696',. 'chr19:5821847_5852441','chr15:101422873_101429606',. 'chr17:39842811_39849028','chr13:6108971_6109684']. sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]). ![atacseq](https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447
https://github.com/scverse/scanpy/issues/447:189,reliability,doe,does,189,"scATACseq; Hi,. Thanks for this amazing package. I have been playing with scanpy on scATACSeq data generated from 10x. And in comparison to the cellranger analysis, I think analysis scanpy does pretty descent job and adds more possibilities. I would like to displays some peaks that are highly present if some clusters using the genome browser which scanpy seem to be able to do ""I think"" ( as shown below). Is it possible to the same thing but with the peak averaged/concatinated for all cells within the same cluster? import matplotlib.pyplot as plt. genes =['chr15:101708546_101718131','chr11:117961932_117970696',. 'chr19:5821847_5852441','chr15:101422873_101429606',. 'chr17:39842811_39849028','chr13:6108971_6109684']. sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]). ![atacseq](https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447
https://github.com/scverse/scanpy/issues/447:810,usability,user,user-images,810,"scATACseq; Hi,. Thanks for this amazing package. I have been playing with scanpy on scATACSeq data generated from 10x. And in comparison to the cellranger analysis, I think analysis scanpy does pretty descent job and adds more possibilities. I would like to displays some peaks that are highly present if some clusters using the genome browser which scanpy seem to be able to do ""I think"" ( as shown below). Is it possible to the same thing but with the peak averaged/concatinated for all cells within the same cluster? import matplotlib.pyplot as plt. genes =['chr15:101708546_101718131','chr11:117961932_117970696',. 'chr19:5821847_5852441','chr15:101422873_101429606',. 'chr17:39842811_39849028','chr13:6108971_6109684']. sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]). ![atacseq](https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447
https://github.com/scverse/scanpy/issues/448:77,energy efficiency,current,current,77,"Warning about setting `obs` to categorical when that's already been done; On current master (f428848ece1d7a4794), every time I try to plot a scatter plot I get warnings about setting columns of `obs` to categorical, even though it's already been done. Here's an example:. ![screen shot 2019-01-27 at 6 05 40 pm](https://user-images.githubusercontent.com/8238804/51797863-94c94780-225e-11e9-82db-2f170518a977.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/448
https://github.com/scverse/scanpy/issues/448:120,performance,time,time,120,"Warning about setting `obs` to categorical when that's already been done; On current master (f428848ece1d7a4794), every time I try to plot a scatter plot I get warnings about setting columns of `obs` to categorical, even though it's already been done. Here's an example:. ![screen shot 2019-01-27 at 6 05 40 pm](https://user-images.githubusercontent.com/8238804/51797863-94c94780-225e-11e9-82db-2f170518a977.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/448
https://github.com/scverse/scanpy/issues/448:320,usability,user,user-images,320,"Warning about setting `obs` to categorical when that's already been done; On current master (f428848ece1d7a4794), every time I try to plot a scatter plot I get warnings about setting columns of `obs` to categorical, even though it's already been done. Here's an example:. ![screen shot 2019-01-27 at 6 05 40 pm](https://user-images.githubusercontent.com/8238804/51797863-94c94780-225e-11e9-82db-2f170518a977.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/448
https://github.com/scverse/scanpy/issues/449:4,integrability,batch,batch,4,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:119,integrability,batch,batch,119,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:362,integrability,filter,filter,362,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:494,integrability,batch,batch,494,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:155,modifiability,variab,variable,155,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:244,modifiability,variab,variable,244,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:323,modifiability,variab,variable,323,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:4,performance,batch,batch,4,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:119,performance,batch,batch,119,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:494,performance,batch,batch,494,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:291,reliability,doe,does,291,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:83,usability,document,documentation,83,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:338,usability,effectiv,effectively,338,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/449:424,usability,minim,minimum,424,"mnn batch correction recommended number of genes and negative gene values; Hi, the documentation describes running MNN batch correction on a set of highly variable genes - how many genes are recommended? . * I tried running with the top 10,000 variable genes. Is this a good number. * Also, does selecting for these highly variable genes effectively permanently filter the dataset for only these genes? * I noticed that the minimum gene expression level for some genes was less than zero after batch correction, is this expected?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449
https://github.com/scverse/scanpy/issues/450:1882,availability,down,downcast,1882,"of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1891,availability,down,downcast,1891," one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.ht",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2026,availability,toler,tolerance,2026,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2193,availability,down,downcast,2193,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2435,availability,toler,tolerance,2435,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2746,availability,error,error,2746,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:105,deployability,api,api,105,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:119,deployability,log,logging,119,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:546,deployability,modul,module,546,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1050,deployability,log,logg,1050,"das 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1430,deployability,contain,contained,1430,"---------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2806,deployability,API,API,2806,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1126,energy efficiency,core,core,1126,"rint_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1336,energy efficiency,core,core,1336,"els==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1581,energy efficiency,core,core,1581,"). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorica",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1696,energy efficiency,core,core,1696,"/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1967,energy efficiency,core,core,1967,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2363,energy efficiency,core,core,2363,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:105,integrability,api,api,105,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:839,integrability,sub,subset,839,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2806,integrability,API,API,2806,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:105,interoperability,api,api,105,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2806,interoperability,API,API,2806,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:546,modifiability,modul,module,546,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:683,modifiability,pac,packages,683,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1110,modifiability,pac,packages,1110,". sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1224,modifiability,Paramet,Parameters,1224,"thon. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Syno",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1320,modifiability,pac,packages,1320,".20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1565,modifiability,pac,packages,1565,"atasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1680,modifiability,pac,packages,1680,"ackages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. Value",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1951,modifiability,pac,packages,1951,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2347,modifiability,pac,packages,2347,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1599,performance,reindex,reindex,1599,".highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 50",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1715,performance,reindex,reindex,1715,"_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-un",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2391,performance,reindex,reindex,2391,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2698,performance,reindex,reindex,2698,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2746,performance,error,error,2746,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2813,performance,reindex,reindex,2813,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2026,reliability,toleran,tolerance,2026,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2435,reliability,toleran,tolerance,2435,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:119,safety,log,logging,119,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:519,safety,input,input-,519,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:546,safety,modul,module,546,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1050,safety,log,logg,1050,"das 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2746,safety,error,error,2746,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:119,security,log,logging,119,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1050,security,log,logg,1050,"das 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1199,security,access,accessors,1199,"ata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:119,testability,log,logging,119,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:475,testability,Trace,Traceback,475,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:1050,testability,log,logg,1050,"das 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:62,usability,Minim,Minimal,62,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:316,usability,learn,learn,316,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:519,usability,input,input-,519,"ValueError with sc.pp.highly_variable_genes with pandas 0.24; Minimal example:. ```python. import scanpy.api as sc. sc.logging.print_versions(). adata = sc.datasets.blobs(). sc.pp.highly_variable_genes(adata). ```. Output:. ```python. **scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-11-5d93fbf298b7> in <module>. 4 adata = sc.datasets.blobs(). 5 . ----> 6 sc.pp.highly_variable_genes(adata). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 115 # a normalized disperion of 1. 116 one_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/450:2746,usability,error,error,2746,"ne_gene_per_bin = disp_std_bin.isnull(). --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(). 118 if len(gen_indices) > 0:. 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key). 909 Please use .at[] or .iat[] accessors. 910 . --> 911 Parameters. 912 ----------. 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key). 951 -------. 952 series : Series. --> 953 If label is contained, will be reference to calling Series,. 954 otherwise a new object. 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4344 . 4345 elif not is_list_like(value):. -> 4346 new_data = self._data.fillna(value=value, limit=limit,. 4347 inplace=inplace,. 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4357 return self._constructor(new_data).__finalize__(self). 4358 . -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):. 4360 """""". 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance). 501 # in which case we are going to conform to the passed Categorical. 502 new_target = np.asarray(new_target). --> 503 if is_categorical_dtype(target):. 504 new_target = target._shallow_copy(new_target, name=self.name). 505 else:. ValueError: cannot reindex with a non-unique indexer. **. ```. The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450
https://github.com/scverse/scanpy/issues/451:40,energy efficiency,current,currently,40,"Additional functionality; Dear all, I'm currently using scanpy exhaustively and have noticed that compared to other R scRNA-seq packages some nice functionality is still missing. . 1. Scater has the plotExplanatoryVariables function which plots the variance explained by different features (https://rdrr.io/bioc/scater/man/plotExplanatoryVariables.html). Is there currently an alternative in Scanpy for this plot? 2. Is there a variant for the mvoutlier package that is proposed in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408845/ for cell filtering? Kind regards . Dries De Maeyer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/451
https://github.com/scverse/scanpy/issues/451:364,energy efficiency,current,currently,364,"Additional functionality; Dear all, I'm currently using scanpy exhaustively and have noticed that compared to other R scRNA-seq packages some nice functionality is still missing. . 1. Scater has the plotExplanatoryVariables function which plots the variance explained by different features (https://rdrr.io/bioc/scater/man/plotExplanatoryVariables.html). Is there currently an alternative in Scanpy for this plot? 2. Is there a variant for the mvoutlier package that is proposed in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408845/ for cell filtering? Kind regards . Dries De Maeyer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/451
https://github.com/scverse/scanpy/issues/451:545,integrability,filter,filtering,545,"Additional functionality; Dear all, I'm currently using scanpy exhaustively and have noticed that compared to other R scRNA-seq packages some nice functionality is still missing. . 1. Scater has the plotExplanatoryVariables function which plots the variance explained by different features (https://rdrr.io/bioc/scater/man/plotExplanatoryVariables.html). Is there currently an alternative in Scanpy for this plot? 2. Is there a variant for the mvoutlier package that is proposed in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408845/ for cell filtering? Kind regards . Dries De Maeyer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/451
https://github.com/scverse/scanpy/issues/451:128,modifiability,pac,packages,128,"Additional functionality; Dear all, I'm currently using scanpy exhaustively and have noticed that compared to other R scRNA-seq packages some nice functionality is still missing. . 1. Scater has the plotExplanatoryVariables function which plots the variance explained by different features (https://rdrr.io/bioc/scater/man/plotExplanatoryVariables.html). Is there currently an alternative in Scanpy for this plot? 2. Is there a variant for the mvoutlier package that is proposed in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408845/ for cell filtering? Kind regards . Dries De Maeyer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/451
https://github.com/scverse/scanpy/issues/451:454,modifiability,pac,package,454,"Additional functionality; Dear all, I'm currently using scanpy exhaustively and have noticed that compared to other R scRNA-seq packages some nice functionality is still missing. . 1. Scater has the plotExplanatoryVariables function which plots the variance explained by different features (https://rdrr.io/bioc/scater/man/plotExplanatoryVariables.html). Is there currently an alternative in Scanpy for this plot? 2. Is there a variant for the mvoutlier package that is proposed in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408845/ for cell filtering? Kind regards . Dries De Maeyer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/451
https://github.com/scverse/scanpy/issues/452:98,usability,user,users,98,dataframe-to-adata upload method; Is there a `to_adata` method (analogous to `to_df`) that allows users to upload a Pandas DataFrame into an adata object?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/452
https://github.com/scverse/scanpy/issues/453:468,availability,state,states,468,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1136,deployability,log,logreg,1136,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1312,deployability,API,APIs,1312,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:468,integrability,state,states,468,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1312,integrability,API,APIs,1312,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1312,interoperability,API,APIs,1312,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1343,interoperability,compatib,compatible,1343,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1362,modifiability,deco,decorator,1362,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:376,performance,cach,cachdir,376,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:427,performance,cach,cache,427,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:442,performance,cach,cache,442,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:303,safety,test,test,303,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1136,safety,log,logreg,1136,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1457,safety,test,tests,1457,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1136,security,log,logreg,1136,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:303,testability,test,test,303,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:758,testability,simpl,simple,758,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1136,testability,log,logreg,1136,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:1457,testability,test,tests,1457,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/453:758,usability,simpl,simple,758,"TODO: Backwards-compat breaking changes; A list for keeping track of things that we might change when breaking backwards compat at some point:. - [ ] merge sparse pca https://github.com/theislab/scanpy/pull/1066. - [x] merge https://github.com/theislab/scanpy/pull/1111. - [ ] merge #572. - [ ] make `t-test` or `wilxocon` the default of `tl.rank_genes_groups`. - [ ] set the cachdir default to `user_cache_dir(…)`, `~/.scanpy/cache/` or `~/.cache/`. - [ ] stationary states in DPT: https://github.com/theislab/scanpy/blob/b11b4abe5e16053c010e57b2dd3a27396a4b0cf2/scanpy/neighbors/__init__.py#L853-L857 thanks to @Marius1311 for pointing it out! - [ ] rename `log2fc` or similarly: #446. - [ ] add `inplace` functionality where easily possible, that's not a simple renaming; a function that has `inplace` in it, should only return the annotation if `inplace=False`; the `copy` functions return the whole `adata`, which we don't want... - [ ] rename `n_comps` to `n_components` everywhere. - [ ] consider merging https://github.com/theislab/scanpy/pull/403. - [ ] replace default pca solver with 'arpack'. - [ ] change default solver in logreg solver in rank_genes_groups to lbfgs. - [x] merge #621. - [ ] make `pp.highly_variable_genes` return a df instead of a recarray... - [ ] Transition away from positional APIs: #464 (actually backwards compatible through decorator!). anndata:. - [ ] merge https://github.com/theislab/anndata/pull/130 and fix Scanpy tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/453
https://github.com/scverse/scanpy/issues/454:322,availability,error,error,322,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:955,availability,Down,Downgrading,955,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:34,deployability,depend,dependencies,34,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:79,deployability,stack,stackoverflow,79,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:102,deployability,stack,stackoverflow,102,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:160,deployability,fail,failed-while-file-is-in-working-directory,160,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:264,deployability,depend,dependencies,264,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:738,deployability,fail,failed,738,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:891,deployability,version,version,891,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:975,deployability,version,version,975,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:155,energy efficiency,load,load-failed-while-file-is-in-working-directory,155,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:733,energy efficiency,load,load,733,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:34,integrability,depend,dependencies,34,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:264,integrability,depend,dependencies,264,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:891,integrability,version,version,891,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:975,integrability,version,version,975,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:8,interoperability,compatib,compatibility,8,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:750,interoperability,specif,specified,750,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:34,modifiability,depend,dependencies,34,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:264,modifiability,depend,dependencies,264,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:423,modifiability,pac,packages,423,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:520,modifiability,pac,packages,520,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:648,modifiability,pac,packages,648,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:891,modifiability,version,version,891,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:975,modifiability,version,version,975,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:155,performance,load,load-failed-while-file-is-in-working-directory,155,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:322,performance,error,error,322,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:733,performance,load,load,733,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:160,reliability,fail,failed-while-file-is-in-working-directory,160,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:738,reliability,fail,failed,738,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:34,safety,depend,dependencies,34,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:264,safety,depend,dependencies,264,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:322,safety,error,error,322,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:911,safety,avoid,avoid,911,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:34,testability,depend,dependencies,34,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:264,testability,depend,dependencies,264,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:289,usability,user,users,289,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:322,usability,error,error,322,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/454:948,usability,user,users,948,"Windows compatibility issues with dependencies; Hi! As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb. >>> import scanpy. ... File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in. import tables. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in. from .file import File, open_file, copy_file. File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in. from . import hdf5extension. ImportError: DLL load failed: The specified procedure could not be found. ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454
https://github.com/scverse/scanpy/issues/455:454,availability,error,error,454,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:52,deployability,fail,fails,52,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:635,deployability,modul,module,635,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1768,deployability,observ,observation,1768,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1823,deployability,observ,observation,1823,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2009,deployability,observ,observation,2009,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2056,deployability,observ,observation,2056,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2205,deployability,contain,contains,2205,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:460,integrability,messag,message,460,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1174,integrability,compon,components,1174,"display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:460,interoperability,messag,message,460,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1174,interoperability,compon,components,1174,"display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1870,interoperability,format,format,1870,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:635,modifiability,modul,module,635,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:757,modifiability,pac,packages,757,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1007,modifiability,pac,packages,1007,"e_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1174,modifiability,compon,components,1174,"display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1592,modifiability,pac,packages,1592,". <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1802,modifiability,variab,variable,1802,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2035,modifiability,variab,variable,2035,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:454,performance,error,error,454,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:52,reliability,fail,fails,52,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:296,reliability,doe,doesn,296,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:454,safety,error,error,454,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:607,safety,input,input-,607,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:635,safety,modul,module,635,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1762,safety,valid,valid,1762,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1817,safety,Valid,Valid,1817,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2003,safety,valid,valid,2003,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2050,safety,Valid,Valid,2050,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:563,testability,Trace,Traceback,563,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1768,testability,observ,observation,1768,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1823,testability,observ,observation,1823,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2009,testability,observ,observation,2009,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2056,testability,observ,observation,2056,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:454,usability,error,error,454,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:607,usability,input,input-,607,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:782,usability,tool,tools,782,"setting gene_symbol to select symbol from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1032,usability,tool,tools,1032,"l from adata.var fails in sc.pl.umap(); I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-116-e09d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:1617,usability,tool,tools,1617,"d49f2528c> in <module>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/455:2565,usability,learn,learn,2565,"odule>. ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs). 27 If `show==False` a `matplotlib.Axis` or a list of it. 28 """""". ---> 29 return plot_scatter(adata, basis='umap', **kwargs). 30 . 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 275 color_vector, categorical = _get_color_values(adata, value_to_plot,. 276 groups=groups, palette=palette,. --> 277 use_raw=use_raw). 278 . 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw). 665 raise ValueError(""The passed `color` {} is not a valid observation annotation "". 666 ""or variable name. Valid observation annotation keys are: {}"". --> 667 .format(value_to_plot, adata.obs.columns)). 668 . 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['Sample', 'n_counts', 'n_genes', 'percent_mito', 'log_counts',. 'louvain'],. dtype='object'). ```. adata.var contains the column ""Symbol"" and ""Tnnt2"" is present:. `adata.var[adata.var['Symbol'] == 'Tnnt2']`. . Symbol | type | highly_variable | means | dispersions | dispersions_norm. -- | -- | -- | -- | -- | --. Tnnt2 | protein_coding | True | 0.923869 | 4.090601 | 11.370244. run with:. `scanpy==1.3.7 anndata==0.6.17 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 `.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455
https://github.com/scverse/scanpy/issues/456:4,availability,error,errors,4,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:442,availability,error,error,442,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2262,availability,down,downgraded,2262,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:3030,availability,error,error,3030,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2081,deployability,Version,Versions,2081," to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2096,deployability,modul,modules,2096,". ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:1276,energy efficiency,estimat,estimator,1276,"ion step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:268,integrability,batch,batch,268,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:844,integrability,sub,subset,844,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2081,integrability,Version,Versions,2081," to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2434,integrability,transform,transform,2434,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:1413,interoperability,Standard,StandardScaler,1413,"fortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2434,interoperability,transform,transform,2434,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2626,interoperability,format,format,2626,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:3005,interoperability,format,format,3005,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:236,modifiability,pac,package,236,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:352,modifiability,variab,variable,352,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:688,modifiability,pac,packages,688,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:1134,modifiability,pac,packages,1134,"to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:1461,modifiability,pac,packages,1461,"Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a stru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:1659,modifiability,pac,packages,1659,"onda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:1844,modifiability,pac,packages,1844,"et, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2081,modifiability,Version,Versions,2081," to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2096,modifiability,modul,modules,2096,". ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:4,performance,error,errors,4,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:16,performance,perform,performing,16,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:256,performance,perform,perform,256,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:268,performance,batch,batch,268,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:442,performance,error,error,442,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2650,performance,perform,performing,2650,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:3030,performance,error,error,3030,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:91,reliability,pra,practices,91,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:4,safety,error,errors,4,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:442,safety,error,error,442,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2096,safety,modul,modules,2096,". ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:3030,safety,error,error,3030,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:530,testability,Trace,Traceback,530,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:572,testability,Trace,Traceback,572,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:4,usability,error,errors,4,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:16,usability,perform,performing,16,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:72,usability,workflow,workflow,72,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:256,usability,perform,perform,256,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:442,usability,error,error,442,"Get errors when performing sc.pp.highly_variable_genes!; I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets. I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb. LinAlgError Traceback (most recent call last). in . ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace). 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X. 95. ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)). 97 # now actually compute the dispersion. 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2185,usability,learn,learn,2185,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:2650,usability,perform,performing,2650,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/issues/456:3030,usability,error,error,3030,"/scanpy/preprocessing/utils.py in _get_mean_var(X). 16 mean_sq = np.multiply(X, X).mean(axis=0). 17 # enforece R convention (unbiased estimator) for variance. ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)). 19 else:. 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other). 226. 227 def pow(self, other):. --> 228 return matrix_power(self, other). 229. 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n). 600 a = asanyarray(a). 601 _assertRankAtLeast2(a). --> 602 _assertNdSquareness(a). 603. 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays). 213 m, n = a.shape[-2:]. 214 if m != n:. --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'). 216. 217 def _assertFinite(*arrays):. ```. </details>. Versions of my modules:. scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py. adata.X /= adata.obs['size_factors'].values[:,None]. ```. This step transform the adata.X to a structure of matrix. Before the adata.X is. ```. <6242x15065 sparse matrix of type '<class 'numpy.float32'>'. with 19234986 stored elements in Compressed Sparse Row format>. ```. But after performing this step, the adata.X is. This is my adata.X looks like right now:. ```py. matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],. [0. , 0. , 1.203, ..., 0. , 0. , 0. ],. [0. , 1.096, 0. , ..., 0. , 0. , 0. ],. ...,. [0. , 0. , 2.042, ..., 0. , 0. , 0. ],. [0. , 0. , 0. , ..., 0.926, 0. , 0. ],. [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),. ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response! Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456
https://github.com/scverse/scanpy/pull/457:0,deployability,Updat,Updated,0,"Updated PyPairs to v3.0.9; PyPairs v3.0.9 is fully rewritten and will now directly accept AnnData objects. Further it will respect the settings from scanpy regarding verbosity, n_jobs, and output directories. The full documentation can be found at: pypairs.rtfd.io",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457
https://github.com/scverse/scanpy/pull/457:0,safety,Updat,Updated,0,"Updated PyPairs to v3.0.9; PyPairs v3.0.9 is fully rewritten and will now directly accept AnnData objects. Further it will respect the settings from scanpy regarding verbosity, n_jobs, and output directories. The full documentation can be found at: pypairs.rtfd.io",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457
https://github.com/scverse/scanpy/pull/457:0,security,Updat,Updated,0,"Updated PyPairs to v3.0.9; PyPairs v3.0.9 is fully rewritten and will now directly accept AnnData objects. Further it will respect the settings from scanpy regarding verbosity, n_jobs, and output directories. The full documentation can be found at: pypairs.rtfd.io",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457
https://github.com/scverse/scanpy/pull/457:218,usability,document,documentation,218,"Updated PyPairs to v3.0.9; PyPairs v3.0.9 is fully rewritten and will now directly accept AnnData objects. Further it will respect the settings from scanpy regarding verbosity, n_jobs, and output directories. The full documentation can be found at: pypairs.rtfd.io",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457
https://github.com/scverse/scanpy/issues/458:47,modifiability,paramet,parameters,47,"Documentation for pl.scatter; Hi,. Some of the parameters documented online for `pl.scatter` are not accepted by the method: `ncols`, `wspace`, `hspace`. And some are not documented: `right_margin`, `left_margin`. The difference seems to come from the parameters described in `{scatter_bulk}` and used for `pl.scatter` documentation. What should be fixed `scatter_bulk` or inputs for `pl.scatter`? Bérénice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458
