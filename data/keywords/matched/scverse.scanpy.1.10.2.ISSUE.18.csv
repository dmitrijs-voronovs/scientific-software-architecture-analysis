id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/pull/1654:993,deployability,modul,module,993,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:233,modifiability,modul,module,233,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:330,modifiability,pac,packages,330,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:494,modifiability,pac,packages,494,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:657,modifiability,pac,packages,657,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:993,modifiability,modul,module,993,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:233,safety,modul,module,233,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:993,safety,modul,module,993,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:59,testability,Trace,Traceback,59,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:272,usability,User,Users,272,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:436,usability,User,Users,436,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1654:599,usability,User,Users,599,"Fix timeseries_as_heatmap plot function; This fixes:. ```. Traceback (most recent call last):. File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>. sc.pl.dpt_timeseries(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries. timeseries_as_heatmap(. File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap. pl.colorbar(shrink=0.5). File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar. raise RuntimeError('No mappable was found to use for colorbar '. RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf). ```. I see that in other places plt.colobar is used in this module you're. doing the same thing. I believe this broke in. 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1655:346,safety,review,review,346,Drop passing of **kwds; This matches the else branch and fixes problem when `figsize` or `color` for instance. are passed in. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1655
https://github.com/scverse/scanpy/pull/1655:346,testability,review,review,346,Drop passing of **kwds; This matches the else branch and fixes problem when `figsize` or `color` for instance. are passed in. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1655
https://github.com/scverse/scanpy/pull/1655:197,usability,guid,guidelines,197,Drop passing of **kwds; This matches the else branch and fixes problem when `figsize` or `color` for instance. are passed in. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1655
https://github.com/scverse/scanpy/pull/1655:228,usability,guid,guide,228,Drop passing of **kwds; This matches the else branch and fixes problem when `figsize` or `color` for instance. are passed in. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1655
https://github.com/scverse/scanpy/pull/1655:324,usability,workflow,workflow,324,Drop passing of **kwds; This matches the else branch and fixes problem when `figsize` or `color` for instance. are passed in. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1655
https://github.com/scverse/scanpy/pull/1656:12,deployability,log,logic,12,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:82,deployability,fail,fails,82,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:240,deployability,log,log,240,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:385,deployability,observ,observation,385,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:433,deployability,observ,observations,433,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:512,deployability,observ,observation,512,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:556,deployability,observ,observations,556,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:145,modifiability,pac,packages,145,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:261,modifiability,layer,layer,261,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:82,reliability,fail,fails,82,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:12,safety,log,logic,12,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:240,safety,log,log,240,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:379,safety,valid,valid,379,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:506,safety,valid,valid,506,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:832,safety,review,review,832,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:12,security,log,logic,12,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:240,security,log,log,240,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:12,testability,log,logic,12,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:240,testability,log,log,240,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:385,testability,observ,observation,385,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:433,testability,observ,observations,433,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:512,testability,observ,observation,512,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:556,testability,observ,observations,556,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:832,testability,review,review,832,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:683,usability,guid,guidelines,683,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:714,usability,guid,guide,714,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:810,usability,workflow,workflow,810,"Fix groupby logic if adata.uns[key]['params']['groupby'] is array; Otherwise this fails with:. ```. ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1828 import IPython. 1829 IPython.embed(). -> 1830 raise ValueError(. 1831 'groupby has to be a valid observation. '. 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index"". ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1657:259,deployability,contain,contains,259,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:359,modifiability,paramet,parameter,359,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:244,performance,time,time,244,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:677,reliability,doe,does,677,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:1021,reliability,doe,does,1021,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:171,safety,input,input,171,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:971,security,sign,significant,971,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:24,testability,simul,simultaneous,24,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:998,testability,simpl,simple,998,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:171,usability,input,input,171,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:323,usability,visual,visualise,323,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:760,usability,experien,experience,760,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1657:998,usability,simpl,simple,998,"Cell selection based on simultaneous expression (co-expression); Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/pull/1659:42,integrability,rout,routines,42,Fix passing of arguments between scrublet routines; Just a small PR to reinstate correct passing of parameters to Scrublet. Addresses https://github.com/theislab/scanpy/issues/1644.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1659
https://github.com/scverse/scanpy/pull/1659:100,modifiability,paramet,parameters,100,Fix passing of arguments between scrublet routines; Just a small PR to reinstate correct passing of parameters to Scrublet. Addresses https://github.com/theislab/scanpy/issues/1644.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1659
https://github.com/scverse/scanpy/issues/1660:16,availability,Error,Error,16,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:759,availability,Error,Error,759,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:782,availability,Error,Error,782,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:178,deployability,version,version,178,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:868,deployability,Version,Versions,868,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:917,deployability,log,logging,917,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:178,integrability,version,version,178,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:868,integrability,Version,Versions,868,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:848,interoperability,registr,registry,848,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:178,modifiability,version,version,178,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:868,modifiability,Version,Versions,868,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:16,performance,Error,Error,16,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:759,performance,Error,Error,759,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:782,performance,Error,Error,782,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:16,safety,Error,Error,16,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:759,safety,Error,Error,759,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:782,safety,Error,Error,782,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:917,safety,log,logging,917,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:917,security,log,logging,917,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:917,testability,log,logging,917,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:16,usability,Error,Error,16,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:138,usability,confirm,confirmed,138,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:221,usability,confirm,confirmed,221,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:312,usability,guid,guide,312,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:367,usability,minim,minimal-bug-reports,367,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:473,usability,Minim,Minimal,473,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:759,usability,Error,Error,759,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:782,usability,Error,Error,782,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:1076,usability,learn,learn,1076,"Internal Server Error for queries.biomart_annotations ; - [ X] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. annot = sc.queries.biomart_annotations(. ""hsapiens"",. [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""). ```. ```pytb. 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1661:409,availability,cluster,cluster,409,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:496,availability,cluster,cluster,496,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:571,availability,error,error,571,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:172,deployability,version,version,172,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:401,deployability,contain,contain,401,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:409,deployability,cluster,cluster,409,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:496,deployability,cluster,cluster,496,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:172,integrability,version,version,172,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:172,modifiability,version,version,172,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:571,performance,error,error,571,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:571,safety,error,error,571,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:132,usability,confirm,confirmed,132,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:215,usability,confirm,confirmed,215,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:463,usability,indicat,indicate,463,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:571,usability,error,error,571,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:609,usability,user,user-images,609,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1661:722,usability,user,user-images,722,"sc.pl.rank_genes_groups_heatmap column color bar ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1662:684,performance,overhead,overhead,684,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:122,reliability,doe,does,122,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:36,safety,test,tests,36,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:47,safety,test,test,47,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:83,safety,test,test,83,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:173,safety,reme,remember,173,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:269,safety,test,test,269,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:706,safety,test,test,706,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:36,testability,test,tests,36,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:47,testability,test,test,47,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:83,testability,test,test,83,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:269,testability,test,test,269,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:706,testability,test,test,706,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:142,usability,close,close,142,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:288,usability,close,closes,288,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:426,usability,close,close,426,"Add figure closing teardown for all tests; The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python. @pytest.fixture(autouse=True). def close_figures_on_teardown():. yield. plt.close(""all""). ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended). * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/pull/1663:553,availability,avail,available,553,"Allow dask arrays to propagate through _normalize_data(); . While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575. But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/pull/1663:527,performance,time,time,527,"Allow dask arrays to propagate through _normalize_data(); . While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575. But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/pull/1663:145,reliability,doe,doesn,145,"Allow dask arrays to propagate through _normalize_data(); . While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575. But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/pull/1663:296,reliability,doe,does,296,"Allow dask arrays to propagate through _normalize_data(); . While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575. But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/pull/1663:553,reliability,availab,available,553,"Allow dask arrays to propagate through _normalize_data(); . While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575. But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/pull/1663:553,safety,avail,available,553,"Allow dask arrays to propagate through _normalize_data(); . While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575. But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/pull/1663:553,security,availab,available,553,"Allow dask arrays to propagate through _normalize_data(); . While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575. But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/issues/1664:1746,availability,cluster,clustermap,1746, the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . - [ ] Preprocessing. - [ ] `sc.pl.filter_genes_dispersion`. - [ ] `sc.pl.highest_expr_genes`. - [ ] `sc.pl.highly_variable_genes`. - [ ] DE. - [x] `sc.pl.rank_genes_groups` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_dotplot` #1810 @LouisK92 #1529 @fidelram. - [x] `sc.pl.rank_genes_groups_heatmap` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_matrixplot` #1529 @fidelram. - [ ] `sc.pl.rank_genes_groups_stacked_violin`. - [ ] `sc.pl.rank_genes_groups_tracksplot`. - [ ] `sc.pl.rank_genes_groups_violin`. - [ ] Misc/ to be classified. - [ ] `sc.pl.ranking`. - [ ] `sc.pl.scatter`. - [ ] `sc.pl.sim`. - [ ] `sc.pl.correlation_matrix`. - [ ] `sc.pl.matrix`. - [ ] Time series (???). - [ ] `sc.pl.timeseries`. - [ ] `sc.pl.timeseries_as_heatmap`. -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:117,deployability,API,API,117,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:326,deployability,api,api,326,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:454,deployability,api,api,454,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:1746,deployability,cluster,clustermap,1746, the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . - [ ] Preprocessing. - [ ] `sc.pl.filter_genes_dispersion`. - [ ] `sc.pl.highest_expr_genes`. - [ ] `sc.pl.highly_variable_genes`. - [ ] DE. - [x] `sc.pl.rank_genes_groups` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_dotplot` #1810 @LouisK92 #1529 @fidelram. - [x] `sc.pl.rank_genes_groups_heatmap` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_matrixplot` #1529 @fidelram. - [ ] `sc.pl.rank_genes_groups_stacked_violin`. - [ ] `sc.pl.rank_genes_groups_tracksplot`. - [ ] `sc.pl.rank_genes_groups_violin`. - [ ] Misc/ to be classified. - [ ] `sc.pl.ranking`. - [ ] `sc.pl.scatter`. - [ ] `sc.pl.sim`. - [ ] `sc.pl.correlation_matrix`. - [ ] `sc.pl.matrix`. - [ ] Time series (???). - [ ] `sc.pl.timeseries`. - [ ] `sc.pl.timeseries_as_heatmap`. -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:1790,energy efficiency,heat,heatmap,1790,xamples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . - [ ] Preprocessing. - [ ] `sc.pl.filter_genes_dispersion`. - [ ] `sc.pl.highest_expr_genes`. - [ ] `sc.pl.highly_variable_genes`. - [ ] DE. - [x] `sc.pl.rank_genes_groups` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_dotplot` #1810 @LouisK92 #1529 @fidelram. - [x] `sc.pl.rank_genes_groups_heatmap` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_matrixplot` #1529 @fidelram. - [ ] `sc.pl.rank_genes_groups_stacked_violin`. - [ ] `sc.pl.rank_genes_groups_tracksplot`. - [ ] `sc.pl.rank_genes_groups_violin`. - [ ] Misc/ to be classified. - [ ] `sc.pl.ranking`. - [ ] `sc.pl.scatter`. - [ ] `sc.pl.sim`. - [ ] `sc.pl.correlation_matrix`. - [ ] `sc.pl.matrix`. - [ ] Time series (???). - [ ] `sc.pl.timeseries`. - [ ] `sc.pl.timeseries_as_heatmap`. - [ ] `sc.pl.timeseries_subplot`. ### Other ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:117,integrability,API,API,117,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:326,integrability,api,api,326,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:454,integrability,api,api,454,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:117,interoperability,API,API,117,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:326,interoperability,api,api,326,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:454,interoperability,api,api,454,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:1261,interoperability,specif,specific,1261,lculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . - [ ] Preprocessing. - [ ] `sc.pl.filter_genes_dispersion`. - [ ] `sc.pl.highest_expr_genes`. - [ ] `sc.pl.highly_variable_genes`. - [ ] DE. - [x] `sc.pl.rank_genes_groups` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_dotplot` #1810 @LouisK92 #1529 @fidelram. - [,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:2668,performance,Time,Time,2668, `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . - [ ] Preprocessing. - [ ] `sc.pl.filter_genes_dispersion`. - [ ] `sc.pl.highest_expr_genes`. - [ ] `sc.pl.highly_variable_genes`. - [ ] DE. - [x] `sc.pl.rank_genes_groups` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_dotplot` #1810 @LouisK92 #1529 @fidelram. - [x] `sc.pl.rank_genes_groups_heatmap` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_matrixplot` #1529 @fidelram. - [ ] `sc.pl.rank_genes_groups_stacked_violin`. - [ ] `sc.pl.rank_genes_groups_tracksplot`. - [ ] `sc.pl.rank_genes_groups_violin`. - [ ] Misc/ to be classified. - [ ] `sc.pl.ranking`. - [ ] `sc.pl.scatter`. - [ ] `sc.pl.sim`. - [ ] `sc.pl.correlation_matrix`. - [ ] `sc.pl.matrix`. - [ ] Time series (???). - [ ] `sc.pl.timeseries`. - [ ] `sc.pl.timeseries_as_heatmap`. - [ ] `sc.pl.timeseries_subplot`. ### Other functions. - [x] `sc.pp.calculate_qc_metrics` @ivirshup (?). - [x] `sc.tl.embedding_density` @ivirshup (?). - [ ] `sc.get.obs_df`. - [ ] `sc.get.rank_genes_groups_df`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:2700,performance,time,timeseries,2700, `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . - [ ] Preprocessing. - [ ] `sc.pl.filter_genes_dispersion`. - [ ] `sc.pl.highest_expr_genes`. - [ ] `sc.pl.highly_variable_genes`. - [ ] DE. - [x] `sc.pl.rank_genes_groups` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_dotplot` #1810 @LouisK92 #1529 @fidelram. - [x] `sc.pl.rank_genes_groups_heatmap` #1830 @mayarali. - [x] `sc.pl.rank_genes_groups_matrixplot` #1529 @fidelram. - [ ] `sc.pl.rank_genes_groups_stacked_violin`. - [ ] `sc.pl.rank_genes_groups_tracksplot`. - [ ] `sc.pl.rank_genes_groups_violin`. - [ ] Misc/ to be classified. - [ ] `sc.pl.ranking`. - [ ] `sc.pl.scatter`. - [ ] `sc.pl.sim`. - [ ] `sc.pl.correlation_matrix`. - [ ] `sc.pl.matrix`. - [ ] Time series (???). - [ ] `sc.pl.timeseries`. - [ ] `sc.pl.timeseries_as_heatmap`. - [ ] `sc.pl.timeseries_subplot`. ### Other functions. - [x] `sc.pp.calculate_qc_metrics` @ivirshup (?). - [x] `sc.tl.embedding_density` @ivirshup (?). - [ ] `sc.get.obs_df`. - [ ] `sc.get.rank_genes_groups_df`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/issues/1664:688,usability,document,documentation,688,Inline example plots in docs; Meta-issue for tracking the addition of rendered plots in the examples sections of the API docs (initial functionality implemented in #1632). We now allow code samples which generate plots in our docs. See the examples sections of [`calculate_qc_metrics`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics) and [`dotplot`](https://scanpy.readthedocs.io/en/latest/api/scanpy.pl.dotplot.html#scanpy.pl.dotplot) for examples of what this looks like. There is a short section in the dev docs with more information on how to make these: [Plots in docstring](https://scanpy.readthedocs.io/en/latest/dev/documentation.html#plots-in-docstrings). Here is a checklist of the functions which should have rendered examples. This list is not exclusive and can definitely be expanded. ### Functions in `sc.pl`. - [ ] Embedding plots (these may deserve their own prose section). - [ ] `sc.pl.embedding`. - [x] `sc.pl.draw_graph` #1809 @AnnaChristina . - [x] `sc.pl.diffmap` #1809 @AnnaChristina. - [x] `sc.pl.pca` #1813 @lazappi . - [x] `sc.pl.tsne` #1809 @AnnaChristina. - [x] `sc.pl.umap` #1830 @mayarali. - [ ] `sc.pl.spatial`. - [x] `sc.pl.embedding_density` @ivirshup . - [ ] PCA specific. - [x] `sc.pl.pca_loadings` #1815 @bio-la . - [x] `sc.pl.pca_overview` #1812 @MxMstrmn . - [ ] `sc.pl.pca_scatter`. - [ ] `sc.pl.pca_variance_ratio`. - [ ] PAGA. - [x] `sc.pl.paga` #1811 @le-ander . - [ ] `sc.pl.paga_adjacency`. - [ ] `sc.pl.paga_compare`. - [ ] `sc.pl.paga_path`. - [ ] DPT pseudotime. - [ ] `sc.pl.dpt_groups_pseudotime`. - [ ] `sc.pl.dpt_timeseries`. - [x] Groupby. - [x] `sc.pl.dotplot` @ivirshup . - [x] `sc.pl.matrixplot` #1808 @mbuttner . - [x] `sc.pl.clustermap` #2509 @giuliafrrn. - [x] `sc.pl.heatmap` #1809 @AnnaChristina. - [x] `sc.pl.dendrogram` #1809 @AnnaChristina. - [x] `sc.pl.stacked_violin` #2509 @giuliafrrn. - [x] `sc.pl.tracksplot` #2509 @giuliafrrn. - [x] `sc.pl.violin` #1814 @Hrovatin . -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1664
https://github.com/scverse/scanpy/pull/1665:35,deployability,Releas,Release,35,Backport PR #1628 on branch 1.7.x (Release notes reorganization); Backport PR #1628: Release notes reorganization,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1665
https://github.com/scverse/scanpy/pull/1665:85,deployability,Releas,Release,85,Backport PR #1628 on branch 1.7.x (Release notes reorganization); Backport PR #1628: Release notes reorganization,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1665
https://github.com/scverse/scanpy/pull/1666:4,deployability,releas,release,4,Add release notes section for 1.8.0; Adding section to start collecting 1.8.0 release notes in,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1666
https://github.com/scverse/scanpy/pull/1666:78,deployability,releas,release,78,Add release notes section for 1.8.0; Adding section to start collecting 1.8.0 release notes in,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1666
https://github.com/scverse/scanpy/pull/1667:673,energy efficiency,Schedul,Scheduling,673,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:162,interoperability,standard,standard,162,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:275,interoperability,specif,specific,275,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:470,interoperability,specif,specific,470,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:507,interoperability,specif,specific,507,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:256,modifiability,layer,layer,256,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:284,modifiability,layer,layer,284,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:362,modifiability,layer,layers,362,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:418,modifiability,layer,layers,418,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:479,modifiability,layer,layer,479,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:673,performance,Schedul,Scheduling,673,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:642,safety,Test,Tests,642,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:642,testability,Test,Tests,642,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:81,usability,behavi,behaviour,81,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:178,usability,behavi,behaviour,178,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:544,usability,user,user,544,"Cleanup normalize_total; I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations . - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1668:39,performance,time,timeseries,39,Backport PR #1654 on branch 1.7.x (Fix timeseries plot traceback); Backport PR #1654: Fix timeseries plot traceback,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1668
https://github.com/scverse/scanpy/pull/1668:90,performance,time,timeseries,90,Backport PR #1654 on branch 1.7.x (Fix timeseries plot traceback); Backport PR #1654: Fix timeseries plot traceback,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1668
https://github.com/scverse/scanpy/pull/1668:55,testability,trace,traceback,55,Backport PR #1654 on branch 1.7.x (Fix timeseries plot traceback); Backport PR #1654: Fix timeseries plot traceback,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1668
https://github.com/scverse/scanpy/pull/1668:106,testability,trace,traceback,106,Backport PR #1654 on branch 1.7.x (Fix timeseries plot traceback); Backport PR #1654: Fix timeseries plot traceback,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1668
https://github.com/scverse/scanpy/pull/1669:184,deployability,modul,module,184,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:193,deployability,scale,scale,193,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:193,energy efficiency,scale,scale,193,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:397,energy efficiency,core,core,397,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:520,energy efficiency,core,core,520,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:646,energy efficiency,core,core,646,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:772,energy efficiency,core,core,772,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:938,energy efficiency,core,core,938,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:184,modifiability,modul,module,184,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:193,modifiability,scal,scale,193,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:245,modifiability,pac,packages,245,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:381,modifiability,pac,packages,381,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:504,modifiability,pac,packages,504,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:630,modifiability,pac,packages,630,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:756,modifiability,pac,packages,756,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:922,modifiability,pac,packages,922,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:193,performance,scale,scale,193,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:184,safety,modul,module,184,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1006,safety,Except,Exception,1006,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1047,safety,Except,Exception,1047,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1311,safety,review,review,1311,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:61,testability,Trace,Traceback,61,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1311,testability,review,review,1311,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1162,usability,guid,guidelines,1162,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1193,usability,guid,guide,1193,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1289,usability,workflow,workflow,1289,"Fix rank_genes_groups_violin when use_raw=False; Fixes. ```. Traceback (most recent call last):. File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>. scale='width'). File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin. df[g] = X_col. File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__. self._set_item(key, value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item. self._ensure_valid_index(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index. value = Series(value). File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__. data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True). File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array. raise Exception(""Data must be 1-dimensional""). Exception: Data must be 1-dimensional. ```. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/issues/1670:1268,availability,cluster,cluster,1268,"inimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:1512,availability,sli,slice,1512,"-------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:31,deployability,fail,fails,31,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:161,deployability,version,version,161,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:649,deployability,modul,module,649,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:691,deployability,stage,stage,691,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:1268,deployability,cluster,cluster,1268,"inimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2806,deployability,Version,Versions,2806,"arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4613,deployability,log,logical,4613,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4667,deployability,updat,updated,4667,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2316,energy efficiency,core,core,2316," = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2529,energy efficiency,core,core,2529,"turn self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2785,energy efficiency,reduc,reduction,2785,"24 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4621,energy efficiency,CPU,CPU,4621,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4625,energy efficiency,core,cores,4625,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:161,integrability,version,version,161,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2806,integrability,Version,Versions,2806,"arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4373,integrability,wrap,wrapt,4373,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:161,modifiability,version,version,161,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:649,modifiability,modul,module,649,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:976,modifiability,pac,packages,976,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:1388,modifiability,pac,packages,1388,"old_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:1673,modifiability,pac,packages,1673,"groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeEr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:1959,modifiability,pac,packages,1959,"thon3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2301,modifiability,pac,packages,2301,"p]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2514,modifiability,pac,packages,2514,":. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2806,modifiability,Version,Versions,2806,"arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:3149,modifiability,deco,decorator,3149,"indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:3700,modifiability,pac,packaging,3700,"s have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:3643,performance,network,networkx,3643,"cept TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4621,performance,CPU,CPU,4621,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:31,reliability,fail,fails,31,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:1512,reliability,sli,slice,1512,"-------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2702,reliability,doe,does,2702," _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:621,safety,input,input-,621,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:649,safety,modul,module,649,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:2645,safety,except,except,2645,"scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _major_index_fancy(self, idx). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. netwo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4613,safety,log,logical,4613,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4667,safety,updat,updated,4667,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:3022,security,certif,certifi,3022,"). 688 idx_dtype = self.indices.dtype. 689 res_indptr = np.zeros(M+1, dtype=idx_dtype). --> 690 np.cumsum(row_nnz[idx], out=res_indptr[1:]). 691 . 692 nnz = res_indptr[-1]. <__array_function__ internals> in cumsum(*args, **kwargs). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in cumsum(a, axis, dtype, out). 2481 . 2482 """""". -> 2483 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2484 . 2485 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 . 57 try:. ---> 58 return bound(*args, **kwds). 59 except TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:3643,security,network,networkx,3643,"cept TypeError:. 60 # A TypeError occurs if the object does have such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4613,security,log,logical,4613,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4647,security,Session,Session,4647,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4667,security,updat,updated,4667,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:577,testability,Trace,Traceback,577,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4613,testability,log,logical,4613,"such a method in its. ValueError: provided out is the wrong size for the reduction. ```. #### Versions. <details>. ```. -----. anndata 0.7.4. scanpy 1.7.0. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 7.2.0. anndata 0.7.4. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. fa2 NA. fcsparser 0.2.1. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. markupsafe 1.1.1. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. networkx 2.5. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. palantir 1.0.0. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.6. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. rpy2 3.4.2. sca NA. scanpy 1.7.0. scipy 1.4.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. tqdm 4.48.2. traitlets 4.3.3. tzlocal NA. umap 0.4.6. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. -----. Session information updated at 2021-02-19 11:23. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:121,usability,confirm,confirmed,121,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:204,usability,confirm,confirmed,204,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:271,usability,Minim,Minimal,271,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:621,usability,input,input-,621,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:992,usability,tool,tools,992,"sc.tl.filter_rank_genes_groups fails; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-452-b327b6eab2bf> in <module>. 1 sc.tl.rank_genes_groups(adpt, 'stage', method='wilcoxon'). ----> 2 sc.tl.filter_rank_genes_groups(adpt, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.5,use_raw=False). 3 sc.get.rank_genes_groups_df(adpt,group=None,key='rank_genes_groups_filtered'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 759 sub_X = adata.raw[:, var_names].X if use_raw else adata[:, var_names].X. 760 in_group = adata.obs[groupby] == cluster. --> 761 X_in = sub_X[in_group]. 762 X_out = sub_X[~in_group]. 763 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/_index.py in __getitem__(self, key). 57 return self._get_arrayXint(row, col). 58 elif isinstance(col, slice):. ---> 59 return self._get_arrayXslice(row, col). 60 else: # row.ndim == 2. 61 if isinstance(col, INT_TYPES):. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/csr.py in _get_arrayXslice(self, row, col). 323 col = np.arange(*col.indices(self.shape[1])). 324 return self._get_arrayXarray(row, col). --> 325 return self._major_index_fancy(row)._get_submatrix(minor=col). 326 . 327 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/scipy/sparse/compressed.py in _m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/pull/1671:24,safety,test,tests,24,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:251,safety,review,review,251,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:24,testability,test,tests,24,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:251,testability,review,review,251,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:0,usability,Close,Close,0,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:102,usability,guid,guidelines,102,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:133,usability,guid,guide,133,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:229,usability,workflow,workflow,229,Close figures after all tests; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1672:81,energy efficiency,cool,cool,81,"Attempt server-side search; Inspired by @gokceneraslan pointing to [Hail.is]()'s cool doc search I did a little research. It looks like `readthedocs` might offer something similar: https://docs.readthedocs.io/en/stable/server-side-search.html. While those docs make it seem like it should be on by default, that doesn't seem to be the case. This is an attempt to figure out how to get nice search like that with read the docs. An alternative is to use [DocSearch](https://docsearch.algolia.com). First attempt: add [readthedocs-sphinx-search](https://readthedocs-sphinx-search.readthedocs.io/en/latest/index.html).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1672
https://github.com/scverse/scanpy/pull/1672:312,reliability,doe,doesn,312,"Attempt server-side search; Inspired by @gokceneraslan pointing to [Hail.is]()'s cool doc search I did a little research. It looks like `readthedocs` might offer something similar: https://docs.readthedocs.io/en/stable/server-side-search.html. While those docs make it seem like it should be on by default, that doesn't seem to be the case. This is an attempt to figure out how to get nice search like that with read the docs. An alternative is to use [DocSearch](https://docsearch.algolia.com). First attempt: add [readthedocs-sphinx-search](https://readthedocs-sphinx-search.readthedocs.io/en/latest/index.html).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1672
https://github.com/scverse/scanpy/issues/1673:483,interoperability,distribut,distributing-packages-using-setuptools,483,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:59,modifiability,paramet,parameters,59,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:336,modifiability,pac,package,336,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:455,modifiability,pac,packaging,455,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:496,modifiability,pac,packages-using-setuptools,496,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:141,testability,simpl,simple,141,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:133,usability,tool,tool,133,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:141,usability,simpl,simple,141,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:157,usability,tool,tool,157,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:205,usability,tool,tools,205,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:305,usability,tool,tools,305,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:476,usability,guid,guides,476,"Add more links to `project_url`; - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/pull/1674:77,integrability,rout,routines,77,Backport PR #1659 on branch 1.7.x (Fix passing of arguments between scrublet routines); Backport PR #1659: Fix passing of arguments between scrublet routines,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1674
https://github.com/scverse/scanpy/pull/1674:149,integrability,rout,routines,149,Backport PR #1659 on branch 1.7.x (Fix passing of arguments between scrublet routines); Backport PR #1659: Fix passing of arguments between scrublet routines,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1674
https://github.com/scverse/scanpy/issues/1675:397,availability,slo,slow,397,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:729,availability,ping,pinging,729,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:194,deployability,version,version,194,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:426,deployability,instal,installing,426,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:194,integrability,version,version,194,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:194,modifiability,version,version,194,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:497,performance,time,times,497,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:397,reliability,slo,slow,397,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:55,usability,document,document,55,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:154,usability,confirm,confirmed,154,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:237,usability,confirm,confirmed,237,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:664,usability,document,documented,664,"make pinndescent as part of requirements? (or at least document better); - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times. pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:. - afaik there's nowhere in the docs where this is documented. - it might be a good idea to just add it as default? pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/pull/1679:256,availability,state,state,256,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:701,availability,slo,sloppy,701,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:248,energy efficiency,current,current,248,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:256,integrability,state,state,256,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:467,performance,time,time,467,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:701,reliability,slo,sloppy,701,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:745,safety,review,review,745,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:745,testability,review,review,745,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1679:441,usability,clear,clearly,441,"enables highly_variable_genes_seurat_v3 to accept pseudocounts; fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8? we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1680:88,availability,Ping,Pinging,88,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:49,integrability,coupl,couple,49,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:267,integrability,compon,component,267,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:267,interoperability,compon,component,267,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:49,modifiability,coupl,couple,49,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:267,modifiability,compon,component,267,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:49,testability,coupl,couple,49,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:105,usability,user,users,105,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:136,usability,close,closes,136,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:178,usability,close,closes,178,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1680:242,usability,close,closes,242,address few docs issues; This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me). - closes #1434 clarify qc metric and normalize total @havardtl. - closes #827 clarify diff component indexing @veghp.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/issues/1682:142,deployability,API,API,142,"Plotting functions should show up in table of contents; It would be useful for plotting functions to show up in the table of contents for the API section of the docs, like they do for all other functions. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953042-a213c300-76be-11eb-94c6-51d7829fb6ec.png"">. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953055-a93ad100-76be-11eb-8702-94879bbb53dd.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1682
https://github.com/scverse/scanpy/issues/1682:142,integrability,API,API,142,"Plotting functions should show up in table of contents; It would be useful for plotting functions to show up in the table of contents for the API section of the docs, like they do for all other functions. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953042-a213c300-76be-11eb-94c6-51d7829fb6ec.png"">. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953055-a93ad100-76be-11eb-8702-94879bbb53dd.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1682
https://github.com/scverse/scanpy/issues/1682:142,interoperability,API,API,142,"Plotting functions should show up in table of contents; It would be useful for plotting functions to show up in the table of contents for the API section of the docs, like they do for all other functions. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953042-a213c300-76be-11eb-94c6-51d7829fb6ec.png"">. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953055-a93ad100-76be-11eb-8702-94879bbb53dd.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1682
https://github.com/scverse/scanpy/issues/1682:46,performance,content,contents,46,"Plotting functions should show up in table of contents; It would be useful for plotting functions to show up in the table of contents for the API section of the docs, like they do for all other functions. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953042-a213c300-76be-11eb-94c6-51d7829fb6ec.png"">. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953055-a93ad100-76be-11eb-8702-94879bbb53dd.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1682
https://github.com/scverse/scanpy/issues/1682:125,performance,content,contents,125,"Plotting functions should show up in table of contents; It would be useful for plotting functions to show up in the table of contents for the API section of the docs, like they do for all other functions. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953042-a213c300-76be-11eb-94c6-51d7829fb6ec.png"">. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953055-a93ad100-76be-11eb-8702-94879bbb53dd.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1682
https://github.com/scverse/scanpy/issues/1682:247,usability,user,user-images,247,"Plotting functions should show up in table of contents; It would be useful for plotting functions to show up in the table of contents for the API section of the docs, like they do for all other functions. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953042-a213c300-76be-11eb-94c6-51d7829fb6ec.png"">. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953055-a93ad100-76be-11eb-8702-94879bbb53dd.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1682
https://github.com/scverse/scanpy/issues/1682:385,usability,user,user-images,385,"Plotting functions should show up in table of contents; It would be useful for plotting functions to show up in the table of contents for the API section of the docs, like they do for all other functions. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953042-a213c300-76be-11eb-94c6-51d7829fb6ec.png"">. <img width=""303"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/108953055-a93ad100-76be-11eb-8702-94879bbb53dd.png"">.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1682
https://github.com/scverse/scanpy/pull/1683:0,deployability,Updat,Update,0,Update release notes for 1.7.1; Add some straggling release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1683
https://github.com/scverse/scanpy/pull/1683:7,deployability,releas,release,7,Update release notes for 1.7.1; Add some straggling release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1683
https://github.com/scverse/scanpy/pull/1683:52,deployability,releas,release,52,Update release notes for 1.7.1; Add some straggling release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1683
https://github.com/scverse/scanpy/pull/1683:0,safety,Updat,Update,0,Update release notes for 1.7.1; Add some straggling release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1683
https://github.com/scverse/scanpy/pull/1683:0,security,Updat,Update,0,Update release notes for 1.7.1; Add some straggling release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1683
https://github.com/scverse/scanpy/pull/1685:0,safety,test,test,0,test pre-commit yaml; Why is nothing happening. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1685:268,safety,review,review,268,test pre-commit yaml; Why is nothing happening. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1685:0,testability,test,test,0,test pre-commit yaml; Why is nothing happening. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1685:268,testability,review,review,268,test pre-commit yaml; Why is nothing happening. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1685:119,usability,guid,guidelines,119,test pre-commit yaml; Why is nothing happening. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1685:150,usability,guid,guide,150,test pre-commit yaml; Why is nothing happening. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1685:246,usability,workflow,workflow,246,test pre-commit yaml; Why is nothing happening. <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1686:35,deployability,Updat,Update,35,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:42,deployability,releas,release,42,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:87,deployability,Updat,Update,87,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:94,deployability,releas,release,94,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:35,safety,Updat,Update,35,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:87,safety,Updat,Update,87,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:35,security,Updat,Update,35,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:87,security,Updat,Update,87,Backport PR #1683 on branch 1.7.x (Update release notes for 1.7.1); Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/issues/1688:290,usability,user,user-images,290,"Score of rank_genes_groups; Hello, I'm new to scanpy. Recently, I use scanpy on scRNA data, run . ```. sc.tl.rank_genes_groups(adata, 'marker_cluster', groups=['NK_ 8'], method='wilcoxon'). sc.pl.rank_genes_groups(adata, groups=['NK_ 8'], n_genes=20). ```. get the result. ![image](https://user-images.githubusercontent.com/49113803/108975925-f79d9f00-76c1-11eb-93cb-3b854c484d59.png). Can anyone tell me what's the score means here? How it be calculated?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1688
https://github.com/scverse/scanpy/pull/1689:38,integrability,coupl,couple,38,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1689:82,integrability,coupl,couple,82,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1689:38,modifiability,coupl,couple,38,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1689:82,modifiability,coupl,couple,82,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1689:48,performance,time,times,48,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1689:139,security,Sign,Signed-off-by,139,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1689:38,testability,coupl,couple,38,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1689:82,testability,coupl,couple,82,"add flake8 pre-commit; I intervened a couple of times manually and switched off a couple of checks, but it should be a strong improvement. Signed-off-by: Zethson <lukas.heumos@posteo.net>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689
https://github.com/scverse/scanpy/pull/1690:11,safety,test,tests,11,rm call of tests.blackdiff; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1690:248,safety,review,review,248,rm call of tests.blackdiff; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1690:11,testability,test,tests,11,rm call of tests.blackdiff; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1690:248,testability,review,review,248,rm call of tests.blackdiff; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1690:99,usability,guid,guidelines,99,rm call of tests.blackdiff; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1690:130,usability,guid,guide,130,rm call of tests.blackdiff; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1690:226,usability,workflow,workflow,226,rm call of tests.blackdiff; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1691:148,deployability,version,version,148,"Fix print_versions for python<3.8; `importlib_metadata` does not have a `__version__` attribute. This breaks `sinfo`. We can just skip getting it's version. Also, test that `print_versions` works. Fixes #1437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1691
https://github.com/scverse/scanpy/pull/1691:148,integrability,version,version,148,"Fix print_versions for python<3.8; `importlib_metadata` does not have a `__version__` attribute. This breaks `sinfo`. We can just skip getting it's version. Also, test that `print_versions` works. Fixes #1437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1691
https://github.com/scverse/scanpy/pull/1691:148,modifiability,version,version,148,"Fix print_versions for python<3.8; `importlib_metadata` does not have a `__version__` attribute. This breaks `sinfo`. We can just skip getting it's version. Also, test that `print_versions` works. Fixes #1437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1691
https://github.com/scverse/scanpy/pull/1691:56,reliability,doe,does,56,"Fix print_versions for python<3.8; `importlib_metadata` does not have a `__version__` attribute. This breaks `sinfo`. We can just skip getting it's version. Also, test that `print_versions` works. Fixes #1437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1691
https://github.com/scverse/scanpy/pull/1691:163,safety,test,test,163,"Fix print_versions for python<3.8; `importlib_metadata` does not have a `__version__` attribute. This breaks `sinfo`. We can just skip getting it's version. Also, test that `print_versions` works. Fixes #1437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1691
https://github.com/scverse/scanpy/pull/1691:163,testability,test,test,163,"Fix print_versions for python<3.8; `importlib_metadata` does not have a `__version__` attribute. This breaks `sinfo`. We can just skip getting it's version. Also, test that `print_versions` works. Fixes #1437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1691
https://github.com/scverse/scanpy/pull/1693:95,testability,coverag,coverage,95,add codecov so we can have a badge to point to; Adding upload to code cov so we can point to a coverage badge,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1693
https://github.com/scverse/scanpy/issues/1694:395,availability,consist,consistent,395,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:480,energy efficiency,current,currently,480,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:310,interoperability,format,formatting,310,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:321,interoperability,standard,standard,321,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:367,interoperability,format,formatting,367,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:406,interoperability,format,formatting,406,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:496,interoperability,format,formats,496,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:653,modifiability,variab,variable,653,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:621,reliability,pra,practices,621,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:831,reliability,doe,does,831,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1694:395,usability,consist,consistent,395,"Move from 88 to 120 characters with Black; This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1698:129,modifiability,variab,variable,129,Adding Moran's I calculation to Scanpy; Could you add Moran's I calculation to Scanpy? It could be used in scIB and to also find variable genes across embedding (could be an alternative to SEMITONES that takes a while to be computed).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698
https://github.com/scverse/scanpy/pull/1695:15,performance,parallel,parallelism,15,"Use joblib for parallelism in regress_out; Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695
https://github.com/scverse/scanpy/pull/1695:149,performance,parallel,parallelize,149,"Use joblib for parallelism in regress_out; Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695
https://github.com/scverse/scanpy/pull/1695:216,safety,prevent,prevent,216,"Use joblib for parallelism in regress_out; Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695
https://github.com/scverse/scanpy/pull/1695:269,safety,test,test,269,"Use joblib for parallelism in regress_out; Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695
https://github.com/scverse/scanpy/pull/1695:216,security,preven,prevent,216,"Use joblib for parallelism in regress_out; Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695
https://github.com/scverse/scanpy/pull/1695:269,testability,test,test,269,"Use joblib for parallelism in regress_out; Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695
https://github.com/scverse/scanpy/issues/1696:5,availability,ERROR,ERROR,5,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:222,availability,error,error,222,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:242,availability,ERROR,ERROR,242,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:281,availability,error,error,281,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:5,performance,ERROR,ERROR,5,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:222,performance,error,error,222,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:242,performance,ERROR,ERROR,242,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:281,performance,error,error,281,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:334,reliability,Doe,Does,334,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:5,safety,ERROR,ERROR,5,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:222,safety,error,error,222,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:242,safety,ERROR,ERROR,242,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:281,safety,error,error,281,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:5,usability,ERROR,ERROR,5,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:222,usability,error,error,222,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:242,usability,ERROR,ERROR,242,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:281,usability,error,error,281,"LLVM ERROR: Symbol not found: __svml_sqrtf8; Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2. scanpy = 1.7.1. Does anyone encounter similar issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1697:172,deployability,version,versions,172,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:585,deployability,modul,module,585,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:683,deployability,modul,module-attributes,683,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:737,deployability,version,versions,737,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:152,energy efficiency,schedul,schedule,152,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:278,energy efficiency,cool,cool,278,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:172,integrability,version,versions,172,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:737,integrability,version,versions,737,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:103,modifiability,pac,packages,103,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:172,modifiability,version,versions,172,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:585,modifiability,modul,module,585,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:683,modifiability,modul,module-attributes,683,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:737,modifiability,version,versions,737,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:152,performance,schedul,schedule,152,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:585,safety,modul,module,585,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:683,safety,modul,module-attributes,683,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:575,security,access,access,575,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:673,security,access,access-to-module-attributes,673,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:43,usability,support,support,43,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:564,usability,Custom,Customized,564,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:656,usability,custom,customization-of-access-to-module-attributes,656,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:709,usability,user,users,709,"Drop python 3.6 for 1.8; Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this? Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations). * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools). * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1701:431,availability,error,error,431,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:470,availability,state,states,470,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2252,availability,error,error,2252,"if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4630,availability,error,error,4630,"n_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4644,availability,down,downgraded,4644,"conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolki",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4680,availability,error,error,4680,"scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:161,deployability,version,version,161,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2588,deployability,modul,module,2588,". 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2869,deployability,log,log,2869,"9', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6356,deployability,log,logical,6356," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6410,deployability,updat,updated,6410," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6364,energy efficiency,CPU,CPU,6364," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6368,energy efficiency,core,cores,6368," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:161,integrability,version,version,161,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:470,integrability,state,states,470,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:879,integrability,sub,subpopulation,879,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:291,interoperability,standard,standard,291,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:870,interoperability,specif,specific,870,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:161,modifiability,version,version,161,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2588,modifiability,modul,module,2588,". 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2785,modifiability,pac,packages,2785,"olors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:3113,modifiability,layer,layer,3113," '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:3392,modifiability,pac,packages,3392,"s, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute leng",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:3674,modifiability,pac,packages,3674,"e(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:3994,modifiability,pac,packages,3994,"r_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:5049,modifiability,deco,decorator,5049,"lf, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:5519,modifiability,pac,packaging,5519," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6233,modifiability,pac,packaged,6233," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:431,performance,error,error,431,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2252,performance,error,error,2252,"if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4630,performance,error,error,4630,"n_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4680,performance,error,error,4680,"scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6364,performance,CPU,CPU,6364," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:9,reliability,doe,doesn,9,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:936,reliability,doe,doesn,936,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:431,safety,error,error,431,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2252,safety,error,error,2252,"if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2561,safety,input,input-,2561,"FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2588,safety,modul,module,2588,". 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2869,safety,log,log,2869,"9', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4630,safety,error,error,4630,"n_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4680,safety,error,error,4680,"scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6356,safety,log,logical,6356," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6410,safety,updat,updated,6410," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2869,security,log,log,2869,"9', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4931,security,certif,certifi,4931,"ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. soc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4979,security,cryptograph,cryptography,4979,"3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:5932,security,soc,socks,5932," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6356,security,log,logical,6356," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6390,security,Session,Session,6390," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6410,security,updat,updated,6410," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2517,testability,Trace,Traceback,2517,"'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_sub",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2869,testability,log,log,2869,"9', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6356,testability,log,logical,6356," 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.7.4. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.23.0. ruamel NA. scanpy 1.7.1. scipy 1.4.1. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.22.2.post1. sniffio 1.2.0. socks 1.7.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.3.10. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zmq 21.0.1. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.5. notebook 6.2.0. -----. Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]. Linux-4.15.0-112-generic-x86_64-with-glibc2.10. 60 logical CPU cores, x86_64. -----. Session information updated at 2021-03-01 09:45. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:121,usability,confirm,confirmed,121,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:205,usability,confirm,confirmed,205,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:431,usability,error,error,431,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:451,usability,visual,visualise,451,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:667,usability,user,user-images,667,"`scanpy` doesn't plot labels in UMAP; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:1150,usability,user,user-images,1150,"test version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python. sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False). ```. ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#0000",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2252,usability,error,error,2252,"if there was something odd with the labels, but they are there. . ```python. combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',. 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',. 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2561,usability,input,input-,2561,"FB5', 'Mast', 'Meso', 'MØ',. 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',. 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],. dtype='object'). ```. They even have assigned colours: . ```. ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]). ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python. marker_genes = ['PERM1', 'GAB3', 'G6PD']. combined_bbknn.var_names_make_unique(). sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). ```. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-17-3392793686cd> in <module>. 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']. 2 combined_bbknn.var_names_make_unique(). ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds). 949 return dp. 950 else:. --> 951 dp.make_figure(). 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save). 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self). 730 if self.legends_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4469,usability,user,user-images,4469,"ds_width > 0:. 731 legend_ax = self.fig.add_subplot(gs[0, 1]). --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize). 733 . 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4630,usability,error,error,4630,"n_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4680,usability,error,error,4680,"scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4710,usability,help,help,4710,"n _plot_legend(self, legend_ax, return_ax_dict, normalize). 490 if self.show_size_legend:. 491 size_legend_ax = fig.add_subplot(legend_gs[1]). --> 492 self._plot_size_legend(size_legend_ax). 493 return_ax_dict['size_legend_ax'] = size_legend_ax. 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax). 418 # a descending range that is afterwards inverted is used. 419 # to guarantee that dot_max is in the legend. --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]. 421 if self.dot_min != 0 or self.dot_max != 1:. 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length. ```. and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----. anndata 0.7.4. scanpy 1.7.1. sinfo 0.3.1. -----. OpenSSL 20.0.1. PIL 8.1.0. anndata 0.7.4. annoy NA. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bbknn NA. brotli NA. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. cryptography 3.3.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. idna 2.10. igraph 0.9.0. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.2. jupyterlab_server 2.1.3. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.0. llvmlite 0.32.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.49.1. numexpr 2.7.2. numpy 1.18.2. packaging 20.8. pandas 1.0.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.14. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparse",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/pull/1702:201,availability,down,downgrades,201,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:185,deployability,instal,install,185,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:220,deployability,instal,install,220,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:232,deployability,instal,installed,232,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:279,deployability,contain,contains,279,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:300,deployability,version,version,300,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:300,integrability,version,version,300,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:429,interoperability,specif,specifications,429,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:451,interoperability,distribut,distribution-format,451,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:300,modifiability,version,version,300,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:408,modifiability,pac,packaging,408,"Go back to regular pip; Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version). 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1703:236,safety,review,review,236,deprecate scvi; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703
https://github.com/scverse/scanpy/pull/1703:236,testability,review,review,236,deprecate scvi; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703
https://github.com/scverse/scanpy/pull/1703:87,usability,guid,guidelines,87,deprecate scvi; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703
https://github.com/scverse/scanpy/pull/1703:118,usability,guid,guide,118,deprecate scvi; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703
https://github.com/scverse/scanpy/pull/1703:214,usability,workflow,workflow,214,deprecate scvi; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703
https://github.com/scverse/scanpy/pull/1704:17,safety,Test,Testing,17,codecov comment; Testing codecov comment to make seeing coverage easier.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1704
https://github.com/scverse/scanpy/pull/1704:17,testability,Test,Testing,17,codecov comment; Testing codecov comment to make seeing coverage easier.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1704
https://github.com/scverse/scanpy/pull/1704:56,testability,coverag,coverage,56,codecov comment; Testing codecov comment to make seeing coverage easier.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1704
https://github.com/scverse/scanpy/issues/1705:167,deployability,depend,dependent,167,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:167,integrability,depend,dependent,167,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:19,modifiability,exten,extend,19,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:92,modifiability,exten,extend,92,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:167,modifiability,depend,dependent,167,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:167,safety,depend,dependent,167,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:545,security,modif,modifying,545,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:167,testability,depend,dependent,167,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:321,usability,user,user-images,321,"Dotplot labels can extend off plot; @fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>. <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1706:2702,availability,operat,operation,2702,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:176,deployability,version,version,176,"pp.neighbors returns edgeless graph for n_neighbors=1; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1156,deployability,version,version,1156,"s on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_out",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1373,deployability,modul,module,1373,"eighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2753,deployability,Version,Versions,2753,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2778,deployability,log,logging,2778,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2372,energy efficiency,core,core,2372,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2692,energy efficiency,reduc,reduction,2692,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:176,integrability,version,version,176,"pp.neighbors returns edgeless graph for n_neighbors=1; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1156,integrability,version,version,1156,"s on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_out",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2753,integrability,Version,Versions,2753,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:176,modifiability,version,version,176,"pp.neighbors returns edgeless graph for n_neighbors=1; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:970,modifiability,pac,packages,970,"pp.neighbors returns edgeless graph for n_neighbors=1; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1156,modifiability,version,version,1156,"s on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_out",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1373,modifiability,modul,module,1373,"eighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1554,modifiability,pac,packages,1554,"e (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1933,modifiability,pac,packages,1933,"]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2357,modifiability,pac,packages,2357,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2753,modifiability,Version,Versions,2753,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2165,performance,parallel,parallel,2165,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1346,safety,input,input-,1346,"wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1373,safety,modul,module,1373,"eighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2778,safety,log,logging,2778,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2733,security,ident,identity,2733,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2778,security,log,logging,2778,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1302,testability,Trace,Traceback,1302,"bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.elimin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2778,testability,log,logging,2778,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:136,usability,confirm,confirmed,136,"pp.neighbors returns edgeless graph for n_neighbors=1; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:219,usability,confirm,confirmed,219,"pp.neighbors returns edgeless graph for n_neighbors=1; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:540,usability,Minim,Minimal,540,"pp.neighbors returns edgeless graph for n_neighbors=1; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I worked on a very small bulk dataset recently (`n_obs = 15`), and wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1346,usability,input,input-,1346,"wanted to try a 1-nearest-neighbor graph for the UMAP. However, edgeless graphs are returned for `n_neighbors=1`. I would expect that each node would have at least one edge in this case. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:1570,usability,tool,tools,1570,"copy&paste without having any data). ```python. import scanpy as sc. adata = sc.datasets.blobs(n_observations=5). sc.pp.neighbors(adata, n_neighbors=1). print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). sc.tl.umap(adata). ```. ```pytb. Connectivities:. [[0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]. [0. 0. 0. 0. 0.]]. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2948,usability,learn,learn,2948,"ities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata. after removing the cwd from sys.path. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-28-2906b54049c5> in <module>. 3 sc.pp.neighbors(adata, n_neighbors=1). 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A). ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 194 neigh_params.get('metric', 'euclidean'),. 195 neigh_params.get('metric_kwds', {}),. --> 196 verbose=settings.verbosity > 3,. 197 ). 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1022 n_epochs = 200. 1023 . -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0. 1025 graph.eliminate_zeros(). 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where). 37 def _amax(a, axis=None, out=None, keepdims=False,. 38 initial=_NoValue, where=True):. ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where). 40 . 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions. For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/pull/1707:39,deployability,depend,dependent,39,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:290,deployability,contain,contained,290,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:386,deployability,depend,dependency,386,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:39,integrability,depend,dependent,39,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:154,integrability,inject,injection,154,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:386,integrability,depend,dependency,386,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:39,modifiability,depend,dependent,39,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:386,modifiability,depend,dependency,386,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:256,reliability,doe,does,256,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:39,safety,depend,dependent,39,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:386,safety,depend,dependency,386,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:154,security,inject,injection,154,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:39,testability,depend,dependent,39,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:386,testability,depend,dependency,386,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:199,usability,workflow,workflows,199,"Add sparsificiation step before sparse-dependent Scrublet calls; This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/issues/1708:177,deployability,version,version,177,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:878,deployability,modul,module,878,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2831,deployability,Version,Versions,2831,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:355,energy efficiency,adapt,adapt,355,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2574,energy efficiency,core,core,2574,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:177,integrability,version,version,177,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:355,integrability,adapt,adapt,355,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2831,integrability,Version,Versions,2831,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:355,interoperability,adapt,adapt,355,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:177,modifiability,version,version,177,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:355,modifiability,adapt,adapt,355,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:878,modifiability,modul,module,878,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:1136,modifiability,pac,packages,1136,"firmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:1247,modifiability,layer,layer,1247,"he master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:1430,modifiability,pac,packages,1430,", qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 73",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:1533,modifiability,layer,layer,1533,"d different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:1767,modifiability,pac,packages,1767,"------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2054,modifiability,pac,packages,2054,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2313,modifiability,pac,packages,2313,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2559,modifiability,pac,packages,2559,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2831,modifiability,Version,Versions,2831,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:1279,performance,parallel,parallel,1279,"To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:1568,performance,parallel,parallel,1568,"it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\nump",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:852,safety,input,input-,852,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:878,safety,modul,module,878,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:808,testability,Trace,Traceback,808,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:137,usability,confirm,confirmed,137,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:220,usability,confirm,confirmed,220,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:368,usability,workflow,workflow,368,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:852,usability,input,input-,852,"Problems with Drosophila genome due to gene called nan; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-6-455e630e3278> in <module>. 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'. ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2941,usability,learn,learn,2941,"metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 286 X.eliminate_zeros(). 287 . --> 288 obs_metrics = describe_obs(. 289 adata,. 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 119 for qc_var in qc_vars:. 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (. --> 121 X[:, adata.var[qc_var].values].sum(axis=1). 122 ). 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key). 49 return self._get_sliceXslice(row, col). 50 elif col.ndim == 1:. ---> 51 return self._get_sliceXarray(row, col). 52 raise IndexError('index results in >2 dimensions'). 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col). 321 . 322 def _get_sliceXarray(self, row, col):. --> 323 return self._major_slice(row)._minor_index_fancy(col). 324 . 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx). 737 """""". 738 idx_dtype = self.indices.dtype. --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(). 740 . 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like). 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like). 101 . --> 102 return array(a, dtype, copy=False, order=order). 103 . 104 . ValueError: cannot convert float NaN to integer. ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1709:619,deployability,api,api,619,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:619,integrability,api,api,619,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:619,interoperability,api,api,619,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:125,modifiability,paramet,parameters,125,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:402,modifiability,pac,package,402,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:207,testability,simpl,simple,207,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:199,usability,tool,tool,199,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:207,usability,simpl,simple,207,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:223,usability,tool,tool,223,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:271,usability,tool,tools,271,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/issues/1709:371,usability,tool,tools,371,"Matrixplot alternative group statistics; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/pull/1710:50,performance,parallel,parallelism,50,Backport PR #1695 on branch 1.7.x (Use joblib for parallelism in regress_out); Backport PR #1695: Use joblib for parallelism in regress_out,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1710
https://github.com/scverse/scanpy/pull/1710:113,performance,parallel,parallelism,113,Backport PR #1695 on branch 1.7.x (Use joblib for parallelism in regress_out); Backport PR #1695: Use joblib for parallelism in regress_out,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1710
https://github.com/scverse/scanpy/pull/1711:74,deployability,depend,dependent,74,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:159,deployability,depend,dependent,159,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:74,integrability,depend,dependent,74,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:159,integrability,depend,dependent,159,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:74,modifiability,depend,dependent,74,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:159,modifiability,depend,dependent,159,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:74,safety,depend,dependent,74,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:159,safety,depend,dependent,159,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:74,testability,depend,dependent,74,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1711:159,testability,depend,dependent,159,Backport PR #1707 on branch 1.7.x (Add sparsificiation step before sparse-dependent Scrublet calls); Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1712:26,deployability,fail,failing,26,Backport PR #1587: Attach failing plots to CI results; Manual backport of #1587,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1712
https://github.com/scverse/scanpy/pull/1712:26,reliability,fail,failing,26,Backport PR #1587: Attach failing plots to CI results; Manual backport of #1587,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1712
https://github.com/scverse/scanpy/pull/1713:4,deployability,version,version,4,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:86,deployability,version,version,86,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:167,deployability,version,version,167,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:4,integrability,version,version,4,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:86,integrability,version,version,86,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:167,integrability,version,version,167,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:4,modifiability,version,version,4,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:86,modifiability,version,version,86,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:167,modifiability,version,version,167,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:42,reliability,doe,does,42,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:103,safety,detect,detected,103,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:196,safety,test,tests,196,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:103,security,detect,detected,103,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:196,testability,test,tests,196,"Fix version on Travis; By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/issues/1714:16,availability,down,download,16,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:775,availability,error,error,775,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2187,availability,error,error,2187,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2282,availability,error,error,2282,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2609,availability,error,error,2609,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2631,availability,Error,Error,2631,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:153,deployability,version,version,153,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:920,deployability,modul,module,920,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2693,deployability,Version,Versions,2693,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2866,deployability,log,logging,2866,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:153,integrability,version,version,153,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2693,integrability,Version,Versions,2693,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:153,modifiability,version,version,153,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:920,modifiability,modul,module,920,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1053,modifiability,pac,packages,1053," this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, respon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1214,modifiability,pac,packages,1214,"sts on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1385,modifiability,pac,packages,1385,"ote**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1543,modifiability,pac,packages,1543," to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_defaul",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2693,modifiability,Version,Versions,2693,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:775,performance,error,error,775,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1927,performance,time,timeout,1927,"ata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2187,performance,error,error,2187,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2282,performance,error,error,2282,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2609,performance,error,error,2609,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2631,performance,Error,Error,2631,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:775,safety,error,error,775,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:920,safety,modul,module,920,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1927,safety,timeout,timeout,1927,"ata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2187,safety,error,error,2187,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2282,safety,error,error,2282,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2609,safety,error,error,2609,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2631,safety,Error,Error,2631,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2866,safety,log,logging,2866,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2866,security,log,logging,2866,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:827,testability,Trace,Traceback,827,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1754,testability,context,contextlib,1754,"ytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 nump",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2866,testability,log,logging,2866,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:113,usability,confirm,confirmed,113,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:196,usability,confirm,confirmed,196,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:307,usability,visual,visualization,307,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:414,usability,guid,guide,414,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:469,usability,minim,minimal-bug-reports,469,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:575,usability,Minim,Minimal,575,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:775,usability,error,error,775,"spatial dataset download issue; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```when I run . adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb. [Paste the error output produced by the above code here]. ```. Traceback (most recent call last):. File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>. adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2187,usability,error,error,2187,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2282,usability,error,error,2282,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2609,usability,error,error,2609,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2631,usability,Error,Error,2631,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2803,usability,learn,learn,2803,"s.visium_sge(sample_id=""V1_Human_Lymph_Node""). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge. _download_visium_dataset(sample_id). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset. _utils.check_presence_download(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download. _download(backup_url, filename). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download. urlretrieve(url, str(path), reporthook=update_to). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve. with contextlib.closing(urlopen(url, data)) as fp:. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open. response = meth(req, response). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response. response = self.parent.error(. File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error. return self._call_chain(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain. result = func(*args). File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default. raise HTTPError(req.full_url, code, msg, hdrs, fp). urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>. scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/pull/1715:623,availability,operat,operation,623,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:141,deployability,integr,integrates,141,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:323,deployability,version,version,323,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:419,energy efficiency,core,core,419,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:141,integrability,integr,integrates,141,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:323,integrability,version,version,323,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:896,integrability,batch,batches,896,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:141,interoperability,integr,integrates,141,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:141,modifiability,integr,integrates,141,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:323,modifiability,version,version,323,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:607,modifiability,layer,layers,607,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:896,performance,batch,batches,896,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:987,performance,memor,memory-efficient,987,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:141,reliability,integr,integrates,141,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:1331,reliability,doe,does,1331,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:1587,reliability,doe,does,1587,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:356,safety,review,review,356,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:1627,safety,input,input,1627,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:141,security,integr,integrates,141,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:141,testability,integr,integrates,141,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:356,testability,review,review,356,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:595,usability,support,support,595,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:875,usability,support,support,875,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:987,usability,memor,memory-efficient,987,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:1492,usability,user,user,1492,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:1627,usability,input,input,1627,"Normalization and gene selection by analytical Pearson residuals ; Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:. - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc). - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA. - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed! Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/issues/1716:104,modifiability,paramet,parameters,104,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:381,modifiability,pac,package,381,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:741,security,barrier,barrier,741,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:186,testability,simpl,simple,186,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:178,usability,tool,tool,178,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:186,usability,simpl,simple,186,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:202,usability,tool,tool,202,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:250,usability,tool,tools,250,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:350,usability,tool,tools,350,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:484,usability,tool,tools,484,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1716:511,usability,tool,tools,511,"Gitter for scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1718:361,integrability,sub,substitute,361,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:37,interoperability,coordinat,coordinate,37,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:67,interoperability,coordinat,coordinate,67,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:170,interoperability,coordinat,coordinate,170,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:203,interoperability,coordinat,coordinate,203,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:243,interoperability,coordinat,coordinate,243,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:316,interoperability,coordinat,coordinate,316,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:392,interoperability,coordinat,coordinate,392,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1718:422,interoperability,coordinat,coordinate,422,"How can i replace the adata's X_umap coordinate with seurat's umap coordinate ; Hi @ALL,. I had the scVelo object of 'adata' to run the scv.tl.umap(adata) with different coordinate bewteen seurat's umap coordinate and the scVelo object's umap coordinate. So, i hope to visulize the umap plot using the seurat's umap coordinate. based on this request, i hope to substitute the scVelo's X_umap coordinate with seurat's umap coordinate. how can i do for above request? any advice would be appreciated. Best,. hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718
https://github.com/scverse/scanpy/issues/1719:296,deployability,depend,dependent,296,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:423,deployability,integr,integrating,423,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:296,integrability,depend,dependent,296,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:423,integrability,integr,integrating,423,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:588,integrability,interfac,interface,588,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:423,interoperability,integr,integrating,423,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:588,interoperability,interfac,interface,588,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:296,modifiability,depend,dependent,296,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:423,modifiability,integr,integrating,423,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:588,modifiability,interfac,interface,588,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:125,performance,time,time,125,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:423,reliability,integr,integrating,423,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:296,safety,depend,dependent,296,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:390,safety,prevent,preventing,390,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:48,security,team,team,48,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:390,security,preven,preventing,390,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:423,security,integr,integrating,423,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:296,testability,depend,dependent,296,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:423,testability,integr,integrating,423,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:566,usability,support,support,566,"dealing with duplicated gene symbols; Hi Scanpy team! After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general? Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1720:274,deployability,continu,continuously,274,"Can PDF/SVG saved figures maintain text as text for further processing?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG. format with the hope to be able and import it on Illustrator for further processing for publication. purposes. Everything works fine with the images, but the text of the labels is not any more recognized . as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly? Best,. Anastasia.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/issues/1720:438,integrability,pub,publication,438,"Can PDF/SVG saved figures maintain text as text for further processing?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG. format with the hope to be able and import it on Illustrator for further processing for publication. purposes. Everything works fine with the images, but the text of the labels is not any more recognized . as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly? Best,. Anastasia.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/issues/1720:350,interoperability,format,format,350,"Can PDF/SVG saved figures maintain text as text for further processing?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG. format with the hope to be able and import it on Illustrator for further processing for publication. purposes. Everything works fine with the images, but the text of the labels is not any more recognized . as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly? Best,. Anastasia.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/issues/1720:26,modifiability,maintain,maintain,26,"Can PDF/SVG saved figures maintain text as text for further processing?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG. format with the hope to be able and import it on Illustrator for further processing for publication. purposes. Everything works fine with the images, but the text of the labels is not any more recognized . as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly? Best,. Anastasia.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/issues/1720:157,modifiability,paramet,parameters,157,"Can PDF/SVG saved figures maintain text as text for further processing?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG. format with the hope to be able and import it on Illustrator for further processing for publication. purposes. Everything works fine with the images, but the text of the labels is not any more recognized . as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly? Best,. Anastasia.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/issues/1720:26,safety,maintain,maintain,26,"Can PDF/SVG saved figures maintain text as text for further processing?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG. format with the hope to be able and import it on Illustrator for further processing for publication. purposes. Everything works fine with the images, but the text of the labels is not any more recognized . as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly? Best,. Anastasia.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/issues/1720:669,testability,plan,plan,669,"Can PDF/SVG saved figures maintain text as text for further processing?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG. format with the hope to be able and import it on Illustrator for further processing for publication. purposes. Everything works fine with the images, but the text of the labels is not any more recognized . as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly? Best,. Anastasia.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/pull/1721:0,safety,test,test,0,"test pr; ignore me, just wanted to see how something was handled on the github ui.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1721
https://github.com/scverse/scanpy/pull/1721:0,testability,test,test,0,"test pr; ignore me, just wanted to see how something was handled on the github ui.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1721
https://github.com/scverse/scanpy/pull/1721:79,usability,ui,ui,79,"test pr; ignore me, just wanted to see how something was handled on the github ui.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1721
https://github.com/scverse/scanpy/pull/1722:246,safety,review,review,246,Alexmascension ecosystem; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722
https://github.com/scverse/scanpy/pull/1722:246,testability,review,review,246,Alexmascension ecosystem; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722
https://github.com/scverse/scanpy/pull/1722:97,usability,guid,guidelines,97,Alexmascension ecosystem; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722
https://github.com/scverse/scanpy/pull/1722:128,usability,guid,guide,128,Alexmascension ecosystem; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722
https://github.com/scverse/scanpy/pull/1722:224,usability,workflow,workflow,224,Alexmascension ecosystem; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722
https://github.com/scverse/scanpy/issues/1723:117,modifiability,paramet,parameters,117,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:394,modifiability,pac,package,394,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:199,testability,simpl,simple,199,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:191,usability,tool,tool,191,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:199,usability,simpl,simple,199,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:215,usability,tool,tool,215,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:263,usability,tool,tools,263,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:363,usability,tool,tools,363,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:525,usability,statu,status,525,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1723:570,usability,user,user-images,570,Allow seaborn color map strings; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1724:966,availability,cluster,clustermaps,966,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:0,deployability,Integr,Integration,0,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:795,deployability,integr,integration,795,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:966,deployability,cluster,clustermaps,966,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1105,deployability,integr,integration,1105,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1597,deployability,contain,contain,1597,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1854,deployability,integr,integrate,1854,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:257,energy efficiency,estimat,estimate,257,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:701,energy efficiency,reduc,reduction,701,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:955,energy efficiency,heat,heat-maps,955,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1035,energy efficiency,model,modeled,1035,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1239,energy efficiency,reduc,reduction,1239,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:0,integrability,Integr,Integration,0,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:795,integrability,integr,integration,795,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1105,integrability,integr,integration,1105,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1854,integrability,integr,integrate,1854,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:0,interoperability,Integr,Integration,0,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:795,interoperability,integr,integration,795,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1105,interoperability,integr,integration,1105,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1405,interoperability,distribut,distribution,1405,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1854,interoperability,integr,integrate,1854,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:0,modifiability,Integr,Integration,0,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:795,modifiability,integr,integration,795,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1105,modifiability,integr,integration,1105,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1551,modifiability,layer,layer,1551,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1585,modifiability,layer,layers,1585,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1854,modifiability,integr,integrate,1854,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1737,performance,content,contents,1737,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:0,reliability,Integr,Integration,0,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:795,reliability,integr,integration,795,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1105,reliability,integr,integration,1105,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1854,reliability,integr,integrate,1854,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:580,safety,input,input,580,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:760,safety,input,input,760,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:785,safety,input,input,785,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:0,security,Integr,Integration,0,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:795,security,integr,integration,795,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1035,security,model,modeled,1035,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1051,security,sign,significant,1051,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1105,security,integr,integration,1105,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1854,security,integr,integrate,1854,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:0,testability,Integr,Integration,0,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:795,testability,integr,integration,795,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1105,testability,integr,integration,1105,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1854,testability,integr,integrate,1854,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:95,usability,tool,tools,95,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:248,usability,tool,tools,248,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:459,usability,tool,tools,459,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:550,usability,tool,tools,550,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:580,usability,input,input,580,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:760,usability,input,input,760,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:785,usability,input,input,785,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1124,usability,tool,tools,1124,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1705,usability,user,user,1705,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1868,usability,tool,tools,1868,"Integration of dorothea and progeny; Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:. https://github.com/saezlab/dorothea-py. https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: . 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:. 	* Used as input for NN. 	* Used as input for integration methods. 2) New data assays (`X`). Examples of usage:. 	* Plot feature activities in projections such as PCA or UMAP. 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc. 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1725:2803,availability,Sli,Slicing,2803,"ult['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonsche",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2824,availability,sli,slice,2824,"ean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3118,availability,Sli,Slicing,3118,"'means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3139,availability,sli,slice,3139,"). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:236,deployability,version,version,236,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2895,deployability,version,version,2895,"wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3210,deployability,version,version,3210,"at the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3337,deployability,Version,Versions,3337," _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4797,deployability,log,logical,4797,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4851,deployability,updat,updated,4851,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4805,energy efficiency,CPU,CPU,4805,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4809,energy efficiency,core,cores,4809,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:236,integrability,version,version,236,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:518,integrability,batch,batches,518,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:719,integrability,batch,batch,719,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:823,integrability,batch,batch,823,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:1516,integrability,batch,batch,1516,"atches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2037,integrability,batch,batch,2037,"ere:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2254,integrability,batch,batch,2254," reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2293,integrability,batch,batch,2293," np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_gene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2409,integrability,batch,batch,2409,"get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2678,integrability,batch,batch,2678,"ble_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. high",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2895,integrability,version,version,2895,"wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3210,integrability,version,version,3210,"at the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3337,integrability,Version,Versions,3337," _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:236,modifiability,version,version,236,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2895,modifiability,version,version,2895,"wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3210,modifiability,version,version,3210,"at the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3337,modifiability,Version,Versions,3337," _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3619,modifiability,deco,decorator,3619,"batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4061,modifiability,pac,packaging,4061,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:518,performance,batch,batches,518,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:719,performance,batch,batch,719,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:823,performance,batch,batch,823,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:1516,performance,batch,batch,1516,"atches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2037,performance,batch,batch,2037,"ere:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2254,performance,batch,batch,2254," reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2293,performance,batch,batch,2293," np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_gene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2409,performance,batch,batch,2409,"get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2678,performance,batch,batch,2678,"ble_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. high",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4805,performance,CPU,CPU,4805,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2803,reliability,Sli,Slicing,2803,"ult['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonsche",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2824,reliability,sli,slice,2824,"ean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3118,reliability,Sli,Slicing,3118,"'means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3139,reliability,sli,slice,3139,"). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4797,safety,log,logical,4797,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4851,safety,updat,updated,4851,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3507,security,certif,certifi,3507,"y['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_exte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4797,security,log,logical,4797,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4831,security,Session,Session,4831,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4851,security,updat,updated,4851,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4797,testability,log,logical,4797,"ure version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.10. ptyprocess 0.7.0. pvectorc NA. pygments 2.7.3. pyparsing 2.4.7. pyrsistent NA. pytz 2020.5. requests 2.25.1. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. send2trash NA. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. sniffio 1.2.0. storemagic NA. tables 3.6.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. urllib3 1.26.2. wcwidth 0.2.5. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 3.0.3. notebook 6.1.6. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-09 19:18. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:196,usability,confirm,confirmed,196,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:279,usability,confirm,confirmed,279,"sc.pp.highly_variable_genes with flavor='seurat_v3' returns wrong means/variances when batch_key argument is used; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When working on PR #1715, I noticed a small bug when `sc.pp.highly_variable()` is run with `flavor='seurat_v3'` and the `batch_key` argument is used on a dataset with multiple batches:. The columns in the returned data frame `means` and `variances` do not give the correct gene means and gene variances across the whole dataset, but instead give the means and variances of the batch with the last index. I think this because here means and variances are first computed within each batch:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L72-L77. ..and then not re-computed for the whole dataset before inserting them here:. https://github.com/theislab/scanpy/blob/a085333ead6ff8a0f64c25734060ffc048be56c0/scanpy/preprocessing/_highly_variable_genes.py#L136-L137. Should be an easy fix, I can also prepare it if you want :). ### Code to reproduce:. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2712,usability,user,user,2712,"vor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykerne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:2847,usability,support,supported,2847,"t['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3027,usability,user,user,3027,"ch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:3162,usability,support,supported,3162,"th_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? False. False. Wrong results come from last batch? True. True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. certifi 2020.12.05. cffi 1.14.4. chardet 4.0.0. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. idna 2.10. ipykernel 5.4.2. ipython_genutils 0.2.0. jedi 0.17.2. jinja2 2.11.2. joblib 1.0.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.2.1. jupyterlab_server 2.1.1. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbclassic NA. nbformat 5.0.8. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/pull/1726:37,deployability,Updat,Updating,37,Minor addition to contributing docs; Updating instructions to be explicit about which branches to target.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1726
https://github.com/scverse/scanpy/pull/1726:37,safety,Updat,Updating,37,Minor addition to contributing docs; Updating instructions to be explicit about which branches to target.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1726
https://github.com/scverse/scanpy/pull/1726:37,security,Updat,Updating,37,Minor addition to contributing docs; Updating instructions to be explicit about which branches to target.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1726
https://github.com/scverse/scanpy/issues/1729:150,modifiability,design decis,design decisions,150,"split by in sc.pl.dotplot ; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. in Surat, you can plot dot plot using group by and split by option. in scanpy only groupby option in sc.pl.dotplot function. Any help, I need a dot plot for cell types in different condition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1729
https://github.com/scverse/scanpy/issues/1729:48,usability,help,help,48,"split by in sc.pl.dotplot ; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. in Surat, you can plot dot plot using group by and split by option. in scanpy only groupby option in sc.pl.dotplot function. Any help, I need a dot plot for cell types in different condition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1729
https://github.com/scverse/scanpy/issues/1729:334,usability,help,help,334,"split by in sc.pl.dotplot ; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. in Surat, you can plot dot plot using group by and split by option. in scanpy only groupby option in sc.pl.dotplot function. Any help, I need a dot plot for cell types in different condition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1729
https://github.com/scverse/scanpy/issues/1730:7,integrability,sub,subset,7,"how to subset cells in scanpy; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... In seurat, I used subset to subset cells, how can I do it in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1730
https://github.com/scverse/scanpy/issues/1730:230,integrability,sub,subset,230,"how to subset cells in scanpy; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... In seurat, I used subset to subset cells, how can I do it in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1730
https://github.com/scverse/scanpy/issues/1730:240,integrability,sub,subset,240,"how to subset cells in scanpy; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... In seurat, I used subset to subset cells, how can I do it in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1730
https://github.com/scverse/scanpy/issues/1730:153,modifiability,design decis,design decisions,153,"how to subset cells in scanpy; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... In seurat, I used subset to subset cells, how can I do it in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1730
https://github.com/scverse/scanpy/issues/1730:51,usability,help,help,51,"how to subset cells in scanpy; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... In seurat, I used subset to subset cells, how can I do it in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1730
https://github.com/scverse/scanpy/issues/1731:894,deployability,modul,module,894,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2326,deployability,log,logg,2326,"2bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/. barcodes.tsv features.tsv matrix.mtx.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:597,energy efficiency,Current,Currently,597,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:114,modifiability,paramet,parameters,114,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:391,modifiability,pac,package,391,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:894,modifiability,modul,module,894,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1077,modifiability,pac,packages,1077," -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1443,modifiability,pac,packages,1443,"? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1712,modifiability,pac,packages,1712,"ed. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2053,modifiability,pac,packages,2053,"2bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/. barcodes.tsv features.tsv matrix.mtx.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:992,performance,cach,cache,992,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1152,performance,cach,cache,1152,"ged defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, bac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1522,performance,cach,cache,1522,"could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRN",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1654,performance,cach,cache,1654,", but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1660,performance,cach,cache,1660,"the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1822,performance,cach,cache,1822,"raceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_fe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2164,performance,cach,cache,2164,"2bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/. barcodes.tsv features.tsv matrix.mtx.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2372,performance,cach,cache,2372,"2bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/. barcodes.tsv features.tsv matrix.mtx.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:868,safety,input,input-,868,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:894,safety,modul,module,894,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2326,safety,log,logg,2326,"2bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/. barcodes.tsv features.tsv matrix.mtx.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2326,security,log,logg,2326,"2bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/. barcodes.tsv features.tsv matrix.mtx.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:196,testability,simpl,simple,196,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:824,testability,Trace,Traceback,824,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2326,testability,log,logg,2326,"2bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 713 . 714 if not is_present:. --> 715 raise FileNotFoundError(f'Did not find file {filename}.'). 716 logg.debug(f'reading {filename}'). 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```. But I have 10x files there:. ```. ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/. barcodes.tsv features.tsv matrix.mtx.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:188,usability,tool,tool,188,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:196,usability,simpl,simple,196,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:212,usability,tool,tool,212,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:260,usability,tool,tools,260,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:360,usability,tool,tools,360,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:868,usability,input,input-,868,"read_10x_mtx v3 non-gzipped; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped. ... ```. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-8-72e92bd46023> in <module>. ----> 1 adata=sc.read_10x_mtx(path,. 2 var_names='gene_symbols',. 3 make_unique=True,. 4 cache=False,. 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix). 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(). 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx. --> 470 adata = read(. 471 str(path),. 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix). 530 """""". 531 path = Path(path). --> 532 adata = read(. 533 path / f'{prefix}matrix.mtx.gz',. 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/pull/1732:1688,availability,Sli,Slicing,1688,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1709,availability,sli,slice,1709,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2003,availability,Sli,Slicing,2003,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2024,availability,sli,slice,2024,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1780,deployability,version,version,1780,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2095,deployability,version,version,2095,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:70,integrability,batch,batch,70,"bugfix for #1725; Fixed by computing global mean/variance outside the batch for loop :). Verification code (same as in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:374,integrability,batch,batch,374,"bugfix for #1725; Fixed by computing global mean/variance outside the batch for loop :). Verification code (same as in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:895,integrability,batch,batch,895,"bugfix for #1725; Fixed by computing global mean/variance outside the batch for loop :). Verification code (same as in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1112,integrability,batch,batch,1112," in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc wi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1151,integrability,batch,batch,1151," np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions inste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1267,integrability,batch,batch,1267,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1561,integrability,batch,batch,1561,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1780,integrability,version,version,1780,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2095,integrability,version,version,2095,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1780,modifiability,version,version,1780,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2095,modifiability,version,version,2095,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:70,performance,batch,batch,70,"bugfix for #1725; Fixed by computing global mean/variance outside the batch for loop :). Verification code (same as in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:374,performance,batch,batch,374,"bugfix for #1725; Fixed by computing global mean/variance outside the batch for loop :). Verification code (same as in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:895,performance,batch,batch,895,"bugfix for #1725; Fixed by computing global mean/variance outside the batch for loop :). Verification code (same as in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1112,performance,batch,batch,1112," in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc wi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1151,performance,batch,batch,1151," np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions inste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1267,performance,batch,batch,1267,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1561,performance,batch,batch,1561,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1688,reliability,Sli,Slicing,1688,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1709,reliability,sli,slice,1709,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2003,reliability,Sli,Slicing,2003,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2024,reliability,sli,slice,2024,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:89,testability,Verif,Verification,89,"bugfix for #1725; Fixed by computing global mean/variance outside the batch for loop :). Verification code (same as in #1725):. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarnin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1405,testability,Verif,Verification,1405,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1597,usability,user,user,1597,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1732,usability,support,supported,1732,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:1912,usability,user,user,1912,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/pull/1732:2047,usability,support,supported,2047,"h.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). #show that without batch_key, everything works fine. true_mean,true_var = _get_mean_var(adata.X). result = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False). print('Results correct without batch_key?'). print(np.all(result['means']==true_mean)). print(np.all(result['variances']==true_var)). #show that it goes wrong with batch_key.. result_with_batchkey = sc.pp.highly_variable_genes(adata,n_top_genes=2,flavor='seurat_v3',inplace=False,batch_key='batch'). print('Results correct with batch_key?'). print(np.all(result_with_batchkey['means']==true_mean)). print(np.all(result_with_batchkey['variances']==true_var)). #..and that the wrong result comes from the last batch. adata_batch4 = adata[adata.obs['batch']==4,:].copy(). means_batch4,vars_batch4 = _get_mean_var(adata_batch4.X). print('Wrong results come from last batch?'). print(np.all(result_with_batchkey['means']==means_batch4)). print(np.all(result_with_batchkey['variances']==vars_batch4)). ```. Verification code output:. ```pytb. Results correct without batch_key? True. True. Results correct with batch_key? True. True. Wrong results come from last batch? False. False. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:148: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead. df.loc[: int(n_top_genes), 'highly_variable'] = True. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732
https://github.com/scverse/scanpy/issues/1733:217,deployability,version,version,217,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2885,deployability,Version,Versions,2885,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2913,deployability,log,logging,2913,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3760,deployability,log,logical,3760,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3814,deployability,updat,updated,3814,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:1559,energy efficiency,current,current,1559,"ny batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3768,energy efficiency,CPU,CPU,3768,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3772,energy efficiency,core,cores,3772,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:217,integrability,version,version,217,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:566,integrability,batch,batches,566,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:726,integrability,batch,batches,726,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:756,integrability,batch,batch,756,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:918,integrability,batch,batches,918,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2227,integrability,batch,batch,2227,"b.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrappe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2278,integrability,batch,batch,2278,"5603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2299,integrability,batch,batch,2299,"py/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2468,integrability,batch,batch,2468," these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2885,integrability,Version,Versions,2885,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:67,interoperability,conflict,conflict,67,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:217,modifiability,version,version,217,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:943,modifiability,variab,variable,943,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2885,modifiability,Version,Versions,2885,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3399,modifiability,pac,packaging,3399,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:566,performance,batch,batches,566,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:726,performance,batch,batches,726,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:756,performance,batch,batch,756,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:918,performance,batch,batches,918,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2227,performance,batch,batch,2227,"b.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrappe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2278,performance,batch,batch,2278,"5603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2299,performance,batch,batch,2299,"py/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2468,performance,batch,batch,2468," these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3768,performance,CPU,CPU,3768,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2913,safety,log,logging,2913,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3760,safety,log,logical,3760,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3814,safety,updat,updated,3814,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2913,security,log,logging,2913,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3760,security,log,logical,3760,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3794,security,Session,Session,3794,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3814,security,updat,updated,3814,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2913,testability,log,logging,2913,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3760,testability,log,logical,3760,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]. ```. ```pytb. highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches. 87 True 8.0 1.76 2.446869 1.232373 5. 9 False 28.0 1.96 2.281212 1.159891 5. 78 True 24.0 1.95 2.209596 1.124666 5. 30 True 19.0 2.00 2.202020 1.134560 4. 14 False 25.0 2.14 2.162020 1.088266 4. ```. </details>. #### Versions. <details>. >>> sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.7.1.dev2+g8c469411. sinfo 0.3.1. -----. PIL 8.1.0. anndata 0.7.5. cffi 1.14.4. constants NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. google NA. h5py 2.10.0. highs_wrapper NA. joblib 1.0.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. llvmlite 0.35.0. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.52.0. numexpr 2.7.2. numpy 1.19.5. packaging 20.8. pandas 1.2.0. pkg_resources NA. pyparsing 2.4.7. pytz 2020.5. scanpy 1.7.1.dev2+g8c469411. scipy 1.6.0. sinfo 0.3.1. sitecustomize NA. six 1.15.0. sklearn 0.24.0. skmisc 0.1.3. tables 3.6.1. typing_extensions NA. yaml 5.3.1. -----. Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]. Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-03-10 17:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:81,usability,document,documentation,81,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:177,usability,confirm,confirmed,177,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:260,usability,confirm,confirmed,260,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:437,usability,document,documentation,437,"sc.pp.highly_variable_genes with flavor='seurat_v3' and batch_key: conflict with documentation; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:1440,usability,behavi,behavior,1440,"tation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here? https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601. https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python. import numpy as np. import scanpy as sc. import anndata . import sys. sys.path.append(""scanpy/preprocessing""). from _utils import _get_mean_var. np.random.seed(42). adata = anndata.AnnData(np.random.randint(0,5,(100,100))). adata.obs['batch'] = np.random.randint(0,5,(100)). adata.obs['batch'] = adata.obs['batch'].astype('category'). n_top_genes = 50. adata = adata.copy(). sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/pull/1734:38,reliability,doe,does,38,add_dendrogram c/p doc fix; @fidelram does this look ok?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1734
https://github.com/scverse/scanpy/pull/1735:85,modifiability,paramet,parameter,85,"Preserve category order when groupby is a list; Let's preserve categories if groupby parameter in _prepare_dataframe is a list:. ```python. import scanpy as sc. import numpy as np. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.pp.pca(ad). sc.pp.neighbors(ad). sc.tl.leiden(ad). cats = ad.obs.leiden.cat.categories.tolist(). np.random.seed(1). np.random.shuffle(cats). ad.obs.leiden.cat.reorder_categories(cats, inplace=True). ad.obs.leiden.cat.categories. ```. Prints:. ```Index(['2', '3', '4', '9', '1', '6', '0', '7', '10', '8', '5'], dtype='object')```. ```python. sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden']). sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden', 'paul15_clusters']). ```. Outputs:. ![image](https://user-images.githubusercontent.com/1140359/110705581-9ba83f80-81c4-11eb-89fe-e2950b98801f.png). ![image](https://user-images.githubusercontent.com/1140359/110705666-b8dd0e00-81c4-11eb-8930-f72861740c88.png). which is very annoying because we lost the category order of leiden. After this PR the output is:. ![image](https://user-images.githubusercontent.com/1140359/110705698-c2667600-81c4-11eb-88ab-9bb6a2717ca0.png). ![image](https://user-images.githubusercontent.com/1140359/110705744-d0b49200-81c4-11eb-9faf-20abf3cd833e.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735
https://github.com/scverse/scanpy/pull/1735:738,usability,user,user-images,738,"Preserve category order when groupby is a list; Let's preserve categories if groupby parameter in _prepare_dataframe is a list:. ```python. import scanpy as sc. import numpy as np. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.pp.pca(ad). sc.pp.neighbors(ad). sc.tl.leiden(ad). cats = ad.obs.leiden.cat.categories.tolist(). np.random.seed(1). np.random.shuffle(cats). ad.obs.leiden.cat.reorder_categories(cats, inplace=True). ad.obs.leiden.cat.categories. ```. Prints:. ```Index(['2', '3', '4', '9', '1', '6', '0', '7', '10', '8', '5'], dtype='object')```. ```python. sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden']). sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden', 'paul15_clusters']). ```. Outputs:. ![image](https://user-images.githubusercontent.com/1140359/110705581-9ba83f80-81c4-11eb-89fe-e2950b98801f.png). ![image](https://user-images.githubusercontent.com/1140359/110705666-b8dd0e00-81c4-11eb-8930-f72861740c88.png). which is very annoying because we lost the category order of leiden. After this PR the output is:. ![image](https://user-images.githubusercontent.com/1140359/110705698-c2667600-81c4-11eb-88ab-9bb6a2717ca0.png). ![image](https://user-images.githubusercontent.com/1140359/110705744-d0b49200-81c4-11eb-9faf-20abf3cd833e.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735
https://github.com/scverse/scanpy/pull/1735:850,usability,user,user-images,850,"Preserve category order when groupby is a list; Let's preserve categories if groupby parameter in _prepare_dataframe is a list:. ```python. import scanpy as sc. import numpy as np. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.pp.pca(ad). sc.pp.neighbors(ad). sc.tl.leiden(ad). cats = ad.obs.leiden.cat.categories.tolist(). np.random.seed(1). np.random.shuffle(cats). ad.obs.leiden.cat.reorder_categories(cats, inplace=True). ad.obs.leiden.cat.categories. ```. Prints:. ```Index(['2', '3', '4', '9', '1', '6', '0', '7', '10', '8', '5'], dtype='object')```. ```python. sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden']). sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden', 'paul15_clusters']). ```. Outputs:. ![image](https://user-images.githubusercontent.com/1140359/110705581-9ba83f80-81c4-11eb-89fe-e2950b98801f.png). ![image](https://user-images.githubusercontent.com/1140359/110705666-b8dd0e00-81c4-11eb-8930-f72861740c88.png). which is very annoying because we lost the category order of leiden. After this PR the output is:. ![image](https://user-images.githubusercontent.com/1140359/110705698-c2667600-81c4-11eb-88ab-9bb6a2717ca0.png). ![image](https://user-images.githubusercontent.com/1140359/110705744-d0b49200-81c4-11eb-9faf-20abf3cd833e.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735
https://github.com/scverse/scanpy/pull/1735:1061,usability,user,user-images,1061,"Preserve category order when groupby is a list; Let's preserve categories if groupby parameter in _prepare_dataframe is a list:. ```python. import scanpy as sc. import numpy as np. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.pp.pca(ad). sc.pp.neighbors(ad). sc.tl.leiden(ad). cats = ad.obs.leiden.cat.categories.tolist(). np.random.seed(1). np.random.shuffle(cats). ad.obs.leiden.cat.reorder_categories(cats, inplace=True). ad.obs.leiden.cat.categories. ```. Prints:. ```Index(['2', '3', '4', '9', '1', '6', '0', '7', '10', '8', '5'], dtype='object')```. ```python. sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden']). sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden', 'paul15_clusters']). ```. Outputs:. ![image](https://user-images.githubusercontent.com/1140359/110705581-9ba83f80-81c4-11eb-89fe-e2950b98801f.png). ![image](https://user-images.githubusercontent.com/1140359/110705666-b8dd0e00-81c4-11eb-8930-f72861740c88.png). which is very annoying because we lost the category order of leiden. After this PR the output is:. ![image](https://user-images.githubusercontent.com/1140359/110705698-c2667600-81c4-11eb-88ab-9bb6a2717ca0.png). ![image](https://user-images.githubusercontent.com/1140359/110705744-d0b49200-81c4-11eb-9faf-20abf3cd833e.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735
https://github.com/scverse/scanpy/pull/1735:1173,usability,user,user-images,1173,"Preserve category order when groupby is a list; Let's preserve categories if groupby parameter in _prepare_dataframe is a list:. ```python. import scanpy as sc. import numpy as np. ad = sc.datasets.paul15(). sc.pp.log1p(ad). sc.pp.pca(ad). sc.pp.neighbors(ad). sc.tl.leiden(ad). cats = ad.obs.leiden.cat.categories.tolist(). np.random.seed(1). np.random.shuffle(cats). ad.obs.leiden.cat.reorder_categories(cats, inplace=True). ad.obs.leiden.cat.categories. ```. Prints:. ```Index(['2', '3', '4', '9', '1', '6', '0', '7', '10', '8', '5'], dtype='object')```. ```python. sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden']). sc.pl.dotplot(ad, ['Cst3', 'Malat1'], groupby=['leiden', 'paul15_clusters']). ```. Outputs:. ![image](https://user-images.githubusercontent.com/1140359/110705581-9ba83f80-81c4-11eb-89fe-e2950b98801f.png). ![image](https://user-images.githubusercontent.com/1140359/110705666-b8dd0e00-81c4-11eb-8930-f72861740c88.png). which is very annoying because we lost the category order of leiden. After this PR the output is:. ![image](https://user-images.githubusercontent.com/1140359/110705698-c2667600-81c4-11eb-88ab-9bb6a2717ca0.png). ![image](https://user-images.githubusercontent.com/1140359/110705744-d0b49200-81c4-11eb-9faf-20abf3cd833e.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1735
https://github.com/scverse/scanpy/issues/1736:198,availability,failur,failure,198,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2496,availability,error,error,2496,"8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwarg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2696,availability,operat,operation,2696,", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:33,deployability,log,logging,33,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:104,deployability,fail,fail,104,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:198,deployability,fail,failure,198,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:378,deployability,manag,manager,378,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1189,deployability,manag,manager,1189,"test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1356,deployability,manag,manager,1356,"e-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2000,deployability,log,logg,2000,"ackages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2045,deployability,log,logging,2045,". return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2185,deployability,log,logging,2185,"manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2228,deployability,log,log,2228,"n self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2312,deployability,log,logging,2312,"/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_ho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2337,deployability,log,log,2337,"-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2350,deployability,log,log,2350,"ggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2488,deployability,Log,Logging,2488,"on/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2601,deployability,log,logging,2601,"rgs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2727,deployability,stack,stack,2727,"call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2804,deployability,modul,module,2804,"ts/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3415,deployability,manag,manager,3415,"aph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3582,deployability,manag,manager,3582,"/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touchin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4506,deployability,log,logging,4506,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4588,deployability,log,logging,4588,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4854,deployability,log,loggers,4854,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4873,deployability,log,logging,4873,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4882,deployability,log,loggers,4882,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4893,deployability,log,logging,4893,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4921,deployability,log,logging,4921,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4929,deployability,Log,Logger,4929,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4936,deployability,manag,manager,4936,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4944,deployability,log,loggerDict,4944,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4970,deployability,log,logger,4970,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4980,deployability,log,loggers,4980,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5009,deployability,log,logger,5009,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5060,deployability,log,logger,5060,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:378,energy efficiency,manag,manager,378,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1189,energy efficiency,manag,manager,1189,"test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1356,energy efficiency,manag,manager,1356,"e-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3415,energy efficiency,manag,manager,3415,"aph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3582,energy efficiency,manag,manager,3582,"/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touchin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4936,energy efficiency,manag,manager,4936,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2380,integrability,Messag,Message,2380,"mbda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:371,interoperability,plug,pluggy,371,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:555,interoperability,plug,pluggy,555,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1010,interoperability,plug,pluggy,1010,"es have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1182,interoperability,plug,pluggy,1182,"for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1349,interoperability,plug,pluggy,1349,"n3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1533,interoperability,plug,pluggy,1533,"n3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2380,interoperability,Messag,Message,2380,"mbda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2442,interoperability,coordinat,coordinates,2442,".multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3236,interoperability,plug,pluggy,3236,"sg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3408,interoperability,plug,pluggy,3408,"_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"",",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3575,interoperability,plug,pluggy,3575,".8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3759,interoperability,plug,pluggy,3759,"Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4394,interoperability,plug,pluggy,4394,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:362,modifiability,pac,packages,362,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:546,modifiability,pac,packages,546,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:696,modifiability,pac,packages,696,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:838,modifiability,pac,packages,838,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1001,modifiability,pac,packages,1001," sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1173,modifiability,pac,packages,1173," output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1340,modifiability,pac,packages,1340,"ib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. su",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1524,modifiability,pac,packages,1524,"ib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1674,modifiability,pac,packages,1674,"ib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2804,modifiability,modul,module,2804,"ts/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2902,modifiability,pac,packages,2902,"raph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3045,modifiability,pac,packages,3045,"ing.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3227,modifiability,pac,packages,3227,"(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3399,modifiability,pac,packages,3399,"ded\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/ho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3566,modifiability,pac,packages,3566,"Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3750,modifiability,pac,packages,3750,"olcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3900,modifiability,pac,packages,3900,"ckages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.get",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4060,modifiability,pac,packages,4060,"nfig/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4226,modifiability,pac,packages,4226,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4385,modifiability,pac,packages,4385,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:198,performance,failur,failure,198,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2116,performance,time,time,2116,"pt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2121,performance,time,time,2121,"stedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2243,performance,time,time,2243,"ookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/ho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2248,performance,time,time,2248,"ec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2496,performance,error,error,2496,"8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwarg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2692,performance,I/O,I/O,2692,"hon.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5101,performance,time,time,5101,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:104,reliability,fail,fail,104,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:198,reliability,fail,failure,198,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:0,safety,Test,Tests,0,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:33,safety,log,logging,33,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:59,safety,test,tests,59,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:193,safety,test,test,193,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:378,safety,manag,manager,378,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1189,safety,manag,manager,1189,"test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1356,safety,manag,manager,1356,"e-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1745,safety,test,testfunction,1745,"t_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1760,safety,test,testargs,1760,"runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1804,safety,test,tests,1804,"n/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2000,safety,log,logg,2000,"ackages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2045,safety,log,logging,2045,". return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2185,safety,log,logging,2185,"manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2228,safety,log,log,2228,"n self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2312,safety,log,logging,2312,"/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_ho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2337,safety,log,log,2337,"-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2350,safety,log,log,2350,"ggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2488,safety,Log,Logging,2488,"on/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2496,safety,error,error,2496,"8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwarg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2601,safety,log,logging,2601,"rgs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2804,safety,modul,module,2804,"ts/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3415,safety,manag,manager,3415,"aph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 28",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3582,safety,manag,manager,3582,"/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touchin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4506,safety,log,logging,4506,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4588,safety,log,logging,4588,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4854,safety,log,loggers,4854,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4873,safety,log,logging,4873,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4882,safety,log,loggers,4882,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4893,safety,log,logging,4893,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4921,safety,log,logging,4921,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4929,safety,Log,Logger,4929,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4936,safety,manag,manager,4936,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4944,safety,log,loggerDict,4944,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4970,safety,log,logger,4970,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4980,safety,log,loggers,4980,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5009,safety,log,logger,5009,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5060,safety,log,logger,5060,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:33,security,log,logging,33,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2000,security,log,logg,2000,"ackages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2045,security,log,logging,2045,". return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2185,security,log,logging,2185,"manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2228,security,log,log,2228,"n self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2312,security,log,logging,2312,"/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_ho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2337,security,log,log,2337,"-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2350,security,log,log,2350,"ggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2488,security,Log,Logging,2488,"on/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2601,security,log,logging,2601,"rgs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4114,security,session,session,4114,"ode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come acro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4148,security,session,session,4148,"line_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this hap",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4304,security,session,session,4304,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4312,security,session,session,4312,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4506,security,log,logging,4506,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4588,security,log,logging,4588,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4854,security,log,loggers,4854,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4873,security,log,logging,4873,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4882,security,log,loggers,4882,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4893,security,log,logging,4893,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4921,security,log,logging,4921,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4929,security,Log,Logger,4929,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4944,security,log,loggerDict,4944,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4970,security,log,logger,4970,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4980,security,log,loggers,4980,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5009,security,log,logger,5009,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5060,security,log,logger,5060,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:0,testability,Test,Tests,0,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:33,testability,log,logging,33,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:59,testability,test,tests,59,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:193,testability,test,test,193,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:275,testability,hook,hook,275,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:443,testability,hook,hook,443,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:466,testability,hook,hook,466,"Tests sometimes have really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1017,testability,hook,hooks,1017," really long logging output; Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>. <summary> </summary>. ```. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1253,testability,hook,hook,1253,"elf._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1421,testability,hook,hook,1421,"r_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1444,testability,hook,hook,1444,"k, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1745,testability,test,testfunction,1745,"t_call. item.runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1760,testability,test,testargs,1760,"runtest(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1804,testability,test,tests,1804,"n/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest. self.ihook.pytest_pyfunc_call(pyfuncitem=self). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2000,testability,log,logg,2000,"ackages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2045,testability,log,logging,2045,". return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2185,testability,log,logging,2185,"manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2228,testability,log,log,2228,"n self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2312,testability,log,logging,2312,"/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_ho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2337,testability,log,log,2337,"-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2350,testability,log,log,2350,"ggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2488,testability,Log,Logging,2488,"on/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2507,testability,Trace,Traceback,2507,"hon3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/op",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2601,testability,log,logging,2601,"rgs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3137,testability,hook,hook,3137,"xtra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3243,testability,hook,hooks,3243,"e=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/mai",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3479,testability,hook,hook,3479,"). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known prob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3647,testability,hook,hook,3647,".write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3670,testability,hook,hook,3670,"nator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding thi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4280,testability,hook,hook,4280,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4401,testability,hook,hooks,4401,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4506,testability,log,logging,4506,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4588,testability,log,logging,4588,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4854,testability,log,loggers,4854,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4873,testability,log,logging,4873,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4882,testability,log,loggers,4882,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4893,testability,log,logging,4893,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4921,testability,log,logging,4921,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4929,testability,Log,Logger,4929,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4944,testability,log,loggerDict,4944,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4970,testability,log,logger,4970,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4980,testability,log,loggers,4980,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5009,testability,log,logger,5009,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5060,testability,log,logger,5060,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main. return wrap_session(config, _main). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session. session.exitstatus = doit(config, session) or 0. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main. config.hook.pytest_runtestloop(session=session). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python. def clear_loggers():. """"""Remove handlers from all loggers"""""". import logging. loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()). for logger in loggers:. handlers = getattr(logger, 'handlers', []). for handler in handlers:. logger.removeHandler(handler). ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1952,usability,tool,tools,1952,"toolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2496,usability,error,error,2496,"8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall. res = hook_impl.function(*args). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwarg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2709,usability,close,closed,2709," in pytest_pyfunc_call. result = testfunction(**testargs). File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled. sc.tl.draw_graph(adata). File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph. logg.info(. File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info. return settings._root_logger.info(msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info. return self.log(INFO, msg, time=time, deep=deep, extra=extra). File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log. super().log(level, msg, extra=extra). Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)"". Arguments: (). --- Logging error ---. Traceback (most recent call last):. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit. stream.write(msg + self.terminator). ValueError: I/O operation on closed file. Call stack:. File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>. sys.exit(console_main()). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main. code = main(). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main. ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(. File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__. return self._hookexec(self, self.get_hookimpls(), kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec. return self._inner_hookexec(hook, methods, kwargs). File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>. self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(. File ""/opt/hostedtoolcach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/pull/1737:139,deployability,log,logging,139,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:9,safety,test,test,9,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:41,safety,test,tested,41,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:139,safety,log,logging,139,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:139,security,log,logging,139,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:9,testability,test,test,9,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:41,testability,test,tested,41,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:139,testability,log,logging,139,"Fix long test output; Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/issues/1739:94,availability,consist,consists,94,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:412,availability,down,downstream,412,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2029,availability,cluster,cluster,2029,"github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:18,deployability,API,API,18,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:75,deployability,API,API,75,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:116,deployability,modul,modules,116,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:501,deployability,continu,continue,501,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:580,deployability,API,API,580,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:629,deployability,modul,modules,629,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:705,deployability,API,API,705,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1280,deployability,manag,managing,1280,"/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1691,deployability,API,API,1691," reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1999,deployability,log,logreg,1999,"p.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2029,deployability,cluster,cluster,2029,"github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2751,deployability,modul,modules,2751,"_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method (e.g. `highly_variable_genes(flavor='seurat'))` which makes things easier for the new users but here there is no obvious solution to that. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1280,energy efficiency,manag,managing,1280,"/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:18,integrability,API,API,18,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:75,integrability,API,API,75,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:580,integrability,API,API,580,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:705,integrability,API,API,705,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1691,integrability,API,API,1691," reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1944,integrability,filter,filter,1944,". 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:18,interoperability,API,API,18,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:75,interoperability,API,API,75,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:580,interoperability,API,API,580,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:705,interoperability,API,API,705,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:978,interoperability,share,shared,978,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1316,interoperability,specif,specific,1316,"ous that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1691,interoperability,API,API,1691," reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2839,interoperability,specif,specify,2839,"_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method (e.g. `highly_variable_genes(flavor='seurat'))` which makes things easier for the new users but here there is no obvious solution to that. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:54,modifiability,layer,layers,54,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:88,modifiability,layer,layer,88,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:116,modifiability,modul,modules,116,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:266,modifiability,pac,package,266,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:629,modifiability,modul,modules,629,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:659,modifiability,exten,extend,659,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:680,modifiability,maintain,maintaining,680,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1549,modifiability,layer,layers,1549," an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.inge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1669,modifiability,layer,layer,1669,", while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not enti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2751,modifiability,modul,modules,2751,"_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method (e.g. `highly_variable_genes(flavor='seurat'))` which makes things easier for the new users but here there is no obvious solution to that. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2808,modifiability,layer,layer,2808,"_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method (e.g. `highly_variable_genes(flavor='seurat'))` which makes things easier for the new users but here there is no obvious solution to that. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:383,performance,perform,perform,383,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1613,performance,time,time,1613,"lat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with grou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2447,performance,time,time,2447,"_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method (e.g. `highly_variable_genes(flavor='seurat'))` which makes things easier for the new users but here there is no obvious solution to that. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:116,safety,modul,modules,116,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:456,safety,test,tests,456,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:629,safety,modul,modules,629,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:680,safety,maintain,maintaining,680,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:806,safety,compl,completely,806,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1256,safety,compl,complicated,1256,"npy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1280,safety,manag,managing,1280,"/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1999,safety,log,logreg,1999,"p.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:2751,safety,modul,modules,2751,"_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method (e.g. `highly_variable_genes(flavor='seurat'))` which makes things easier for the new users but here there is no obvious solution to that. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:806,security,compl,completely,806,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1256,security,compl,complicated,1256,"npy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1999,security,log,logreg,1999,"p.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:456,testability,test,tests,456,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1999,testability,log,logreg,1999,"p.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:94,usability,consist,consists,94,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:383,usability,perform,perform,383,"More hierarchical API; Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:3120,usability,user,users,3120,"_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java. sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}. sc.pp.neighbors.{umap,gauss,rapids,tsne}. sc.pp.hvg.{seurat,seurat_v3,dispersion}. sc.pp.norm.{tpm,pearson}. sc.pp.filter.{genes,cells,rank_genes,...}. sc.tl.rank_genes.{logreg,wilcoxon,ttest}. sc.tl.cluster.{leiden,louvain}. sc.tl.score.{genes,cell_cycle}. sc.pl.rank_genes.{dotplot,matrixplot,...}. sc.pl.groups.{dot,matrix,violin,...}. sc.pl.embed.{umap,tsne,pca,...}. ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still have a default method (e.g. `highly_variable_genes(flavor='seurat'))` which makes things easier for the new users but here there is no obvious solution to that. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/pull/1740:441,deployability,continu,continuos,441,"Add morans I; close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304. Explicit design choices compared to first proposal in squidpy:. - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ). - only working on genes. technically it could work on continuos covariates as well, should I add that option? - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/pull/1740:576,interoperability,standard,standard,576,"Add morans I; close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304. Explicit design choices compared to first proposal in squidpy:. - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ). - only working on genes. technically it could work on continuos covariates as well, should I add that option? - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/pull/1740:670,safety,test,tests,670,"Add morans I; close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304. Explicit design choices compared to first proposal in squidpy:. - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ). - only working on genes. technically it could work on continuos covariates as well, should I add that option? - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/pull/1740:670,testability,test,tests,670,"Add morans I; close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304. Explicit design choices compared to first proposal in squidpy:. - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ). - only working on genes. technically it could work on continuos covariates as well, should I add that option? - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/pull/1740:14,usability,close,close,14,"Add morans I; close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304. Explicit design choices compared to first proposal in squidpy:. - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ). - only working on genes. technically it could work on continuos covariates as well, should I add that option? - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/pull/1740:628,usability,feedback,feedback,628,"Add morans I; close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304. Explicit design choices compared to first proposal in squidpy:. - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ). - only working on genes. technically it could work on continuos covariates as well, should I add that option? - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/pull/1741:49,interoperability,standard,standards,49,"Make scrublet plotting function more like Scanpy standards for saving plot etc; A small tweak to the plotting function for Scrublet, to use standard Scanpy patterns for saving the plot etc. . Also some minor doc fixes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1741
https://github.com/scverse/scanpy/pull/1741:140,interoperability,standard,standard,140,"Make scrublet plotting function more like Scanpy standards for saving plot etc; A small tweak to the plotting function for Scrublet, to use standard Scanpy patterns for saving the plot etc. . Also some minor doc fixes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1741
https://github.com/scverse/scanpy/issues/1742:9,availability,error,error,9,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:875,availability,error,error,875,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:143,deployability,version,version,143,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2096,deployability,Version,Versions,2096,"t(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2145,deployability,log,logging,2145,"ib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3635,deployability,log,logical,3635,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3734,deployability,updat,updated,3734,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2351,energy efficiency,cloud,cloudpickle,2351,"es\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3643,energy efficiency,CPU,CPU,3643,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3647,energy efficiency,core,cores,3647,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3671,energy efficiency,Model,Model,3671,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:143,integrability,version,version,143,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2096,integrability,Version,Versions,2096,"t(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1051,interoperability,specif,specified,1051,"e has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1095,interoperability,format,format,1095,"have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1245,interoperability,specif,specified,1245,"*Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1289,interoperability,format,format,1289,"matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. ba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1439,interoperability,specif,specified,1439,"l code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1483,interoperability,format,format,1483,"out having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1633,interoperability,specif,specified,1633,"nes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1677,interoperability,format,format,1677,"ata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1827,interoperability,specif,specified,1827,".4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1871,interoperability,format,format,1871," error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2021,interoperability,specif,specified,2021,"on ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2065,interoperability,format,format,2065,"gs.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:143,modifiability,version,version,143,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:963,modifiability,pac,packages,963,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1157,modifiability,pac,packages,1157," - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1351,modifiability,pac,packages,1351,"tailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. clou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1545,modifiability,pac,packages,1545,"ar['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipytho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1739,modifiability,pac,packages,1739,"e). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1933,modifiability,pac,packages,1933,"aurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycpar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2096,modifiability,Version,Versions,2096,"t(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2465,modifiability,deco,decorator,2465,"_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2815,modifiability,pac,packaging,2815,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:9,performance,error,error,9,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:875,performance,error,error,875,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2306,performance,bottleneck,bottleneck,2306,")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_exten",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3643,performance,CPU,CPU,3643,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:9,safety,error,error,9,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:875,safety,error,error,875,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2145,safety,log,logging,2145,"ib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3635,safety,log,logical,3635,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3734,safety,updat,updated,3734,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2145,security,log,logging,2145,"ib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3635,security,log,logical,3635,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3671,security,Model,Model,3671,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3714,security,Session,Session,3714,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3734,security,updat,updated,3734,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2145,testability,log,logging,2145,"ib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3635,testability,log,logical,3635,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:9,usability,error,error,9,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:103,usability,confirm,confirmed,103,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:186,usability,confirm,confirmed,186,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:277,usability,guid,guide,277,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:332,usability,minim,minimal-bug-reports,332,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:438,usability,Minim,Minimal,438,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:875,usability,error,error,875,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:930,usability,User,Users,930,"Tutorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:995,usability,User,UserWarning,995,"utorial error; - . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1124,usability,User,Users,1124,"s on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1189,usability,User,UserWarning,1189," this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line afte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1318,usability,User,Users,1318,"2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1383,usability,User,UserWarning,1383,"ry information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cyc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1512,usability,User,Users,1512,"on. # Your code here. ```. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1577,usability,User,UserWarning,1577,"rtswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1706,usability,User,Users,1706,"top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1771,usability,User,UserWarning,1771,"by_counts', 'total_counts', 'pct_counts_mt'],. jitter=0.4, multi_panel=True). ```pytb. [Paste the error output produced by the above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1900,usability,User,Users,1900," above code here]. ```. C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:1965,usability,User,UserWarning,1965,"\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndesc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3253,usability,tool,toolz,3253,"rWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. bottleneck 1.3.2. cairo 1.20.0. cffi 1.14.3. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.1. joblib 0.17.0. kiwisolver 1.3.0. legacy_api_wrap 0.0.0. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.1. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.5.0. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel. -----. Session information updated at 2021-03-14 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/pull/1743:15,deployability,releas,release,15,Add vcenter to release notes; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/pull/1743:250,safety,review,review,250,Add vcenter to release notes; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/pull/1743:250,testability,review,review,250,Add vcenter to release notes; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/pull/1743:101,usability,guid,guidelines,101,Add vcenter to release notes; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/pull/1743:132,usability,guid,guide,132,Add vcenter to release notes; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/pull/1743:228,usability,workflow,workflow,228,Add vcenter to release notes; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/issues/1744:500,availability,down,downstream,500,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:686,availability,sli,slice,686,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:12,integrability,sub,subsets,12,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:261,integrability,sub,subset,261,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:0,interoperability,Specif,Specify,0,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:187,interoperability,specif,specify,187,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:201,modifiability,variab,variables,201,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:271,modifiability,variab,variables,271,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:567,modifiability,variab,variables,567,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:686,reliability,sli,slice,686,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:30,safety,test,testing,30,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:225,safety,test,testing,225,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:339,safety,test,test,339,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:372,safety,test,test,372,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:602,safety,test,testing,602,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:42,security,auth,authors,42,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:30,testability,test,testing,30,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:225,testability,test,testing,225,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:339,testability,test,test,339,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:349,testability,context,context,349,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:372,testability,test,test,372,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:602,testability,test,testing,602,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:243,usability,user,users,243,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:520,usability,visual,visualisation,520,"Specify var subsets for stats testing; Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1745:528,energy efficiency,current,current,528,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:827,integrability,sub,submit,827,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:144,modifiability,paramet,parameters,144,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:421,modifiability,pac,package,421,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:842,modifiability,maintain,maintainers,842,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:842,safety,maintain,maintainers,842,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:226,testability,simpl,simple,226,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:218,usability,tool,tool,218,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:226,usability,simpl,simple,226,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:242,usability,tool,tool,242,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:290,usability,tool,tools,290,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:390,usability,tool,tools,390,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:697,usability,user,users,697,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1745:875,usability,prefer,preferred,875,Unused basis argument in external.pp.scanorama_integrate(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1746:16,availability,down,down,16,Scanpy docs are down?; Getting this across multiple browsers. ![Screen Shot 2021-03-16 at 9 27 49 AM](https://user-images.githubusercontent.com/10859440/111344731-e1885c00-8639-11eb-8cb0-93fd463844c4.png).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1746
https://github.com/scverse/scanpy/issues/1746:110,usability,user,user-images,110,Scanpy docs are down?; Getting this across multiple browsers. ![Screen Shot 2021-03-16 at 9 27 49 AM](https://user-images.githubusercontent.com/10859440/111344731-e1885c00-8639-11eb-8cb0-93fd463844c4.png).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1746
https://github.com/scverse/scanpy/issues/1747:3,deployability,automat,automatic,3,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:160,modifiability,design decis,design decisions,160,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:13,safety,sanit,sanitisation,13,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:13,security,sanit,sanitisation,13,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:488,security,control,control,488,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:605,security,control,control,605,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:3,testability,automat,automatic,3,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:488,testability,control,control,488,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:605,testability,control,control,605,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:58,usability,help,help,58,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:422,usability,user,user,422,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1747:599,usability,user,users,599,"Is automatic sanitisation necessary?; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. In several Scanpy functions `sanitize_anndata()` is called which converts most string columns in `obs`/`var` to categorical columns. Often this seems to be a precaution rather than really necessary and as a user it's frustrating to have things changed in a way you have no control over. Just wondering if you have considered how required this is and whether it would be better to let users control when/if this happens.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747
https://github.com/scverse/scanpy/issues/1748:172,deployability,version,version,172,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:814,deployability,log,logfoldchanges,814,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:1407,deployability,Version,Versions,1407,"can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3054,deployability,log,logical,3054,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3062,energy efficiency,CPU,CPU,3062,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3066,energy efficiency,core,cores,3066,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:172,integrability,version,version,172,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:1407,integrability,Version,Versions,1407,"can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:2814,integrability,wrap,wrapt,2814,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:172,modifiability,version,version,172,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:1407,modifiability,Version,Versions,1407,"can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:1727,modifiability,deco,decorator,1727,"iver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. thr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:2206,modifiability,pac,packaging,2206,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3062,performance,CPU,CPU,3062,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:814,safety,log,logfoldchanges,814,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3054,safety,log,logical,3054,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:814,security,log,logfoldchanges,814,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:1600,security,certif,certifi,1600,"group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3054,security,log,logical,3054,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:814,testability,log,logfoldchanges,814,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3054,testability,log,logical,3054,"2 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. lxml 4.5.2. magic 2.0.3. matplotlib 3.3.1. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.8. pandas 1.2.1. parso 0.7.1. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.6. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.6.1. pygsp 0.5.1. pylab NA. pyparsing 2.4.7. pytz 2020.1. requests 2.24.0. requests_cache 0.5.2. sca NA. scanpy 1.7.0. scipy 1.6.1. scprep 1.0.5.post2. seaborn 0.10.1. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. statsmodels 0.11.1. storemagic NA. tables 3.6.1. tasklogger 1.0.0. texttable 1.6.2. threadpoolctl 2.1.0. tornado 6.0.4. traitlets 4.3.3. urllib3 1.25.10. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. zope NA. -----. IPython 7.17.0. jupyter_client 6.1.6. jupyter_core 4.6.3. notebook 6.1.3. -----. Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10. 64 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:132,usability,confirm,confirmed,132,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:382,usability,Minim,Minimal,382,"NAN as gene name in sc.get.rank_genes_groups_df; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'). sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'). sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]. ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj. -- | -- | -- | -- | --. HBB | 94.312996 | 4.962673 | 0.0 | 0.0. HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0. NaN | 83.383812 | 3.280355 | 0.0 | 0.0. NaN | 77.977989 | 3.548592 | 0.0 | 0.0. S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0. NaN | 66.913872 | 2.049016 | 0.0 | 0.0. NaN | 66.620399 | 1.637823 | 0.0 | 0.0. NaN | 66.236443 | 1.807056 | 0.0 | 0.0. NaN | 64.112152 | 2.446921 | 0.0 | 0.0. NaN | 64.083160 | 2.495992 | 0.0 | 0.0. HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0. NaN | 63.009491 | 2.059168 | 0.0 | 0.0. NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.0. sinfo 0.3.1. -----. PIL 7.2.0. anndata 0.7.5. appdirs 1.4.4. autoreload NA. backcall 0.2.0. bioservices 1.7.8. bs4 4.9.1. cairo 1.19.1. certifi 2020.12.05. cffi 1.14.4. chardet 3.0.4. colorama 0.4.3. colorlog NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. deprecated 1.2.10. easydev 0.9.38. future 0.18.2. future_fstrings NA. get_version 2.1. graphtools 1.5.2. gseapy 0.10.1. h5py 2.10.0. idna 2.10. igraph 0.8.2. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.16.0. kiwisolver ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1749:157,deployability,version,version,157,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1619,deployability,Version,Versions,1619,"py as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1669,deployability,contain,container,1669,"adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. picklesha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3503,deployability,log,logical,3503,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3549,deployability,updat,updated,3549,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1967,energy efficiency,cloud,cloudpickle,1967,['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3511,energy efficiency,CPU,CPU,3511,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3515,energy efficiency,core,cores,3515,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:157,integrability,version,version,157,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1619,integrability,Version,Versions,1619,"py as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:483,interoperability,specif,specific,483,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:157,modifiability,version,version,157,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1619,modifiability,Version,Versions,1619,"py as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:2098,modifiability,deco,decorator,2098,348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:2607,modifiability,pac,packaging,2607,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1876,performance,bottleneck,bottleneck,1876,"equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3511,performance,CPU,CPU,3511,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:329,reliability,doe,does,329,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:376,reliability,doe,does,376,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3503,safety,log,logical,3503,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3549,safety,updat,updated,3549,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:343,security,ident,identical,343,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:386,security,ident,identical,386,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1919,security,certif,certifi,1919,_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3022,security,soc,socks,3022,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3503,security,log,logical,3503,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3529,security,Session,Session,3529,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3549,security,updat,updated,3549,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3503,testability,log,logical,3503,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:117,usability,confirm,confirmed,117,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:200,usability,confirm,confirmed,200,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:509,usability,Minim,Minimal,509,"reproducibility of pca with arpack; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Running pca with arpack twice like in the example below sometimes does not give identical results. Sometimes, it does give identical results. Results are reproducible when I use the `randomized` svd solver, the issue is specific to `arpack`. ### Minimal code sample (that we can copy&paste without having any data). ```python. %env PYTHONHASHSEED=0. import numpy as np. np.random.seed(42). import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). adata1 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). adata2 = sc.pp.pca(adata, copy=True, random_state=42, svd_solver='arpack'). print(np.array_equal(adata1.obsm['X_pca'], adata2.obsm['X_pca'])). print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']). ```. ```pytb. env: PYTHONHASHSEED=0. False. [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03. -5.5277348e-04 8.6665154e-05]. [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03. -3.6475658e-03 -1.0871887e-04]. [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03. 6.9665909e-04 4.2915344e-04]. ... [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04. -1.0134950e-03 -1.2260675e-04]. [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03. -2.4490356e-03 2.4688244e-04]. [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03. 7.9727173e-04 8.6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3146,usability,tool,toolz,3146,"6218119e-04]]. ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----. anndata 0.7.5. scanpy 1.7.1. sinfo 0.3.1. -----. PIL 8.1.2. anndata 0.7.5. anyio NA. attr 20.3.0. babel 2.9.0. backcall 0.2.0. bottleneck 1.3.2. brotli NA. cairo 1.20.0. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. constants NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.03.0. dateutil 2.8.1. decorator 4.4.2. future_fstrings NA. get_version 2.1. google NA. h5py 3.1.0. highs_wrapper NA. idna 2.10. igraph 0.8.3. ipykernel 5.5.0. ipython_genutils 0.2.0. jedi 0.18.0. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.3.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.35.0. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.3.4. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.2. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.3. parso 0.8.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. scanpy 1.7.1. scipy 1.6.0. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sparse 0.11.2. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.26.3. wcwidth 0.2.5. yaml 5.4.1. zmq 22.0.3. zope NA. -----. IPython 7.21.0. jupyter_client 6.1.11. jupyter_core 4.7.1. jupyterlab 3.0.10. notebook 6.2.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-44-generic-x86_64-with-glibc2.10. 28 logical CPU cores. -----. Session information updated at 2021-03-18 12:37. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/pull/1750:273,safety,review,review,273,Check and warn if rank_genes_groups gets raw counts; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1750
https://github.com/scverse/scanpy/pull/1750:273,testability,review,review,273,Check and warn if rank_genes_groups gets raw counts; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1750
https://github.com/scverse/scanpy/pull/1750:124,usability,guid,guidelines,124,Check and warn if rank_genes_groups gets raw counts; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1750
https://github.com/scverse/scanpy/pull/1750:155,usability,guid,guide,155,Check and warn if rank_genes_groups gets raw counts; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1750
https://github.com/scverse/scanpy/pull/1750:251,usability,workflow,workflow,251,Check and warn if rank_genes_groups gets raw counts; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1750
https://github.com/scverse/scanpy/pull/1752:269,safety,review,review,269,Fix rmsprop keyword and switch to nb by default; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1752
https://github.com/scverse/scanpy/pull/1752:269,testability,review,review,269,Fix rmsprop keyword and switch to nb by default; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1752
https://github.com/scverse/scanpy/pull/1752:120,usability,guid,guidelines,120,Fix rmsprop keyword and switch to nb by default; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1752
https://github.com/scverse/scanpy/pull/1752:151,usability,guid,guide,151,Fix rmsprop keyword and switch to nb by default; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1752
https://github.com/scverse/scanpy/pull/1752:247,usability,workflow,workflow,247,Fix rmsprop keyword and switch to nb by default; <!-- . Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1752
https://github.com/scverse/scanpy/pull/1753:469,availability,error,error-case-sensitive-drives-supported,469,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:35,deployability,contain,contains,35,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:68,deployability,API,API,68,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:776,deployability,updat,update,776,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:872,deployability,api,api,872,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1180,deployability,API,API,1180,"addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1336,deployability,api,api,1336,"macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1393,deployability,modul,modules,1393,"important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> exa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1609,deployability,api,api,1609," the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1781,deployability,manag,managed,1781,"em. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1789,deployability,api,api,1789," Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1848,deployability,api,api,1848,"t to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1877,deployability,api,api,1877,"s when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in dept",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1966,deployability,API,API,1966,"s. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1991,deployability,api,api,1991," problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and ha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2641,deployability,modul,modules,2641,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2981,deployability,build,build,2981,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3041,deployability,api,api,3041,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3207,deployability,fail,fail,3207,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3243,deployability,modul,module,3243,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1781,energy efficiency,manag,managed,1781,"em. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1983,energy efficiency,current,current,1983,"e of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:68,integrability,API,API,68,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:872,integrability,api,api,872,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1180,integrability,API,API,1180,"addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1336,integrability,api,api,1336,"macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1609,integrability,api,api,1609," the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1789,integrability,api,api,1789," Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1848,integrability,api,api,1848,"t to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1877,integrability,api,api,1877,"s when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in dept",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1966,integrability,API,API,1966,"s. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1991,integrability,api,api,1991," problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and ha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3041,integrability,api,api,3041,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:68,interoperability,API,API,68,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:872,interoperability,api,api,872,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1180,interoperability,API,API,1180,"addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1336,interoperability,api,api,1336,"macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1609,interoperability,api,api,1609," the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1789,interoperability,api,api,1789," Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1848,interoperability,api,api,1848,"t to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1877,interoperability,api,api,1877,"s when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in dept",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1966,interoperability,API,API,1966,"s. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1991,interoperability,api,api,1991," problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and ha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3041,interoperability,api,api,3041,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1393,modifiability,modul,modules,1393,"important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> exa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2641,modifiability,modul,modules,2641,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3243,modifiability,modul,module,3243,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:469,performance,error,error-case-sensitive-drives-supported,469,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:823,performance,content,content,823,"Reorganize reference docs; This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings. * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2825,performance,content,content,2825,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2172,reliability,doe,does,2172,"rated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:3207,reliability,fail,fail,3207,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space. * It takes up a different amount of space for each function. * These plots are manually generated, and are often quite out of date. <details>. <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**. - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
